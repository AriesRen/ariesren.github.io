<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[算法-二分查找]]></title>
    <url>%2Fposts%2F2018-09-30-%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE.html</url>
    <content type="text"><![CDATA[1、二分查找 查找中间索引，判断是否是要查找的数 &nbsp;&nbsp;1）是，返回中间索引； &nbsp;&nbsp;2）否，判断中间索引的数比目标数大还是小？ &nbsp;&nbsp;&nbsp;&nbsp;a) 比目标数大：则目标数在左侧，将最大数设置为中间索引-1； &nbsp;&nbsp;&nbsp;&nbsp;b) 比目标数小：则目标数在右侧，将最小数设置为中间索引+1； &nbsp;&nbsp;计算中间索引，再次判断中间索引是否是要查找的数，进行循环 &nbsp;&nbsp;当最小数大于最大数的时候，说明没有找到，返回-1。 12345678910111213141516171819202122232425262728293031323334import java.util.*;/*** 二分查找*/public class ArraySelectDemo01&#123; public static void main(String[] args)&#123; int[] arr = &#123;11,33,55,66,88,99&#125;; int index = getIndex(arr, 100); System.out.println(index); &#125; public static int getIndex(int[] arr, int value)&#123; int min = 0; int max = arr.length - 1; int mid = (min + max) &gt;&gt;&gt; 1; while(arr[mid] != value)&#123; if(arr[mid] &gt; value)&#123; max = mid - 1; &#125;else&#123; min = mid + 1; &#125; if(min &gt; max)&#123; return -1; &#125; mid = (min + max) &gt;&gt;&gt; 1; &#125; return mid; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-快速排序]]></title>
    <url>%2Fposts%2F2018-09-28-%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[快速排序思想 快速排序是对冒泡排序的一种改进。 快速排序的思想： 选取一个基数，通过与基数的比较将要排序的数据分割成独立的两部分，并且左边的数比基数小，右边的数比基数大， 分析代码复杂度分析]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>快速排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-基数排序]]></title>
    <url>%2Fposts%2F2018-09-25-%E7%AE%97%E6%B3%95-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[算法-选择排序]]></title>
    <url>%2Fposts%2F2018-09-23-%E7%AE%97%E6%B3%95-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>快速排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-选择排序]]></title>
    <url>%2Fposts%2F2018-09-22-%E7%AE%97%E6%B3%95-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[算法-冒泡排序]]></title>
    <url>%2Fposts%2F2018-09-20-%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[排序思想分析代码复杂度分析]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>冒泡排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-递归]]></title>
    <url>%2Fposts%2F2018-09-18-%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92.html</url>
    <content type="text"></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-队列]]></title>
    <url>%2Fposts%2F2018-09-16-%E7%AE%97%E6%B3%95-%E9%98%9F%E5%88%97.html</url>
    <content type="text"></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-栈]]></title>
    <url>%2Fposts%2F2018-09-15-%E7%AE%97%E6%B3%95-%E6%A0%88.html</url>
    <content type="text"></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-链表]]></title>
    <url>%2Fposts%2F2018-09-12-%E7%AE%97%E6%B3%95-%E9%93%BE%E8%A1%A8.html</url>
    <content type="text"><![CDATA[前言]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-数组]]></title>
    <url>%2Fposts%2F2018-09-10-%E7%AE%97%E6%B3%95-%E6%95%B0%E7%BB%84.html</url>
    <content type="text"><![CDATA[前言 提到数组，我想你肯定不陌生，甚至还会自信的说他很简单。 是的，在每一种编程语言中，基本都会有数组这种数据类型。尽管数组看起来非常基础、简单，但是我估计很多人都没有理解这个基础数据结构的精髓。 在大部分的数据结构中，数组都是从0开始编号的，但是为什么数组要从0开始，而不是1开始呢？从1开始不是更符合人类的思维习惯吗？下面我们通过本篇文章来认识这个问题。 数组如何实现随机访问？ 什么是数组呢？数组是一种线性表结构，它用一组连续的内存空间，来存储一组具有相同数据类型的数据。 这里有几个关键词： 第一是线性表。顾名思义，线性表就是数据像一条线一样的结构。每个线性表上的数据最多只有前后两个方向。除了数组，链表、队列、栈等也是线性表结构。 与线性表相对应的概念是非线性表，比如二叉树、堆、图，之所以叫非线性，是因为在非线性表中，数据之间并不是简单的前后关系。 第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，所以才有一个堪称杀手锏的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如在数组中插入、删除一个数据，为了保证连续性，就需要做大量的数据搬移工作。 说到数据的随机访问，那么数组是如何实现很具下标随机访问数组元素的吗？ 我们拿一个长度为10的int类型的数组int[] a = new int[10] 来举例。在如下图中，假设计算机给数组a[10] 分配了一块连续的内存空间000-039，其中首地址为000。 我们知道计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问某个数组元素时，它会通过寻址公式，计算出该元素的内存地址。 $$ a[i]\_address = base\_address + i * data\_type\_size $$ 其中base address表示数组的基地址，data_type_size表示数组中的每个元素的大小，在这个例子中，数组中存储的int类型，所以data_type_size就是4个字节。 很多人在面试中回答数组和链表的区别都会这么说：“链表适合插入、删除，时间复杂度为 O(1)；数组适合查找，查找时间复杂度为O(1)”。实际上这种表述是不准确的。数组是适合查找操作，但是查找的复杂度并不是O(1)，即便是排好序的数组，用二分查找时间复杂度也是$O(logN)$。所以正确的表述应该是数组的随机访问的复杂度是O(1)。 低效的“插入”和“删除”前面我们提到，数组为了保持内存数据的连续性，会导致插入、删除操作比较低效，现在我们就来看看究竟为什么会导致低效？ 插入操作假设数组的长度为n，现在需要将一个数据插入到数组中的第k个位置。为了把第k个位置腾出来，我们需要将k-n这部分的元素都往后顺挪一位。 如果是在数组的末尾插入元素，那就不需要移动数据，时间复杂度为O(1)；但是如果在数组开头插入一个元素，那所有的元素都需要后移一位，所以最坏时间复杂度为O(n)；因为在每个位置插入元素的概率是一样的，所以平均时间复杂度为$ (1+2+3+…+n)/n = O(n) $ 。 所以对于插入的时间复杂度：最好的O(1)，最坏O(n)，平均O(n)。 如果数组中的元素是有序的，并且插入新元素也要保证数组有序，那么就必须按照刚才的方法移动数据。但是如果数组中存储的数据没有任何规律，只是被当来存储数据的集合，那么如果在k处插入一个数据，可以将k处的数据移到数组的末尾，然后替换k处数据为要插入的数据，这种插入处理技巧可以将时间复杂度降为O(1)。 删除操作跟插入数据类似，如果要删除第k个位置的数据，为了保持内存的连续性，也需要搬迁数据，不然数组中间就会出现断层，内存就不连续了。 和插入类似，如果删除数组末尾的数据，则是最好时间复杂度为O(1)；如果删除开头的数据，则最坏时间复杂度为O(n)，平均情况时间复杂度也为O(n)。 实际上，在某些特殊场景下，我们并不一定追求数组中数据的连续性，如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？ 我们继续来看一个例子，数组a[10]中存储了8个元素：a,b,c,d,e,f,g,h。现在我们要依次删除a,b,c这三个元素。 为了避免d,e,f,g这几个数据会被搬移三次，我们可以先记录下已删除的数据，每次的删除并不是真正的搬移数据，只是记录数据已经被删除，当数组没有更多空间存储数据事，我们再进行一次真正的删除操作，这样就大大减少了删除数据之后导致的数据迁移。 如果你了解JVM，会发现，这不就是JVM的标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或算法，而是要学习他背后的思想和处理技巧，这些东西才是最优价值的。如果你细心留意，不管是在开发还是在架构设计中，总能找到某些数据结构和算法的影子。 警惕数组越界问题了解数组的几个基本操作后，再来看看数据的访问越界问题。 这里以一段C语言代码为例来进行说明： 123456789int main(int argc, char* argv[])&#123; int i = 0; int arr[3] = &#123;0&#125;; for(i; i&lt;=3; i++)&#123; arr[i] = 0; printf("hello world\n"); &#125; return 0;&#125; 你发现问题了吗？这段代码并不是打印三行”hello world”，而是会无限打印”hello world”，这是为什么呢？ 我们知道数组大小为3，分别为a[0]、a[1]、a[2]，而我们代码因为书写错误，for循环结束条件错写为了i&lt;=3而非i&lt;3，所以当i=3时，数组访问越界。 我们知道，在C语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。而根据我们前面讲的寻址公式，a[3]也会被定位到一个某块不属于数组的内存地址上，而在C语言的内存管理中，在局部变量分配空间的顺序是跟变量的声明顺序直接相关，同时按照内存由高到低的顺序进行空间分配，所以在内存布局中，i变量的地址刚好是在数组arr之后的一个字，所以在循环体中，将arr[3]赋值为0，实际上却是将计数器i的值设为0，这就导致了该函数的死循环。 关于C语言中编译器关于变量的内存分配顺序可以看此篇文章理解一下: https://blog.csdn.net/liuhuiyi/article/details/7526889 数组越界在C语言中是一种未决行为，并没有规定数组访问越界编译器应该如何处理。因为数组访问的本质就是访问一段连续的内存地址，只要数组通过偏移计算得到的内存地址是可用的，那么程序就不会报错。 所以在这种情况下，一般会出现莫名其妙的错误，而且很多计算机病毒也是利用了代码中数组越界可以访问到非法地址的漏洞，来攻击系统，所以代码中一定要警惕数组的越界访问。 但并非所有的编程语言都想C一样，将数组越界检查交给程序员来做，像Java、Python本身就会做越界检查，比如java会抛出java.lang.ArrayIndexOutOfBoundsException的异常，Python会有IndexError: list index out of range的错误。 容器能否完全代替数组?针对数组类型，很多语言提供了容器类。比如在java中提供了ArrayList、C++ STL中的vector等。那么在项目开发中，什么时候适合用数组，什么时候适合用容器呢？ 以java中ArrayList为例，ArrayList最大的优势就是可以将很多数组操作封装，比如数组的插入、删除等。另外，它还支持动态扩容，当存储空间不够时，它会自动扩容为原来的1.5倍。 不过由于扩容操作涉及内存申请和数据搬移，是比较耗时的，因此如果事先能确定存储数据的大小，最好在创建ArrayList时实现指定数据的大小。 作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有时候用数组会更合适些。 1、Java ArrayList无法存储基本类型，需要封装为Long、Integer等包装类类型，因此存在一定的拆装箱上的性能损耗，如果特别关注性能，或者要使用基本类型，则可以选择数组。 2、如果事先知道数据的大小，并且对数据的操作非常简单，用不到ArrayList提供的大部分方法，也可以使用数组。 对于业务开发，直接使用容器就足够了，省时省力，毕竟一丢丢的性能损耗，不会影响到系统整体的性能，但是如果做一些非常底层的开发，这个时候数组就会优于容器，成为首选。 解答开篇为什么数组的索引是从0开始，而不是从1开始呢？ 从数组存储的内存模型来看，”下标”即索引最确切的定义应该是”偏移(offset)”，如果用arr表示数组的首地址，a[0]就是偏移为0的位置，也就是首地址，a[k]表示偏移k个type_size的位置，所以计算a[k]的内存地址只需要根据如下公式计算即可$$ a[k]\_address = base\_address + k * type\_size $$ 但是如果数组从1开始计数，那我们计算a[k]的内存地址计算公式就会变为：$$ a[k]\_address = base\_address + (k-1) * type\_size $$ 对比两个公式，从1开始的话，每次随机访问数组元素就多了一次减法指令。数组作为非常基础的数据结构，通过下标随机访问数组元素又是非常基础的操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作指令，数组选择了从小标从0开始，而不是从1开始。 不过解释的再多，我认为都算不上压倒性的证明，说数组编号非从0开始不可，最主要的原因可能是历史原因。 C语言设计者用0开始计数数组下标之后，Java、JavaScript等高级语言都效仿了C语言，或者说为了在一定程度上减少C语言程序学习Java的成本，继续沿用了从0开始计数的习惯。但是仍有很多语言中数组并不是从0开始的，比如Matlab。甚至还有一些语言支持负数下标，比如python。 思考题1、在数组的删除操作中，提到了JVM的标记清除垃圾回收算法的核心理念，如果熟悉Java、JVM，回顾下JVM的标记清除垃圾回收算法。2、上面讲到一维数组的寻址公式，类比一下，二维数组的内存寻址公式是怎么样的？ JVM标记清除垃圾回收算法：分为两个阶段，标记和清除。在大多数主流的虚拟机中采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有GC ROOTS，将所有GC ROOTS可达对象标记为存活，只有当标记工作完成后，才会进行清理工作。 该算法最大的问题是会产生连续的内存空间碎片，同时标记和回收的效率都不高，但是对于只有少量垃圾产生时可以采用此种算法。 二维数组的寻址公式： 根据上图,对于一个二维数组int arr[m][n]，arr[i][j]的寻址公式为：$$ arr[i][j]\_address = base\_address + (i + n*j)*data\_type\_size $$ MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-最好、最坏、平均、均摊时间复杂度]]></title>
    <url>%2Fposts%2F2018-09-09-%E7%AE%97%E6%B3%95-%E6%9C%80%E5%A5%BD%E3%80%81%E6%9C%80%E5%9D%8F%E3%80%81%E5%B9%B3%E5%9D%87%E3%80%81%E5%9D%87%E6%91%8A%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.html</url>
    <content type="text"><![CDATA[前言 前面我们讲过复杂度的大O表示法和几个分析技巧，还举了一些复杂度分析的例子，掌握了这些内容，对于复杂度分析这个知识点，已经达到及格线了。 这篇会着重讲一下复杂度分析的四个复杂度分析方面的知识： 最好时间情况复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度。 最好、最坏时间复杂度 我们先用学过的知识试着分析以下代码的时间复杂度： 1234567891011int findArray(int[] arr, int n, int target)&#123; int i = 0; int pos = -1; for(i; i&lt;n; i++)&#123; if(arr[i] = target)&#123; pos = i; &#125; &#125; return pos;&#125; 上面代码实现的功能是在一个无序数组中，查找变量target的位置，如果找不到就返回-1，按照前面的分析方法，该段代码的时间复杂度为O(n)。 但是我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，优化一下这段代码： 123456789101112int findArray(int[] arr, int n, int target)&#123; int i = 0; int pos = -1; for(i; i&lt;n; i++)&#123; if(arr[i] = target)&#123; pos = i; break; &#125; &#125; return pos;&#125; 但是这时候问题来了，优化完之后，时间复杂度还是O(n)吗？ 因为要查找的变量target可能出现在数组的任何位置，如果要查找的target刚好出现在数组的开始位置，那么就不需要遍历剩余的数据，此时时间复杂度为O(1)。但是如果数组中不存在变量target，或者在最后一位，那我们就需要把整个数组都遍历一遍，时间复杂度就成了O(n)，所以这段代码在不同情况下时间复杂度是不同的。 为了表示代码在不同情况下的时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况复杂度、平均时间复杂度。 顾名思义，最好情况时间复杂度就是，在最理想情况下，执行这段代码的时间复杂度。如上例中，在最理想情况下，查找的变量target刚好在第一个，这时候对应的时间复杂度就是最好情况时间复杂度。 同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度，上例中，如果数组中没有要查找的变量target，我们需要把整个数组遍历一遍，所以最坏情况下对应的时间复杂度就是最坏情况复杂度。 平均时间复杂度我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率并不大。为了更好的表示平均情况下的时间复杂度，我们引入一个概念：平均情况时间复杂度，简称平均时间复杂度。 平均时间复杂度又该怎么分析呢？我们还是借助上面的例子。 要查找的变量target在数组中的位置，有n+1中情况： 在数组0 ~ n-1位置 n种情况和不在数组中1个情况。我们把每种情况下，需要遍历的元素个数累加起来，然后在除以n+1，就可以得到需要遍历的元素个数的平均值，即： $$ \frac{1+2+3+…+n+n}{n+1} = \frac{n(n + 3)}{2(n + 1)} $$ 我们知道，时间复杂度大O标记法中，可以省略掉系数、低阶、常量，所以上面的时间复杂度为O(n)。 这个结论虽然是正确的，但是计算过程稍微有点问题。我们刚讲的这n+1中情况，出现的概率并不一样。下面结合概率论的知识分析一下。 我们知道，要查找的变量x，要么在数组中，要么不再数组中，我们假设这两个概率分布为$\frac{1}{2}$。 不在数组中时，时间复杂度为: $n\times\frac{1}{2}$; 在数组中时，因为数组大小为n，出现在任何一个位置的可能性都是一样的，所以每个位置的概率就是:$\frac{1}{2n}$, 因此在数组中时的时间复杂度为：$(1+2+3+…+n)\times\frac{1}{2n} $。 那平均时间复杂度就是：$(1+2+3+…+n)\times\frac{1}{2n} + n\times\frac{1}{2} = \frac{3n+1}{4} = O(n)$。 这个值就是概率论中的加权平均值，也叫做期望值，所以平均时间复杂度也叫做加权平均时间复杂度或者期望时间复杂度。 实际上，在大多情况下我们并不需要区分最好、最坏、平均时间复杂度三种情况，很多时候我们只用一个复杂度就可以满足需求了。只有同一代码在不同的情况下，时间复杂度有量级的差距，我们才会使用三种复杂度表示法来区分。 均摊时间复杂度目前为止，我们应该已经掌握了算法复杂度分析的大部分内容了，下面来认识一个更高级的概念：均摊时间复杂度，以及它对应的分析方法摊还分析。 均摊时间复杂度听起来跟平均时间复杂度有点像，对于初学者来说，这两个概念很容易弄混。前面说过，大部分情况下不需要区分最好、最坏、平均时间复杂度，只有某些特殊情况才需要平均时间复杂度，而均摊时间复杂度比它的应用场景比它更特殊、更有限。 还是以一个例子来说明(别太在意例子，只是为了说明)： 1234567891011121314151617int[] arr = new int[n];int size = 0；void insert(int val)&#123; // 如果数组满了 if(count == arr.length)&#123; int sum = 0; for(int i=0; i&lt;arr.length;i++)&#123; sum = sum + arr[i]; &#125; arr[0] = sum; count = 1; &#125; // 数组赋值 arr[count] = val; ++count;&#125; 先简单解释一下这段代码的功能，这段代码实现了一个往数组中插入数据的功能，如果数组有空闲空间，直接插入即可。如果数组满了，将数组中的数据求和，清空数组，将求和之后的数据放入数组的第一个位置，然后再将新的数据插入。 那这段代码的时间复杂度是多少呢？我们可以先利用上面讲的三种分析方法来分析一下。 最理想情况下，数组有空闲空间，直接插入数据就可以，所以最好时间复杂度为O(1)；最坏情况下，数组中没有空闲空间了，我们需要先进行一次数组遍历求和，在做数据插入，所以最坏情况时间复杂度为O(n)；平均情况时间复杂度，我们还是用概率论的方法来分析，假设数组长度为n，根据插入位置不同，可以分为n种情况，每种情况的时间复杂度为O(1)，另外还有一种特殊情况，就是数组没有空闲时间时，时间复杂度为O(n)，而且这n+1中情况出现的概率是一样的，所以根据加权平均的计算方法，求得平均时间复杂度为：$ 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} +….+ 1\times\frac{1}{n+1} + n\times\frac{1}{n+1} = O(1) $。 我们来比较一下这个例子中insert函数和上面findArray的不同。首先，findArray在极端情况下，复杂度才为O(1)，大部分情况都为O(n)，而insert函数大部分情况时间复杂度都为O(1)，只有特殊情况时间复杂度才为O(n)，这是第一个区别。第二个不同的地方，对于insert函数来说，O(1)和O(n)的时间复杂度出现的频率是非常有规律的，而且有一定的时序关系，一般都是一个O(n)插入之后，跟n-1个O(1)的插入操作，循环往复。 针对这样一种情况，我们并不需要像平均复杂度分析那样，计算所有输入情况和发生的概率，计算加权平均值。 我们引入一种更加简单的分析方法：摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字叫：摊还时间复杂度。 那么究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？ 我们还是以这个insert函数为例，每一次O(n)的插入操作，后面都会跟n-1次O(1)插入操作，所以我们把耗时最多的操作均摊到n-1次耗时少的操作上，均摊下来，这一组连续操作的均摊时间复杂度就为O(1)，这就是均摊分析法的大致思路。 均摊时间复杂度和摊还分析应用场景比较特殊，所以不会经常用到，这里简单总结一下他们的应用场景。 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块分析，看看是否能将时间复杂度高的操作，均摊到其他时间复杂度低的操作上。在一般的能运用均摊时间复杂度的场景中，均摊时间复杂度是等于最好时间复杂度的。 思考题：根据今天学习的几个复杂度分析的方法，来分析一下下面这个add()函数的时间复杂度。 1234567891011121314151617181920int[] arr = new int[10];int len = 10;int i=0;void add(int element)&#123; // 数组空间满了 if(i&gt;=len)&#123; // 数组扩容 int new_arr = new int[len*2]; // 把数组拷贝到新数组 for(int j=0; i&lt;len; j++)&#123; new_arr[j] = arr[j]; &#125; arr = new_arr; len = len*2; &#125; // 添加到数组中 arr[i] = element; ++i;&#125; 在最理想情况下，数组中有空闲空间，可以直接添加到数组中，时间复杂度为O(1)；最坏情况下，数组中没有空闲空间，先进行一次扩容操作，在进行遍历给新数组赋值，时间复杂度为O(n)，所以最坏时间复杂度为O(n)。 平均时间复杂度，可以分为有空闲空间和没有空闲空间两种，有空间空间有n中情况，所以每种情况出现的概率为$\frac{1}{n+1}$，所以根据加权平均的计算方法，求得平均时间复杂度为：$ 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} +….+ 1\times\frac{1}{n+1} + n\times\frac{1}{n+1} = O(1) $。 均摊时间复杂度，可以看出本例是符合均摊时间复杂度的场景的，在一次O(n)时间复杂度操作后都会跟n-1次O(1)时间复杂度操作，所以将O(n)时间复杂度的操作均摊到n-1次O(1)时间复杂度操作上，最终均摊时间复杂度为O(1)。 MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>复杂度分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-复杂度分析]]></title>
    <url>%2Fposts%2F2018-09-08-%E7%AE%97%E6%B3%95-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[前言 我们都知道，数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行的更快、更省存储空间。那如何来衡量算法的“快”和“省”呢？这就要用到复杂度分析：时间、空间复杂度分析。复杂度分析是整个算法学习的精髓，掌握了它，数据结构和算法的内容基本就掌握了一半。 为什么需要复杂度分析 有人说，我只要把代码跑一遍，通过统计、监控，就可以得到算法执行的时间和占用的那内存，为什么还要做复杂度分析呢？ 1、首先，这种评估方法确实是准确的，但是这种方法是”事后统计法”，是有非常大的局限性。 2、测试结果非常依赖测试环境，同样一段代码，在不同的CPU可能执行的时间会差很多，比如Intel Core i9就比i3运行的快，同样在不同的两台机器上也可能会出现代码执行不一样的情况。 3、对于不同的数据集，如果数据的有序程度不一样，那么对数据进行同一种算法运算，也可能会得到不同的结果。除此之外，数据规模的大小也可能对算法产生影响。 因此我们需要一个不用具体的测试数据来测试，就可以粗略估计算法的执行效率的方法，这就是时间、空间复杂度分析所解决的问题。 大O复杂度表示法 算法的执行效率，粗略的讲，就是算法执行的时间，但是如何能在不运行的情况下，得到一段代码的运行时间呢？ 这里举一个简单的例子，求解1，2，3……n 的累加和，以下为一个简单的代码实现： 1234567int sum(int n)&#123; int sum = 0; for (int i=1; i&lt;=n; i++)&#123; sum += i; &#125; return sum;&#125; 从CPU的角度看，每一行代码都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的CPU执行个数、执行时间都不尽相同，但是我们只是粗略的估计，因此这里假设每行代码执行的时间都相同，那么在此基础上，这段代码执行的时间可以进行如下计算： 第二行代码执行时间为time，第三、四行代码执行的时间为 $ 2 \times n \times time $，所以此段代码执行的时间为$ (2n + 1)\times time $ ，可以看出这段代码执行时间T(n)与每行代码的执行次数成正比。 按照这个思路，再对以下代码段进行分析： 12345678int sum(int n)&#123; int sum = 0; for(int i=1; i &lt;= n; i++)&#123; for(int j=1; j &lt;= n; j++)&#123; sum += i*j; &#125; &#125;&#125; 假设每行代码执行的时间依然为time，那么这段代码执行的时间是多少呢？ 第二行代码的执行时间依然为time，第三行代码执行的次数为n次，所以需要的时间为$ n*time $,内层循环第四、五行代码都执行了$ n*n $次,需要的时间为$ 2*n^2*time $。所以此段代码总的执行时间为$(n + 1 + 2n^2)*time $。 尽管不知道time的具体值，但是通过这两段代码的分析过程，得出一个非常重要的规律： 所有的代码执行时间T(n)与每行代码的执行次数成正比$$ T(n) = O(f(n)) $$ 其中 $T(n)$ 表示代码执行的时间; n表示数据规模大小; $ f(n) $ 表示每行代码执行次数的总和，因为是一个公式，所以用$ f(n) $ 表示。公式中的O表示代码执行时间 $ T(n) $ 与 $ f(n) $ 成正比。 所以在第一个例子中 $ T(n) = O(2n + 1) $ ，第二个例子中 $ T(n) = O(2n^2 + n + 1)$ , 这就是大O时间复杂度表示法。大O时间复杂度实际上并不具体表示代码真正执行的时间，而是表示代码执行时间随数据规模增长的变化趋势，所以也叫做渐进时间复杂度，简称时间复杂度。 在时间复杂度公式中，如果n很大时，公式中的低阶、常量、系数三部分并不影响增长趋势，所以可以先忽略。所以上述两个例子的时间复杂度就可以记为： $ T(n) = O(n) $； $ T(n) = O(n^2) $; 时间复杂度分析 前面介绍了大 O 时间复杂度的由来和表示方法，那如何分析一段代码的时间复杂度呢？ 1、只关注循环次数最多的一段代码在大 O 表示法中，只是表示一种趋势，通常我们会忽略公式中的常量、低阶、系数，因此只需要记录一个最大的量级就可以了，所以我们在分析一个算法时，只关注循环次数执行次数最多的那一段代码就行了。 2、加法法则：总复杂度等于量级最大的那段代码的复杂度如果一段代码中出现多个循环，那么总的时间复杂度就是各个循环相加得到的，但是往往会忽略低阶、常量，因此只取量级最大的那段代码就可以了。 注意：当一段代码循环次数是一个常量，比如循环10000、1000000次，只要是一个已知的常量数，且不随数据规模变化，那么该循环照样是一个常量级别的执行时间。 3、乘法法则: 嵌套代码的时间复杂度等于嵌套内外代码复杂度的乘积比如第二个例子中如果但看外层循环的时间复杂度是 $ O(n) $；内层循环的时间复杂度也是 $O(n)$， 因此总共的时间复杂度就是 $ T(n) = O(n) * O(n) = O(n^2) $ 几种常见时间复杂度 1、$O(1)$O(1) 只是常量级时间复杂度的一种表示方法，并不是指执行了一行代码。只要代码的执行时间不随n的增大而增大，这样的代码时间复杂度都可以记为O(1)。一般情况下，只要代码中不出现循环、递归等，即使有成千上万行代码，时间复杂度也是O(1)。 2、$ O(logN)、O(N*logN) $对数阶的时间复杂度非常常见，同时也是最难分析的一种。 1234int i = 1;while(i &lt;= n)&#123; i = i * 2;&#125; 在上述代码中，变量i从1取值，第二次为2，第三次为4，第四次为8……,所以i的取值规律为 $$ 2^0 \&nbsp;&nbsp;&nbsp;&nbsp; 2^1 \&nbsp;&nbsp; 2^2 \&nbsp;&nbsp; 2^3 … 2^k… 2^x $$ 当$2^x = n$ 时，循环结束，而循环的次数即为x，所以时间复杂度也为$ O(x=\log_2 N) $。 如果把代码改为如下。那时间复杂度是多少呢？ 1234int i = 1;while(i &lt;= n)&#123; i = i * 3;&#125; 根据上面的思路，很容易看出这段代码的时间复杂度为$ O(log_3N) $ 。 实际上，不管是以2为底，还是以3为底，亦或是以10为底，我们都把对数阶的时间复杂度记为$ O(logN) $，为什么呢？ 我们知道对数之间是可以互相转化的，$ log_3n$ 就可以转换为$ log_32*log_2N $，所以$ O(log_32) = O(C * log_2N) $，其中$ C = log_32 $ 是一个常量，基于前面的结论： 在采用大O标记复杂度的时候，可以忽略系数，即$ O(C*f(n)) = O(f(n)) $。因此在对数阶时间复杂度的表示方法里，我们忽略的底，统一表示为$O(logN)$。 如果理解了$O(logN)$，那么$O(nlogN)$就很容易了，根据前面所说的乘法法则，如果一段代码的时间复杂度是$O(logN)$，如果循环执行了 n 次，那么该代码的时间复杂度就是$O(nlogN)$。而且$O(nlogN)$是一种非常常见的时间复杂度，归并排序、快速排序的时间复杂度都是$O(nlogN)$。 2、$ O(m+n)、O(m*n) $我们再来讲跟前面都不一样的时间复杂度，代码的时间复杂度由两个数据规模来决定。 123456789101112int func(int m, int n)&#123; int sum1 = 0; for(int i=1; i&lt;=m; i++)&#123; sum1 += i; &#125; int sum1 = 0; for(int j=1; j&lt;=m; j++)&#123; sum1 += j; &#125; return sum1+sum2;&#125; 从代码中看出，m和n表示两个不同的数据规模，我们无法事先评估m和n的量级大小，所以我们在分析复杂度时，就不能简单用加法法则忽略一个，因此上面代码的时间复杂度为$O(m + n)$， 针对这种情况，加法原则就不正确了，我们将加法原则改为：$ T1(m) + T2(n) = O(f(m) + g(n)) $，但是乘法法则继续有效：$ T1(m) + T2(n) = O(f(m) * f(n)) $。 空间复杂度 前面讲过，时间复杂度的全称是渐近时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度的全称就是渐进空间复杂度，表示算法的存储空间与数据规模的增长关系。 还是拿具体的例子说明(仅供测试,一般没人这么写) 12345678void func(int n)&#123; int i = 0; int[] a = new int[n]; for(i; i&lt;n; i++)&#123; a[i] = i*1; print(a[i]); &#125;&#125; 和分析时间复杂度一样，我们看到第二行申请了一个空间变量i，但是它是常量阶的，跟数据规模n无关，所以可以忽略，第三行申请了一个大小为n的int数组，除此之外，该代码没有占据更多的空间O(n). 我们常见的空间复杂度就是$O(1)、O(n)、O(n^2)$，像$ O(logN)、O(nlogN) $ 这样的对数阶复杂度平时都用不到。空间复杂度分析相对时间复杂度要简单得多。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>复杂度分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-安装及配置]]></title>
    <url>%2Fposts%2F2018-09-07-hexo-%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[前言曾几何时，你是否也想有个自己的博客，抒发自己的心情，总结自己的得失，与人分享喜悦、哀伤、愤怒、忧愁，那么这篇文章你就必须看了，非常简单搭建一个自己的开源博客。 一、预备1、安装Nodejs及npm Nodejs下载地址： 官网下载地址：https://nodejs.org/zh-cn/download/ 2、安装Git Git下载地址： 官网下载地址：https://git-scm.com/download/ 安装完成后，执行如下命令，可以显示版本号就算安装成功了 12345678$ node -vv9.11.1$ npm -v6.3.0$ git --versiongit version 2.17.0.windows.1 二、安装hexo进入命令行，执行如下命令: 1234567891011121、全局安装hexo$ npm install hexo -g2、创建hexo工作目录$ mkdir hexo-blog$ cd hexo-blog3、初始化工作目录$ hexo init4、本地启动hexo$ hexo serve 到此一个hexo博客已经搭建完成了，可以访问 http://localhost:4000/ 查看博客的效果。 当然现在你就可以开始写博客了，默认的配置足够你写作、发表文章了，但是默认的东西有些并不符合自己的要求和审美。所以下面对hexo进行一些配置，以符合自己的要求。 三、hexo配置hexo的配置文件在根目录下_config.yml文件中。本文仅列举几项，其余配置可以参照hexo官网文档进行配置，当然，有兴趣可以参照我的配置 网站配置：12345678# Sitetitle: Aries' blog 网站标题subtitle: 副标题description: 我不生产知识，我只是知识的搬运工。 网站一句话描述keywords: 关键词author: 无名万物 作者language: zh-CN 语言timezone: Asia/Shanghai 时区 文章配置：1234url: http://blog.renhj.org 网站urlroot: / 文章根路径permalink: posts/:year-:month-:day-:title.html 文章urlpermalink_defaults: 四、创建新文章你可以通过以下命令来创建一篇新文章1hexo new [layout] &lt;title&gt; 命令中指令文章的布局，默认为post，可以通过修改_config.yml中的default_layout来修改默认布局，当然也可以在文章Front-Matter上添加布局. 当然也可以新建一个草稿： draft，这种布局在建立时会保存到source/_drafts文件夹，也可以通过publish来将草稿移动到正式文件夹。 12345# 新建草稿文章$ hexo new draft &lt;title&gt;# 将文章正式发布$ hexo publish [layout] &lt;title&gt; Front-matter Front-matter是文章最上方以--- 分割的区域，用于指定个别文件的变量 12345678910---layout: 指定文章的布局属性title： 文章标题data：建立日期updated： 更新日期comments： 是否开启文章的评论功能(如果有的话)tags： 标签categories：分类permalink： 覆盖文章的网址--- 修改美化默认的主题是有点丑，可以去hexo的主题商店 找一个自己喜欢的、漂亮的主题。 本人找的是网上比较流行的nexT的主题，即本博客所使用的主题：hexo nexT主题，更多的配置可以参照nexT官网的配置或者其他文章进行配置。本文就不再这里赘述的，具体效果可以看本博客的。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>nexT</tag>
        <tag>Github Pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Markdown来写文章]]></title>
    <url>%2Fposts%2F2018-09-06-%E7%94%A8Markdown%E6%9D%A5%E5%86%99%E6%96%87%E7%AB%A0.html</url>
    <content type="text"><![CDATA[MarkdownMarkdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成丰富的HTML页面。 Markdown用一些简单的符号标识不同的标题，将某些文章标记为”粗体“或者斜体，下面就来一起学习一下。 语法1、标题 不同的标题采用不等个数的#号来进行标记，如下所示： 1234# 一级标题## 二级标题### 三级标题#### 四级标题 2、代码块 在需要高亮的代码块的前一行及后一行使用三个反引号“`”，同时第一行反引号后面表面代码块所使用的语言, 如下： ```pyhtonprint (“Hello World!”)``` 3、特殊字符 123**粗体***斜体*&gt; 引用内容]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
